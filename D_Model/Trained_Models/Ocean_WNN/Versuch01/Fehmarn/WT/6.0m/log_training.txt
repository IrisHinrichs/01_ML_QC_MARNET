INFO:WNN:Epoch 0: Training Loss 0.26886859842755867 	 Validation Loss 0.1573438359890133
INFO:WNN:Epoch 1: Training Loss 0.1680613424852962 	 Validation Loss 0.19252250641584395
INFO:WNN:Epoch 2: Training Loss 0.06794317330593314 	 Validation Loss 0.29933600351214407
INFO:WNN:Epoch 3: Training Loss 0.10243423848672287 	 Validation Loss 0.6674614489078522
INFO:WNN:Epoch 4: Training Loss 0.3494085467750607 	 Validation Loss 1.0449000477790833
INFO:WNN:Epoch 5: Training Loss 0.435076894922347 	 Validation Loss 0.3994376830756664
INFO:WNN:Epoch 6: Training Loss 0.15418153199591214 	 Validation Loss 0.06348883807659149
INFO:WNN:Epoch 7: Training Loss 0.15013561317921156 	 Validation Loss 0.03284752173349261
INFO:WNN:Epoch 8: Training Loss 0.08345038445940524 	 Validation Loss 0.2198665291070938
INFO:WNN:Epoch 9: Training Loss 0.1616006538719882 	 Validation Loss 0.053119885921478274
INFO:WNN:Epoch 10: Training Loss 0.10987493884012904 	 Validation Loss 0.3891089290380478
INFO:WNN:Epoch 11: Training Loss 0.27825564980400797 	 Validation Loss 0.06883698776364326
INFO:WNN:Epoch 12: Training Loss 0.0930619296275928 	 Validation Loss 0.16464405059814452
INFO:WNN:Epoch 13: Training Loss 0.3951981926478351 	 Validation Loss 0.9276788234710693
INFO:WNN:Epoch 14: Training Loss 0.5048421980721781 	 Validation Loss 1.576885610818863
INFO:WNN:Epoch 15: Training Loss 0.528117295027463 	 Validation Loss 2.307745122909546
INFO:WNN:Epoch 16: Training Loss 0.5098772209190728 	 Validation Loss 1.6243758976459504
INFO:WNN:Epoch 17: Training Loss 0.35533410922883524 	 Validation Loss 0.39860260039567946
INFO:WNN:Epoch 18: Training Loss 0.26596375511917936 	 Validation Loss 0.3956752553582191
threshold tensor(1.7195, grad_fn=<MulBackward0>)
