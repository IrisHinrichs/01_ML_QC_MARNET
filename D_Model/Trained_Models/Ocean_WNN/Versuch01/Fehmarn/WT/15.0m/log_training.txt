INFO:WNN:Epoch 0: Training Loss 0.21728692576068134 	 Validation Loss 0.9893642902374268
INFO:WNN:Epoch 1: Training Loss 0.1517058723868472 	 Validation Loss 0.05267936605960131
INFO:WNN:Epoch 2: Training Loss 0.04880024609192793 	 Validation Loss 0.06264282763004303
INFO:WNN:Epoch 3: Training Loss 0.09827419389717139 	 Validation Loss 0.3117684476077557
INFO:WNN:Epoch 4: Training Loss 0.1561945516062028 	 Validation Loss 0.04139594919979572
INFO:WNN:Epoch 5: Training Loss 0.15803520659815898 	 Validation Loss 0.21277961432933806
INFO:WNN:Epoch 6: Training Loss 0.1786419208650772 	 Validation Loss 0.022929138969630003
INFO:WNN:Epoch 7: Training Loss 0.14316827728253895 	 Validation Loss 0.4156986141577363
INFO:WNN:Epoch 8: Training Loss 0.11754009781900464 	 Validation Loss 0.9857875958085061
INFO:WNN:Epoch 9: Training Loss 0.19589886563547143 	 Validation Loss 1.7882586598396302
INFO:WNN:Epoch 10: Training Loss 0.22364659380400553 	 Validation Loss 4.539946443587541
INFO:WNN:Epoch 11: Training Loss 0.5087307042978657 	 Validation Loss 3.7280935373157265
INFO:WNN:Epoch 12: Training Loss 0.42741114391850993 	 Validation Loss 5.3390202015638355
INFO:WNN:Epoch 13: Training Loss 0.5081951226685432 	 Validation Loss 1.4020936673507094
INFO:WNN:Epoch 14: Training Loss 0.23421941737532379 	 Validation Loss 0.8204824805259705
INFO:WNN:Epoch 15: Training Loss 0.11785819647609716 	 Validation Loss 0.4906482666730881
INFO:WNN:Epoch 16: Training Loss 0.12069739027264162 	 Validation Loss 0.15442942418158054
INFO:WNN:Epoch 17: Training Loss 0.11305573144028717 	 Validation Loss 0.284629438072443
threshold tensor(0.8294, grad_fn=<MulBackward0>)
