INFO:WNN:Epoch 0: Training Loss 0.25944901637945184 	 Validation Loss 0.406760161742568
INFO:WNN:Epoch 1: Training Loss 0.1710439224571249 	 Validation Loss 0.035894638299942015
INFO:WNN:Epoch 2: Training Loss 0.046558952642769755 	 Validation Loss 0.07809370048344136
INFO:WNN:Epoch 3: Training Loss 0.10984811181780187 	 Validation Loss 0.18538478165864944
INFO:WNN:Epoch 4: Training Loss 0.08060805307836802 	 Validation Loss 0.12524659372866154
INFO:WNN:Epoch 5: Training Loss 0.06788178666972237 	 Validation Loss 0.07682772688567638
INFO:WNN:Epoch 6: Training Loss 0.06934483689874929 	 Validation Loss 0.0370565521530807
INFO:WNN:Epoch 7: Training Loss 0.05451275926979282 	 Validation Loss 0.03838258283212781
INFO:WNN:Epoch 8: Training Loss 0.04217211895952402 	 Validation Loss 0.23968226313591004
INFO:WNN:Epoch 9: Training Loss 0.08233153268464995 	 Validation Loss 0.5666478872299194
INFO:WNN:Epoch 10: Training Loss 0.107178042339945 	 Validation Loss 0.21790232062339782
INFO:WNN:Epoch 11: Training Loss 0.13270850453519886 	 Validation Loss 0.04914795346558094
INFO:WNN:Epoch 12: Training Loss 0.0806770181206727 	 Validation Loss 0.5112112954258918
threshold tensor(1.8751, grad_fn=<MulBackward0>)
