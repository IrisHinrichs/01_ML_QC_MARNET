INFO:WNN:Epoch 0: Training Loss 0.96721235619043 	 Validation Loss 0.8018534779548645
INFO:WNN:Epoch 1: Training Loss 0.6291643162403489 	 Validation Loss 0.8301001787185669
INFO:WNN:Epoch 2: Training Loss 0.46489648264832795 	 Validation Loss 0.7481533288955688
INFO:WNN:Epoch 3: Training Loss 0.36396902418346144 	 Validation Loss 0.6717408299446106
INFO:WNN:Epoch 4: Training Loss 0.334379144696868 	 Validation Loss 0.6838093400001526
INFO:WNN:Epoch 5: Training Loss 0.4356948485074099 	 Validation Loss 0.6519066095352173
INFO:WNN:Epoch 6: Training Loss 0.5203798804868711 	 Validation Loss 0.6437589526176453
INFO:WNN:Epoch 7: Training Loss 0.3707931772369193 	 Validation Loss 0.7186160087585449
INFO:WNN:Epoch 8: Training Loss 0.30028090449923184 	 Validation Loss 0.659832239151001
INFO:WNN:Epoch 9: Training Loss 0.26530862590880133 	 Validation Loss 0.6519249081611633
INFO:WNN:Epoch 10: Training Loss 0.27972342155408114 	 Validation Loss 0.6495083570480347
INFO:WNN:Epoch 11: Training Loss 0.26685549775720574 	 Validation Loss 0.6580477952957153
INFO:WNN:Epoch 12: Training Loss 0.292433867638465 	 Validation Loss 0.653356671333313
INFO:WNN:Epoch 13: Training Loss 0.2224767035950208 	 Validation Loss 0.6875011324882507
INFO:WNN:Epoch 14: Training Loss 0.2051974138157675 	 Validation Loss 0.6849250793457031
threshold tensor(7.7142, grad_fn=<MulBackward0>)
