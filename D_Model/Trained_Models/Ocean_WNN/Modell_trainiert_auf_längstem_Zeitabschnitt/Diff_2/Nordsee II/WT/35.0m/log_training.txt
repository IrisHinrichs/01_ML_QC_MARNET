INFO:WNN:Epoch 0: Training Loss 1.1450078484735318 	 Validation Loss 0.1930920798331499
INFO:WNN:Epoch 1: Training Loss 0.9453498537519148 	 Validation Loss 0.17777019925415516
INFO:WNN:Epoch 2: Training Loss 0.7728281743114903 	 Validation Loss 0.17229405231773853
INFO:WNN:Epoch 3: Training Loss 0.6908806835611662 	 Validation Loss 0.1730139385908842
INFO:WNN:Epoch 4: Training Loss 0.6140271764071215 	 Validation Loss 0.18122155964374542
INFO:WNN:Epoch 5: Training Loss 0.5484268277706135 	 Validation Loss 0.1744377315044403
INFO:WNN:Epoch 6: Training Loss 0.4852644543030432 	 Validation Loss 0.1731760185211897
INFO:WNN:Epoch 7: Training Loss 0.4339853335349333 	 Validation Loss 0.172748819924891
INFO:WNN:Epoch 8: Training Loss 0.40904545402597814 	 Validation Loss 0.17934985551983118
INFO:WNN:Epoch 9: Training Loss 0.3886313589201087 	 Validation Loss 0.1765716401860118
INFO:WNN:Epoch 10: Training Loss 0.38761257140764166 	 Validation Loss 0.19490742776542902
INFO:WNN:Epoch 11: Training Loss 0.365872677903445 	 Validation Loss 0.18397306185215712
INFO:WNN:Epoch 12: Training Loss 0.37799504434778575 	 Validation Loss 0.19721745233982801
threshold tensor(4.3371, grad_fn=<MulBackward0>)
