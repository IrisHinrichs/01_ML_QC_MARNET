INFO:WNN:Epoch 0: Training Loss 0.8066463811056954 	 Validation Loss 0.9997582361102104
INFO:WNN:Epoch 1: Training Loss 0.6701240064132781 	 Validation Loss 0.9460305385291576
INFO:WNN:Epoch 2: Training Loss 0.6041725721387636 	 Validation Loss 0.9389026500284672
INFO:WNN:Epoch 3: Training Loss 0.5722859498290789 	 Validation Loss 0.9253893718123436
INFO:WNN:Epoch 4: Training Loss 0.5209260309735934 	 Validation Loss 0.9289312623441219
INFO:WNN:Epoch 5: Training Loss 0.48043555056764964 	 Validation Loss 0.9370532669126987
INFO:WNN:Epoch 6: Training Loss 0.4446039008242743 	 Validation Loss 0.9572705663740635
INFO:WNN:Epoch 7: Training Loss 0.40923780522176195 	 Validation Loss 0.9880288131535053
INFO:WNN:Epoch 8: Training Loss 0.37604109659081414 	 Validation Loss 1.0145470388233662
INFO:WNN:Epoch 9: Training Loss 0.3454281450027511 	 Validation Loss 1.0314209088683128
INFO:WNN:Epoch 10: Training Loss 0.31841868233113063 	 Validation Loss 1.0456643924117088
INFO:WNN:Epoch 11: Training Loss 0.29483574096645626 	 Validation Loss 1.0640068352222443
INFO:WNN:Epoch 12: Training Loss 0.27494837024382185 	 Validation Loss 1.0894316732883453
threshold tensor(22.6049, grad_fn=<MulBackward0>)
