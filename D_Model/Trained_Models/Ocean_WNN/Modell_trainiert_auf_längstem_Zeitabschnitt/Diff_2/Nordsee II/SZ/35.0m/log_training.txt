INFO:WNN:Epoch 0: Training Loss 1.1068125205735366 	 Validation Loss 0.270100861787796
INFO:WNN:Epoch 1: Training Loss 0.9098527911119163 	 Validation Loss 0.23238565027713776
INFO:WNN:Epoch 2: Training Loss 0.8189937560819089 	 Validation Loss 0.22016401588916779
INFO:WNN:Epoch 3: Training Loss 0.7996610961854458 	 Validation Loss 0.21253523975610733
INFO:WNN:Epoch 4: Training Loss 0.6955662610319754 	 Validation Loss 0.2203037440776825
INFO:WNN:Epoch 5: Training Loss 0.6712765524474283 	 Validation Loss 0.21775052696466446
INFO:WNN:Epoch 6: Training Loss 0.615559739448751 	 Validation Loss 0.230497308075428
INFO:WNN:Epoch 7: Training Loss 0.5658474633625398 	 Validation Loss 0.2314436435699463
INFO:WNN:Epoch 8: Training Loss 0.5695916089850167 	 Validation Loss 0.21826182305812836
INFO:WNN:Epoch 9: Training Loss 0.5685808941877136 	 Validation Loss 0.22792519629001617
INFO:WNN:Epoch 10: Training Loss 0.5346098865071932 	 Validation Loss 0.24529655277729034
INFO:WNN:Epoch 11: Training Loss 0.5145877243485302 	 Validation Loss 0.24473785609006882
INFO:WNN:Epoch 12: Training Loss 0.5251921358673522 	 Validation Loss 0.2660615146160126
INFO:WNN:Epoch 13: Training Loss 0.48413573834113777 	 Validation Loss 0.2547737807035446
threshold tensor(3.7956, grad_fn=<MulBackward0>)
