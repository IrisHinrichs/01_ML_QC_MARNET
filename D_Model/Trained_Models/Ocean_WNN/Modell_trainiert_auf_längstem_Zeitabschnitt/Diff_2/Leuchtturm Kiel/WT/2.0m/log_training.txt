INFO:WNN:Epoch 0: Training Loss 0.7071337510621355 	 Validation Loss 1.260149672627449
INFO:WNN:Epoch 1: Training Loss 0.6151339202638595 	 Validation Loss 1.21967351436615
INFO:WNN:Epoch 2: Training Loss 0.5772375800917225 	 Validation Loss 1.2207171693444252
INFO:WNN:Epoch 3: Training Loss 0.5482380805356849 	 Validation Loss 1.2285729572176933
INFO:WNN:Epoch 4: Training Loss 0.5257884191289064 	 Validation Loss 1.2355415597558022
INFO:WNN:Epoch 5: Training Loss 0.5067227597558691 	 Validation Loss 1.2446231618523598
INFO:WNN:Epoch 6: Training Loss 0.48560872457681165 	 Validation Loss 1.259748175740242
INFO:WNN:Epoch 7: Training Loss 0.46718184950370945 	 Validation Loss 1.277460440993309
INFO:WNN:Epoch 8: Training Loss 0.4508904582189937 	 Validation Loss 1.2914231643080711
INFO:WNN:Epoch 9: Training Loss 0.4352796083135951 	 Validation Loss 1.307573325932026
INFO:WNN:Epoch 10: Training Loss 0.41940033832384693 	 Validation Loss 1.3353943228721619
INFO:WNN:Epoch 11: Training Loss 0.4039953085443666 	 Validation Loss 1.3614868447184563
threshold tensor(31.3808, grad_fn=<MulBackward0>)
