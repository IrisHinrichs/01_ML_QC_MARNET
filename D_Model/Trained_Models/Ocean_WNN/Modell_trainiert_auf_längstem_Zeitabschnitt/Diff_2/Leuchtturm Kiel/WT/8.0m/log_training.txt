INFO:WNN:Epoch 0: Training Loss 0.917246317468761 	 Validation Loss 0.31734603829681873
INFO:WNN:Epoch 1: Training Loss 0.7146717097817196 	 Validation Loss 0.3119487427175045
INFO:WNN:Epoch 2: Training Loss 0.6815508688755688 	 Validation Loss 0.3519103415310383
INFO:WNN:Epoch 3: Training Loss 0.6554760967662173 	 Validation Loss 0.30099423974752426
INFO:WNN:Epoch 4: Training Loss 0.6058593969200812 	 Validation Loss 0.3471975736320019
INFO:WNN:Epoch 5: Training Loss 0.5765388175283396 	 Validation Loss 0.3413125239312649
INFO:WNN:Epoch 6: Training Loss 0.5391054316497748 	 Validation Loss 0.3046122509986162
INFO:WNN:Epoch 7: Training Loss 0.5477444612465444 	 Validation Loss 0.35411957651376724
INFO:WNN:Epoch 8: Training Loss 0.5371674549218918 	 Validation Loss 0.3334069289267063
INFO:WNN:Epoch 9: Training Loss 0.5053449625533725 	 Validation Loss 0.3340687081217766
INFO:WNN:Epoch 10: Training Loss 0.49714564857265303 	 Validation Loss 0.35344070568680763
INFO:WNN:Epoch 11: Training Loss 0.49696380035981297 	 Validation Loss 0.350344218313694
INFO:WNN:Epoch 12: Training Loss 0.480866455295611 	 Validation Loss 0.34428442269563675
INFO:WNN:Epoch 13: Training Loss 0.4668338280171156 	 Validation Loss 0.3697746582329273
INFO:WNN:Epoch 14: Training Loss 0.43396401836995097 	 Validation Loss 0.3892551138997078
threshold tensor(3.7856, grad_fn=<MulBackward0>)
