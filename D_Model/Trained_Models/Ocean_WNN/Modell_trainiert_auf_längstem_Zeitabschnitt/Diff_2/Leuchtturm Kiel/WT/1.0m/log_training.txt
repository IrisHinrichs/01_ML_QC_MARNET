INFO:WNN:Epoch 0: Training Loss 0.6670840111753297 	 Validation Loss 0.9675055518746376
INFO:WNN:Epoch 1: Training Loss 0.5789031324287256 	 Validation Loss 0.9430900141596794
INFO:WNN:Epoch 2: Training Loss 0.5430670672702411 	 Validation Loss 0.9482392221689224
INFO:WNN:Epoch 3: Training Loss 0.5177188516254463 	 Validation Loss 0.9617161601781845
INFO:WNN:Epoch 4: Training Loss 0.494014846722758 	 Validation Loss 0.9803135320544243
INFO:WNN:Epoch 5: Training Loss 0.47098956174320644 	 Validation Loss 1.0011792033910751
INFO:WNN:Epoch 6: Training Loss 0.4472306785247629 	 Validation Loss 1.0140697956085205
INFO:WNN:Epoch 7: Training Loss 0.4262842409430988 	 Validation Loss 1.0302661061286926
INFO:WNN:Epoch 8: Training Loss 0.406776194179815 	 Validation Loss 1.0444185584783554
INFO:WNN:Epoch 9: Training Loss 0.3883805501437376 	 Validation Loss 1.0622657984495163
INFO:WNN:Epoch 10: Training Loss 0.3694146753303588 	 Validation Loss 1.0743441581726074
INFO:WNN:Epoch 11: Training Loss 0.3508126665320661 	 Validation Loss 1.0886877179145813
threshold tensor(18.2536, grad_fn=<MulBackward0>)
