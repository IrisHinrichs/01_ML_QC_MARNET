INFO:WNN:Epoch 0: Training Loss 0.5662905468295018 	 Validation Loss 1.468151032924652
INFO:WNN:Epoch 1: Training Loss 0.49276066707476734 	 Validation Loss 1.4238043949007988
INFO:WNN:Epoch 2: Training Loss 0.4610906679124113 	 Validation Loss 1.395358219742775
INFO:WNN:Epoch 3: Training Loss 0.438145379225413 	 Validation Loss 1.3769128173589706
INFO:WNN:Epoch 4: Training Loss 0.4193055698027213 	 Validation Loss 1.374152660369873
INFO:WNN:Epoch 5: Training Loss 0.4037704721447967 	 Validation Loss 1.3803712725639343
INFO:WNN:Epoch 6: Training Loss 0.39025756160891245 	 Validation Loss 1.3978172987699509
INFO:WNN:Epoch 7: Training Loss 0.37546692359896877 	 Validation Loss 1.4094040393829346
INFO:WNN:Epoch 8: Training Loss 0.3595809864974211 	 Validation Loss 1.4239335656166077
INFO:WNN:Epoch 9: Training Loss 0.3452856220186703 	 Validation Loss 1.4444518089294434
INFO:WNN:Epoch 10: Training Loss 0.33333682857217295 	 Validation Loss 1.4566284343600273
INFO:WNN:Epoch 11: Training Loss 0.32234189023692456 	 Validation Loss 1.4738226234912872
INFO:WNN:Epoch 12: Training Loss 0.31250689764107975 	 Validation Loss 1.4887137115001678
INFO:WNN:Epoch 13: Training Loss 0.3036444289166303 	 Validation Loss 1.5033286809921265
INFO:WNN:Epoch 14: Training Loss 0.2948176080863627 	 Validation Loss 1.5175779163837433
threshold tensor(32.8190, grad_fn=<MulBackward0>)
