INFO:WNN:Epoch 0: Training Loss 0.9616340026259422 	 Validation Loss 0.21026330441236496
INFO:WNN:Epoch 1: Training Loss 0.7753101504640654 	 Validation Loss 0.1984318196773529
INFO:WNN:Epoch 2: Training Loss 0.6478251403314061 	 Validation Loss 0.19323346763849258
INFO:WNN:Epoch 3: Training Loss 0.5570151634165086 	 Validation Loss 0.19391870498657227
INFO:WNN:Epoch 4: Training Loss 0.4801309118629433 	 Validation Loss 0.19594145566225052
INFO:WNN:Epoch 5: Training Loss 0.42165612912504 	 Validation Loss 0.19622420519590378
INFO:WNN:Epoch 6: Training Loss 0.3758789171697572 	 Validation Loss 0.2013847753405571
INFO:WNN:Epoch 7: Training Loss 0.3531630606157705 	 Validation Loss 0.22699198126792908
INFO:WNN:Epoch 8: Training Loss 0.32086221559438854 	 Validation Loss 0.2193235605955124
INFO:WNN:Epoch 9: Training Loss 0.3064600176876411 	 Validation Loss 0.22302031517028809
INFO:WNN:Epoch 10: Training Loss 0.3000901811174117 	 Validation Loss 0.21500413119792938
INFO:WNN:Epoch 11: Training Loss 0.3003990576835349 	 Validation Loss 0.23482756316661835
INFO:WNN:Epoch 12: Training Loss 0.2974494321970269 	 Validation Loss 0.23339587450027466
threshold tensor(4.6085, grad_fn=<MulBackward0>)
