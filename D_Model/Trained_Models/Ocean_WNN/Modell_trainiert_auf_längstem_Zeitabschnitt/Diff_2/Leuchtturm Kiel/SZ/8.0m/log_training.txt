INFO:WNN:Epoch 0: Training Loss 1.0860546982059112 	 Validation Loss 0.21163010597229004
INFO:WNN:Epoch 1: Training Loss 0.8471998943266674 	 Validation Loss 0.20042992383241653
INFO:WNN:Epoch 2: Training Loss 0.7133219091830632 	 Validation Loss 0.19815246388316154
INFO:WNN:Epoch 3: Training Loss 0.641875743597316 	 Validation Loss 0.1959703452885151
INFO:WNN:Epoch 4: Training Loss 0.5761036040583769 	 Validation Loss 0.1889094039797783
INFO:WNN:Epoch 5: Training Loss 0.51355049558557 	 Validation Loss 0.18278146907687187
INFO:WNN:Epoch 6: Training Loss 0.4575437643350317 	 Validation Loss 0.17806196957826614
INFO:WNN:Epoch 7: Training Loss 0.40933440589847475 	 Validation Loss 0.1756049022078514
INFO:WNN:Epoch 8: Training Loss 0.3661106051160739 	 Validation Loss 0.17666161805391312
INFO:WNN:Epoch 9: Training Loss 0.33025912567973137 	 Validation Loss 0.18464386463165283
INFO:WNN:Epoch 10: Training Loss 0.3030272661350094 	 Validation Loss 0.19850660115480423
INFO:WNN:Epoch 11: Training Loss 0.28854803561877745 	 Validation Loss 0.21375752985477448
INFO:WNN:Epoch 12: Training Loss 0.29174934424316656 	 Validation Loss 0.2009262703359127
INFO:WNN:Epoch 13: Training Loss 0.3133806692293057 	 Validation Loss 0.23995763808488846
INFO:WNN:Epoch 14: Training Loss 0.29045954174720323 	 Validation Loss 0.27821920812129974
INFO:WNN:Epoch 15: Training Loss 0.2750466801942541 	 Validation Loss 0.19984682649374008
INFO:WNN:Epoch 16: Training Loss 0.2428932499785263 	 Validation Loss 0.19537807255983353
INFO:WNN:Epoch 17: Training Loss 0.23589576544383398 	 Validation Loss 0.20231817290186882
threshold tensor(1.6140, grad_fn=<MulBackward0>)
