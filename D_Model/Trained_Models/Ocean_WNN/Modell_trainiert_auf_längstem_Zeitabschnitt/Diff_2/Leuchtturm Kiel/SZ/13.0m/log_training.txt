INFO:WNN:Epoch 0: Training Loss 0.908522138475544 	 Validation Loss 0.29925741418264806
INFO:WNN:Epoch 1: Training Loss 0.7514866630265874 	 Validation Loss 0.29417233378626406
INFO:WNN:Epoch 2: Training Loss 0.6963435084381628 	 Validation Loss 0.2997523727826774
INFO:WNN:Epoch 3: Training Loss 0.654092401118269 	 Validation Loss 0.30505019961856306
INFO:WNN:Epoch 4: Training Loss 0.6154461782277812 	 Validation Loss 0.3113117176108062
INFO:WNN:Epoch 5: Training Loss 0.5877403454662907 	 Validation Loss 0.3182621686719358
INFO:WNN:Epoch 6: Training Loss 0.5588597477310233 	 Validation Loss 0.3242576625198126
INFO:WNN:Epoch 7: Training Loss 0.5329159187699949 	 Validation Loss 0.325849337503314
INFO:WNN:Epoch 8: Training Loss 0.5034862796199464 	 Validation Loss 0.33371272310614586
INFO:WNN:Epoch 9: Training Loss 0.4799264290828317 	 Validation Loss 0.3356172344647348
INFO:WNN:Epoch 10: Training Loss 0.4618082685721299 	 Validation Loss 0.34926954470574856
INFO:WNN:Epoch 11: Training Loss 0.4456338255873157 	 Validation Loss 0.3522780449129641
threshold tensor(9.9854, grad_fn=<MulBackward0>)
