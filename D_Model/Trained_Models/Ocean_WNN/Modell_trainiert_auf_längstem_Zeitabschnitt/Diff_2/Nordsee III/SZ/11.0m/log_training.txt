INFO:WNN:Epoch 0: Training Loss 0.4439758046264095 	 Validation Loss 1.9509244163831074
INFO:WNN:Epoch 1: Training Loss 0.34437621692195536 	 Validation Loss 1.7159555455048878
INFO:WNN:Epoch 2: Training Loss 0.30953415294310876 	 Validation Loss 1.7438190678755443
INFO:WNN:Epoch 3: Training Loss 0.27097483337191597 	 Validation Loss 1.7830698192119598
INFO:WNN:Epoch 4: Training Loss 0.23053282267813172 	 Validation Loss 1.809666117032369
INFO:WNN:Epoch 5: Training Loss 0.20284812508949213 	 Validation Loss 1.8354269166787465
INFO:WNN:Epoch 6: Training Loss 0.17937663796224765 	 Validation Loss 1.8492663502693176
INFO:WNN:Epoch 7: Training Loss 0.16103565450757742 	 Validation Loss 1.8593340367078781
INFO:WNN:Epoch 8: Training Loss 0.14718984658164638 	 Validation Loss 1.8697332839171092
INFO:WNN:Epoch 9: Training Loss 0.13852854787505098 	 Validation Loss 1.8618536194165547
INFO:WNN:Epoch 10: Training Loss 0.13515847757724778 	 Validation Loss 1.9236320455869038
INFO:WNN:Epoch 11: Training Loss 0.13880611027457884 	 Validation Loss 1.9010462760925293
INFO:WNN:Epoch 12: Training Loss 0.13168292991550906 	 Validation Loss 1.9919593681891758
threshold tensor(40.3002, grad_fn=<MulBackward0>)
