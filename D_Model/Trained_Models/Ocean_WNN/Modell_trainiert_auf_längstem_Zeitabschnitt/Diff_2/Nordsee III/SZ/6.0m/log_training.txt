INFO:WNN:Epoch 0: Training Loss 0.7232693575056536 	 Validation Loss 1.2384107609589894
INFO:WNN:Epoch 1: Training Loss 0.5894610898303134 	 Validation Loss 1.1671522756417592
INFO:WNN:Epoch 2: Training Loss 0.5075008989178709 	 Validation Loss 1.1707855363686879
INFO:WNN:Epoch 3: Training Loss 0.43828624691814183 	 Validation Loss 1.2186751465002696
INFO:WNN:Epoch 4: Training Loss 0.37754605899431876 	 Validation Loss 1.2525429129600525
INFO:WNN:Epoch 5: Training Loss 0.33018198162317275 	 Validation Loss 1.2803296744823456
INFO:WNN:Epoch 6: Training Loss 0.28954062858330354 	 Validation Loss 1.3141982704401016
INFO:WNN:Epoch 7: Training Loss 0.2713257433314409 	 Validation Loss 1.3093791206677754
INFO:WNN:Epoch 8: Training Loss 0.25168348364531995 	 Validation Loss 1.3237607379754384
INFO:WNN:Epoch 9: Training Loss 0.24135303271136113 	 Validation Loss 1.3613587319850922
INFO:WNN:Epoch 10: Training Loss 0.22295585865420955 	 Validation Loss 1.3039454023043315
INFO:WNN:Epoch 11: Training Loss 0.2259912549917187 	 Validation Loss 1.3551342884699504
INFO:WNN:Epoch 12: Training Loss 0.208893508464098 	 Validation Loss 1.370408296585083
threshold tensor(24.6888, grad_fn=<MulBackward0>)
