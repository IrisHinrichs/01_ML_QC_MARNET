INFO:WNN:Epoch 0: Training Loss 1.1871759129422053 	 Validation Loss 0.05077421354750792
INFO:WNN:Epoch 1: Training Loss 0.969868605317814 	 Validation Loss 0.03984740190207958
INFO:WNN:Epoch 2: Training Loss 0.7804669318188514 	 Validation Loss 0.04319982727368673
INFO:WNN:Epoch 3: Training Loss 0.6976684725178139 	 Validation Loss 0.044121634835998215
INFO:WNN:Epoch 4: Training Loss 0.637708054003971 	 Validation Loss 0.042421781768401466
INFO:WNN:Epoch 5: Training Loss 0.562560864857265 	 Validation Loss 0.04382605850696564
INFO:WNN:Epoch 6: Training Loss 0.5025183584541082 	 Validation Loss 0.041304330031077065
INFO:WNN:Epoch 7: Training Loss 0.45632681644388606 	 Validation Loss 0.045292979727188744
INFO:WNN:Epoch 8: Training Loss 0.41111286671033925 	 Validation Loss 0.04211836991210779
INFO:WNN:Epoch 9: Training Loss 0.39289471288876876 	 Validation Loss 0.04495209828019142
INFO:WNN:Epoch 10: Training Loss 0.3672638564769711 	 Validation Loss 0.043364288906256356
INFO:WNN:Epoch 11: Training Loss 0.3835379821913583 	 Validation Loss 0.042766950403650604
INFO:WNN:Epoch 12: Training Loss 0.3432652512299163 	 Validation Loss 0.04350310998658339
threshold tensor(0.4199, grad_fn=<MulBackward0>)
