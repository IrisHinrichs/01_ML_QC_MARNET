INFO:WNN:Epoch 0: Training Loss 0.42386161558555835 	 Validation Loss 2.3763102293014526
INFO:WNN:Epoch 1: Training Loss 0.3578974300374587 	 Validation Loss 2.200600028038025
INFO:WNN:Epoch 2: Training Loss 0.32613866753650433 	 Validation Loss 2.1779571175575256
INFO:WNN:Epoch 3: Training Loss 0.2930509824531548 	 Validation Loss 2.1842114329338074
INFO:WNN:Epoch 4: Training Loss 0.25830694643611257 	 Validation Loss 2.226254880428314
INFO:WNN:Epoch 5: Training Loss 0.23307370913751196 	 Validation Loss 2.280192017555237
INFO:WNN:Epoch 6: Training Loss 0.20760244955167625 	 Validation Loss 2.3235331773757935
INFO:WNN:Epoch 7: Training Loss 0.1844055846785054 	 Validation Loss 2.3567221760749817
INFO:WNN:Epoch 8: Training Loss 0.16551853840549788 	 Validation Loss 2.378930389881134
INFO:WNN:Epoch 9: Training Loss 0.15117821690033784 	 Validation Loss 2.390580713748932
INFO:WNN:Epoch 10: Training Loss 0.14044732950402028 	 Validation Loss 2.387545943260193
INFO:WNN:Epoch 11: Training Loss 0.1319073379378427 	 Validation Loss 2.392668902873993
INFO:WNN:Epoch 12: Training Loss 0.12489372418459618 	 Validation Loss 2.3900967240333557
threshold tensor(26.9279, grad_fn=<MulBackward0>)
