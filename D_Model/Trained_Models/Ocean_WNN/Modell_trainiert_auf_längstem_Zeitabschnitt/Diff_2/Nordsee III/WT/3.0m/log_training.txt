INFO:WNN:Epoch 0: Training Loss 0.9272272752390968 	 Validation Loss 0.7188764810562134
INFO:WNN:Epoch 1: Training Loss 0.7571522209931303 	 Validation Loss 0.6476326882839203
INFO:WNN:Epoch 2: Training Loss 0.6229514156778654 	 Validation Loss 0.5987862944602966
INFO:WNN:Epoch 3: Training Loss 0.5391199906115178 	 Validation Loss 0.5856032371520996
INFO:WNN:Epoch 4: Training Loss 0.4820561905701955 	 Validation Loss 0.589053601026535
INFO:WNN:Epoch 5: Training Loss 0.42959073461868147 	 Validation Loss 0.5974881649017334
INFO:WNN:Epoch 6: Training Loss 0.3835738270922943 	 Validation Loss 0.6032637059688568
INFO:WNN:Epoch 7: Training Loss 0.346476083000501 	 Validation Loss 0.6180297136306763
INFO:WNN:Epoch 8: Training Loss 0.3153828658439495 	 Validation Loss 0.6297825574874878
INFO:WNN:Epoch 9: Training Loss 0.2926477122086066 	 Validation Loss 0.6490954458713531
INFO:WNN:Epoch 10: Training Loss 0.27607527209652793 	 Validation Loss 0.6612505912780762
INFO:WNN:Epoch 11: Training Loss 0.2688865904454832 	 Validation Loss 0.6824504137039185
INFO:WNN:Epoch 12: Training Loss 0.2602224959819405 	 Validation Loss 0.6912277638912201
INFO:WNN:Epoch 13: Training Loss 0.24999849222324513 	 Validation Loss 0.7206418216228485
threshold tensor(8.1230, grad_fn=<MulBackward0>)
