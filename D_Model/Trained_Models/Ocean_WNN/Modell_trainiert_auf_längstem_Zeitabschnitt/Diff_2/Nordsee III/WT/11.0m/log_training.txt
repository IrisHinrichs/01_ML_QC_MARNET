INFO:WNN:Epoch 0: Training Loss 0.1593654781692859 	 Validation Loss 4.287244439125061
INFO:WNN:Epoch 1: Training Loss 0.093207629256402 	 Validation Loss 4.0096248388290405
INFO:WNN:Epoch 2: Training Loss 0.09004294293735063 	 Validation Loss 3.9426605701446533
INFO:WNN:Epoch 3: Training Loss 0.07871272800151598 	 Validation Loss 3.8607712984085083
INFO:WNN:Epoch 4: Training Loss 0.09054643346815172 	 Validation Loss 3.987823963165283
INFO:WNN:Epoch 5: Training Loss 0.07990712714804844 	 Validation Loss 4.004865050315857
INFO:WNN:Epoch 6: Training Loss 0.08762032153423537 	 Validation Loss 4.1173442006111145
INFO:WNN:Epoch 7: Training Loss 0.06013293016109277 	 Validation Loss 4.109919905662537
INFO:WNN:Epoch 8: Training Loss 0.062498306763838184 	 Validation Loss 4.09030818939209
INFO:WNN:Epoch 9: Training Loss 0.05667595985825315 	 Validation Loss 4.1090410351753235
INFO:WNN:Epoch 10: Training Loss 0.06257519770808743 	 Validation Loss 4.18562114238739
INFO:WNN:Epoch 11: Training Loss 0.05399795839647678 	 Validation Loss 4.135187923908234
INFO:WNN:Epoch 12: Training Loss 0.0618964006249426 	 Validation Loss 4.2420294880867
threshold tensor(104.6316, grad_fn=<MulBackward0>)
