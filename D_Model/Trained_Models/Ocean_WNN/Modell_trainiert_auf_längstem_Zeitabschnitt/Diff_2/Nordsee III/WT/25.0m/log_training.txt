INFO:WNN:Epoch 0: Training Loss 1.101573764958552 	 Validation Loss 0.1435389742255211
INFO:WNN:Epoch 1: Training Loss 0.878477074525186 	 Validation Loss 0.12757831811904907
INFO:WNN:Epoch 2: Training Loss 0.7127949576292719 	 Validation Loss 0.13589179515838623
INFO:WNN:Epoch 3: Training Loss 0.6048040609806776 	 Validation Loss 0.1541342337926229
INFO:WNN:Epoch 4: Training Loss 0.5278720031891551 	 Validation Loss 0.15342362225055695
INFO:WNN:Epoch 5: Training Loss 0.45779091593410287 	 Validation Loss 0.20868984361489615
INFO:WNN:Epoch 6: Training Loss 0.4088718593652759 	 Validation Loss 0.16017499566078186
INFO:WNN:Epoch 7: Training Loss 0.37498797061187883 	 Validation Loss 0.21793413162231445
INFO:WNN:Epoch 8: Training Loss 0.3411017863878182 	 Validation Loss 0.18882128099600473
INFO:WNN:Epoch 9: Training Loss 0.31846576961023465 	 Validation Loss 0.17564424872398376
INFO:WNN:Epoch 10: Training Loss 0.28401927639331137 	 Validation Loss 0.2356123924255371
INFO:WNN:Epoch 11: Training Loss 0.295033097160714 	 Validation Loss 0.22911878923575082
INFO:WNN:Epoch 12: Training Loss 0.2536733729498727 	 Validation Loss 0.25295574963092804
threshold tensor(1.7618, grad_fn=<MulBackward0>)
