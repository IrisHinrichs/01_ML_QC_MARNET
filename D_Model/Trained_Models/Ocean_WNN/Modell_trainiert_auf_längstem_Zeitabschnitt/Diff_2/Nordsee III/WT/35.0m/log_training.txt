INFO:WNN:Epoch 0: Training Loss 1.0713576697877476 	 Validation Loss 0.28359995285669964
INFO:WNN:Epoch 1: Training Loss 0.8749040883566652 	 Validation Loss 0.2401968240737915
INFO:WNN:Epoch 2: Training Loss 0.7437422318117959 	 Validation Loss 0.24959988395373026
INFO:WNN:Epoch 3: Training Loss 0.6752645514905453 	 Validation Loss 0.2578537066777547
INFO:WNN:Epoch 4: Training Loss 0.6134481755750519 	 Validation Loss 0.2688981741666794
INFO:WNN:Epoch 5: Training Loss 0.5771013177931309 	 Validation Loss 0.27425016462802887
INFO:WNN:Epoch 6: Training Loss 0.5381026064710958 	 Validation Loss 0.28670049210389453
INFO:WNN:Epoch 7: Training Loss 0.5073694097144263 	 Validation Loss 0.288363183538119
INFO:WNN:Epoch 8: Training Loss 0.46020757481455804 	 Validation Loss 0.30240463217099506
INFO:WNN:Epoch 9: Training Loss 0.41946191936731336 	 Validation Loss 0.3038596312204997
INFO:WNN:Epoch 10: Training Loss 0.38279077580996923 	 Validation Loss 0.32311515013376874
INFO:WNN:Epoch 11: Training Loss 0.36815549199070247 	 Validation Loss 0.33666226267814636
INFO:WNN:Epoch 12: Training Loss 0.3700488107545035 	 Validation Loss 0.33758654197057086
threshold tensor(3.3299, grad_fn=<MulBackward0>)
