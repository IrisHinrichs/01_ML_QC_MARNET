INFO:WNN:Epoch 0: Training Loss 0.17632836971565016 	 Validation Loss 2.8034378762046495
INFO:WNN:Epoch 1: Training Loss 0.10528900571100946 	 Validation Loss 2.6345013746370873
INFO:WNN:Epoch 2: Training Loss 0.0836673086475847 	 Validation Loss 2.4239036260793605
INFO:WNN:Epoch 3: Training Loss 0.12157043290457555 	 Validation Loss 2.6407578556487956
INFO:WNN:Epoch 4: Training Loss 0.16570507212475474 	 Validation Loss 2.9585456432153783
INFO:WNN:Epoch 5: Training Loss 0.13155190794329558 	 Validation Loss 2.8543480740239224
INFO:WNN:Epoch 6: Training Loss 0.08719346971650209 	 Validation Loss 2.729200054270526
INFO:WNN:Epoch 7: Training Loss 0.10350072963296303 	 Validation Loss 2.77056764314572
INFO:WNN:Epoch 8: Training Loss 0.10410799135320953 	 Validation Loss 2.9157861346999803
INFO:WNN:Epoch 9: Training Loss 0.06611959680781833 	 Validation Loss 2.805383791526159
INFO:WNN:Epoch 10: Training Loss 0.04352398589918656 	 Validation Loss 2.8494537385801473
INFO:WNN:Epoch 11: Training Loss 0.03800412591081113 	 Validation Loss 2.8501001093536615
INFO:WNN:Epoch 12: Training Loss 0.034895930731935164 	 Validation Loss 2.9042413756251335
INFO:WNN:Epoch 13: Training Loss 0.031648569095081514 	 Validation Loss 2.8848963690300784
threshold tensor(46.5361, grad_fn=<MulBackward0>)
