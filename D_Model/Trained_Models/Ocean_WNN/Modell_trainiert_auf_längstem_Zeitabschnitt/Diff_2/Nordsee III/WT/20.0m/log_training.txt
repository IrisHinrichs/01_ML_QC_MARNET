INFO:WNN:Epoch 0: Training Loss 0.19908581825438887 	 Validation Loss 10.83678150177002
INFO:WNN:Epoch 1: Training Loss 0.11962005873210728 	 Validation Loss 10.441565990447998
INFO:WNN:Epoch 2: Training Loss 0.09107867123758687 	 Validation Loss 10.18936038017273
INFO:WNN:Epoch 3: Training Loss 0.08579326518811285 	 Validation Loss 10.494306564331055
INFO:WNN:Epoch 4: Training Loss 0.08643408038520388 	 Validation Loss 10.327878872553507
INFO:WNN:Epoch 5: Training Loss 0.1116268966213933 	 Validation Loss 10.917000850041708
INFO:WNN:Epoch 6: Training Loss 0.1036361071148089 	 Validation Loss 10.807644685109457
INFO:WNN:Epoch 7: Training Loss 0.08789104114818785 	 Validation Loss 11.306692679723104
INFO:WNN:Epoch 8: Training Loss 0.07888887750783137 	 Validation Loss 11.14110811551412
INFO:WNN:Epoch 9: Training Loss 0.07304272729171706 	 Validation Loss 11.52147881189982
INFO:WNN:Epoch 10: Training Loss 0.06336668287736497 	 Validation Loss 11.583898623784384
INFO:WNN:Epoch 11: Training Loss 0.05154163361460503 	 Validation Loss 11.711753924687704
INFO:WNN:Epoch 12: Training Loss 0.04630144520862294 	 Validation Loss 11.923634926478067
INFO:WNN:Epoch 13: Training Loss 0.03493770981939243 	 Validation Loss 11.455584208170572
threshold tensor(56.1683, grad_fn=<MulBackward0>)
