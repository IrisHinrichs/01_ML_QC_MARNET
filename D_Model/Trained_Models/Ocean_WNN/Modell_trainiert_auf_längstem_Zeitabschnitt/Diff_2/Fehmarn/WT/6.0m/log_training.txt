INFO:WNN:Epoch 0: Training Loss 0.99936829176214 	 Validation Loss 0.0992517073949178
INFO:WNN:Epoch 1: Training Loss 0.765776424591119 	 Validation Loss 0.11673681437969208
INFO:WNN:Epoch 2: Training Loss 0.6451978910610907 	 Validation Loss 0.12107119957605998
INFO:WNN:Epoch 3: Training Loss 0.5716606496522824 	 Validation Loss 0.12325046459833781
INFO:WNN:Epoch 4: Training Loss 0.5092574707749817 	 Validation Loss 0.12880316625038782
INFO:WNN:Epoch 5: Training Loss 0.44604490174808437 	 Validation Loss 0.1241551861166954
INFO:WNN:Epoch 6: Training Loss 0.3688158933073282 	 Validation Loss 0.11288011074066162
INFO:WNN:Epoch 7: Training Loss 0.3064380067711075 	 Validation Loss 0.11366248379151027
INFO:WNN:Epoch 8: Training Loss 0.2787910010665655 	 Validation Loss 0.0999293401837349
INFO:WNN:Epoch 9: Training Loss 0.2653883415170842 	 Validation Loss 0.11919218550125758
INFO:WNN:Epoch 10: Training Loss 0.2658310629841354 	 Validation Loss 0.10831181208292644
INFO:WNN:Epoch 11: Training Loss 0.2651271262827019 	 Validation Loss 0.11410995572805405
threshold tensor(1.2700, grad_fn=<MulBackward0>)
