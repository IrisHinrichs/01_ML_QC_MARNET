INFO:WNN:Epoch 0: Training Loss 0.9743420786478303 	 Validation Loss 0.621293693780899
INFO:WNN:Epoch 1: Training Loss 0.7621549334038388 	 Validation Loss 0.5884497165679932
INFO:WNN:Epoch 2: Training Loss 0.6273150396617976 	 Validation Loss 0.6029915511608124
INFO:WNN:Epoch 3: Training Loss 0.5350947122682225 	 Validation Loss 0.6193625330924988
INFO:WNN:Epoch 4: Training Loss 0.4735670191320506 	 Validation Loss 0.6466923952102661
INFO:WNN:Epoch 5: Training Loss 0.42054485563527455 	 Validation Loss 0.6643798649311066
INFO:WNN:Epoch 6: Training Loss 0.37711608240550215 	 Validation Loss 0.6731833219528198
INFO:WNN:Epoch 7: Training Loss 0.33795352652668953 	 Validation Loss 0.672393262386322
INFO:WNN:Epoch 8: Training Loss 0.31744102422486653 	 Validation Loss 0.6753016710281372
INFO:WNN:Epoch 9: Training Loss 0.2945161820812659 	 Validation Loss 0.6753177642822266
INFO:WNN:Epoch 10: Training Loss 0.29461108622225846 	 Validation Loss 0.6778528094291687
INFO:WNN:Epoch 11: Training Loss 0.2733651645142924 	 Validation Loss 0.6879364848136902
INFO:WNN:Epoch 12: Training Loss 0.2637798711657524 	 Validation Loss 0.6928119659423828
threshold tensor(9.1413, grad_fn=<MulBackward0>)
