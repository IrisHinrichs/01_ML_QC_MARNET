INFO:WNN:Epoch 0: Training Loss 1.0100688675625458 	 Validation Loss 0.19366220633188883
INFO:WNN:Epoch 1: Training Loss 0.7678354378375742 	 Validation Loss 0.21431044737497965
INFO:WNN:Epoch 2: Training Loss 0.6440674230042431 	 Validation Loss 0.22191220770279566
INFO:WNN:Epoch 3: Training Loss 0.5371090705609984 	 Validation Loss 0.2095032533009847
INFO:WNN:Epoch 4: Training Loss 0.4556873761531379 	 Validation Loss 0.19950339694817862
INFO:WNN:Epoch 5: Training Loss 0.3810412663604236 	 Validation Loss 0.19359596818685532
INFO:WNN:Epoch 6: Training Loss 0.32380327716883683 	 Validation Loss 0.18614649772644043
INFO:WNN:Epoch 7: Training Loss 0.2872260723573466 	 Validation Loss 0.2017495408654213
INFO:WNN:Epoch 8: Training Loss 0.28067262889817357 	 Validation Loss 0.19848536451657614
INFO:WNN:Epoch 9: Training Loss 0.2800909101497382 	 Validation Loss 0.22592855741580328
INFO:WNN:Epoch 10: Training Loss 0.2741649983864691 	 Validation Loss 0.23548238227764764
INFO:WNN:Epoch 11: Training Loss 0.2720043713278655 	 Validation Loss 0.20864405731360117
threshold tensor(1.7116, grad_fn=<MulBackward0>)
