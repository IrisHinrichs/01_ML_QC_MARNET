INFO:WNN:Epoch 0: Training Loss 0.8544879228045995 	 Validation Loss 0.5964586436748505
INFO:WNN:Epoch 1: Training Loss 0.6912629175931215 	 Validation Loss 0.5689400732517242
INFO:WNN:Epoch 2: Training Loss 0.5986331105796676 	 Validation Loss 0.565655529499054
INFO:WNN:Epoch 3: Training Loss 0.5343543341326894 	 Validation Loss 0.5882594287395477
INFO:WNN:Epoch 4: Training Loss 0.4882815021344207 	 Validation Loss 0.616577535867691
INFO:WNN:Epoch 5: Training Loss 0.45234607352000294 	 Validation Loss 0.6442899107933044
INFO:WNN:Epoch 6: Training Loss 0.4230744070514585 	 Validation Loss 0.6659767329692841
INFO:WNN:Epoch 7: Training Loss 0.3973725319021579 	 Validation Loss 0.6973768472671509
INFO:WNN:Epoch 8: Training Loss 0.3769813333779122 	 Validation Loss 0.7025638520717621
INFO:WNN:Epoch 9: Training Loss 0.3543120482089845 	 Validation Loss 0.7266191244125366
INFO:WNN:Epoch 10: Training Loss 0.3355374878667521 	 Validation Loss 0.7191784083843231
INFO:WNN:Epoch 11: Training Loss 0.3197608105273861 	 Validation Loss 0.7419494688510895
INFO:WNN:Epoch 12: Training Loss 0.3064762743359262 	 Validation Loss 0.7545683085918427
INFO:WNN:Epoch 13: Training Loss 0.2977249017267516 	 Validation Loss 0.7511931359767914
threshold tensor(6.1176, grad_fn=<MulBackward0>)
