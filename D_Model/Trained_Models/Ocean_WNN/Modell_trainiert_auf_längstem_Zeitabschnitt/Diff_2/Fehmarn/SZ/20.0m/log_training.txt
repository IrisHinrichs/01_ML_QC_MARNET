INFO:WNN:Epoch 0: Training Loss 0.7259581482503563 	 Validation Loss 0.892495408654213
INFO:WNN:Epoch 1: Training Loss 0.5513189206831157 	 Validation Loss 0.8545706421136856
INFO:WNN:Epoch 2: Training Loss 0.507943230913952 	 Validation Loss 0.8405702114105225
INFO:WNN:Epoch 3: Training Loss 0.47576303966343403 	 Validation Loss 0.8368068039417267
INFO:WNN:Epoch 4: Training Loss 0.4444310390390456 	 Validation Loss 0.8420953154563904
INFO:WNN:Epoch 5: Training Loss 0.4121549967676401 	 Validation Loss 0.8495836406946182
INFO:WNN:Epoch 6: Training Loss 0.3798905520234257 	 Validation Loss 0.865500196814537
INFO:WNN:Epoch 7: Training Loss 0.34939368697814643 	 Validation Loss 0.8883887529373169
INFO:WNN:Epoch 8: Training Loss 0.3222205874044448 	 Validation Loss 0.9231218844652176
INFO:WNN:Epoch 9: Training Loss 0.29921263456344604 	 Validation Loss 0.9552670419216156
INFO:WNN:Epoch 10: Training Loss 0.28047575568780303 	 Validation Loss 0.9885159134864807
INFO:WNN:Epoch 11: Training Loss 0.262710013310425 	 Validation Loss 1.006364956498146
INFO:WNN:Epoch 12: Training Loss 0.2474684347398579 	 Validation Loss 1.0198348462581635
INFO:WNN:Epoch 13: Training Loss 0.23721202579326928 	 Validation Loss 1.0314213782548904
threshold tensor(12.7403, grad_fn=<MulBackward0>)
