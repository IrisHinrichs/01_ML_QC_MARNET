INFO:WNN:Epoch 0: Training Loss 0.7043513301759958 	 Validation Loss 0.9584861993789673
INFO:WNN:Epoch 1: Training Loss 0.5845391115705881 	 Validation Loss 0.8369623422622681
INFO:WNN:Epoch 2: Training Loss 0.5099409887833255 	 Validation Loss 0.8092063665390015
INFO:WNN:Epoch 3: Training Loss 0.45420360937714577 	 Validation Loss 0.8050571382045746
INFO:WNN:Epoch 4: Training Loss 0.4138948975929192 	 Validation Loss 0.8150849938392639
INFO:WNN:Epoch 5: Training Loss 0.3815775814000517 	 Validation Loss 0.8273151516914368
INFO:WNN:Epoch 6: Training Loss 0.3528865457379392 	 Validation Loss 0.8418629467487335
INFO:WNN:Epoch 7: Training Loss 0.3294454206646021 	 Validation Loss 0.8580661416053772
INFO:WNN:Epoch 8: Training Loss 0.3091223396227828 	 Validation Loss 0.8756566047668457
INFO:WNN:Epoch 9: Training Loss 0.29076479308839354 	 Validation Loss 0.893410861492157
INFO:WNN:Epoch 10: Training Loss 0.27388664461406215 	 Validation Loss 0.9114692807197571
INFO:WNN:Epoch 11: Training Loss 0.2592322326132229 	 Validation Loss 0.9300233423709869
INFO:WNN:Epoch 12: Training Loss 0.24659382990960563 	 Validation Loss 0.9526059627532959
threshold tensor(11.5519, grad_fn=<MulBackward0>)
