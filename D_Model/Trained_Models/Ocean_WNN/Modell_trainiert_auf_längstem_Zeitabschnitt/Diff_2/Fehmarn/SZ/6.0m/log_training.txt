INFO:WNN:Epoch 0: Training Loss 0.8633942923144154 	 Validation Loss 1.1175859868526459
INFO:WNN:Epoch 1: Training Loss 0.699152802562584 	 Validation Loss 1.0040894150733948
INFO:WNN:Epoch 2: Training Loss 0.5724583743545024 	 Validation Loss 1.047686517238617
INFO:WNN:Epoch 3: Training Loss 0.4832203474867603 	 Validation Loss 1.1319689750671387
INFO:WNN:Epoch 4: Training Loss 0.41933803632855415 	 Validation Loss 1.2415765821933746
INFO:WNN:Epoch 5: Training Loss 0.3740666865006737 	 Validation Loss 1.3320838510990143
INFO:WNN:Epoch 6: Training Loss 0.3389495541544064 	 Validation Loss 1.4072945713996887
INFO:WNN:Epoch 7: Training Loss 0.3080133973904278 	 Validation Loss 1.4474825859069824
INFO:WNN:Epoch 8: Training Loss 0.28213743622536247 	 Validation Loss 1.4982745349407196
INFO:WNN:Epoch 9: Training Loss 0.2620701946966026 	 Validation Loss 1.5010985434055328
INFO:WNN:Epoch 10: Training Loss 0.2518273674599502 	 Validation Loss 1.5539278388023376
INFO:WNN:Epoch 11: Training Loss 0.24317410410098408 	 Validation Loss 1.5347914397716522
INFO:WNN:Epoch 12: Training Loss 0.2409798906225225 	 Validation Loss 1.5511248707771301
threshold tensor(15.0914, grad_fn=<MulBackward0>)
