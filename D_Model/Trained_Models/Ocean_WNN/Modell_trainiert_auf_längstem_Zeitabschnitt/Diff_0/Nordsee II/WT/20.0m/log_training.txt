INFO:WNN:Epoch 0: Training Loss 0.29455408334858174 	 Validation Loss 0.7116816341876984
INFO:WNN:Epoch 1: Training Loss 0.30418017295596655 	 Validation Loss 1.128383845090866
INFO:WNN:Epoch 2: Training Loss 0.3246802453456136 	 Validation Loss 3.199531674385071
INFO:WNN:Epoch 3: Training Loss 0.24217148095097704 	 Validation Loss 1.8316895365715027
INFO:WNN:Epoch 4: Training Loss 0.1102502034433807 	 Validation Loss 0.8462434709072113
INFO:WNN:Epoch 5: Training Loss 0.05661259000771679 	 Validation Loss 0.999210774898529
INFO:WNN:Epoch 6: Training Loss 0.022602517642856885 	 Validation Loss 0.28249016404151917
INFO:WNN:Epoch 7: Training Loss 0.016639340468827868 	 Validation Loss 0.18652977049350739
INFO:WNN:Epoch 8: Training Loss 0.014937226561111553 	 Validation Loss 0.12794873118400574
INFO:WNN:Epoch 9: Training Loss 0.01587680018080088 	 Validation Loss 0.1103178858757019
INFO:WNN:Epoch 10: Training Loss 0.013689929472699683 	 Validation Loss 0.1171058751642704
INFO:WNN:Epoch 11: Training Loss 0.013672987411458356 	 Validation Loss 0.09491507336497307
INFO:WNN:Epoch 12: Training Loss 0.014049677056997703 	 Validation Loss 0.10107820108532906
INFO:WNN:Epoch 13: Training Loss 0.012033146454389984 	 Validation Loss 0.08503896370530128
INFO:WNN:Epoch 14: Training Loss 0.01270514433660234 	 Validation Loss 0.08082190528512001
INFO:WNN:Epoch 15: Training Loss 0.012938522442709655 	 Validation Loss 0.0628854725509882
INFO:WNN:Epoch 16: Training Loss 0.017939424394474674 	 Validation Loss 0.07634015381336212
INFO:WNN:Epoch 17: Training Loss 0.021587675403376732 	 Validation Loss 0.1346062496304512
INFO:WNN:Epoch 18: Training Loss 0.03319092480220812 	 Validation Loss 0.20170900225639343
INFO:WNN:Epoch 19: Training Loss 0.05523460673672768 	 Validation Loss 0.5480072200298309
INFO:WNN:Epoch 20: Training Loss 0.07433607597583129 	 Validation Loss 0.901727944612503
INFO:WNN:Epoch 21: Training Loss 0.029168740397532627 	 Validation Loss 0.23303598165512085
INFO:WNN:Epoch 22: Training Loss 0.02894730024369589 	 Validation Loss 0.08886699751019478
INFO:WNN:Epoch 23: Training Loss 0.03264848518786797 	 Validation Loss 0.09283117577433586
INFO:WNN:Epoch 24: Training Loss 0.03982646069683445 	 Validation Loss 0.16064058244228363
INFO:WNN:Epoch 25: Training Loss 0.05348072850514048 	 Validation Loss 0.49117738008499146
INFO:WNN:Epoch 26: Training Loss 0.06649873090160933 	 Validation Loss 0.5880129933357239
threshold tensor(2.0225, grad_fn=<MulBackward0>)
