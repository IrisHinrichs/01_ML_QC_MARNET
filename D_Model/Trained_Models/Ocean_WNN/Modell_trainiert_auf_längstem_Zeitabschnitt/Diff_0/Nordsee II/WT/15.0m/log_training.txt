INFO:WNN:Epoch 0: Training Loss 0.3442795838595235 	 Validation Loss 0.07042680867016315
INFO:WNN:Epoch 1: Training Loss 0.7781250330929955 	 Validation Loss 1.1546894311904907
INFO:WNN:Epoch 2: Training Loss 0.3255531613859126 	 Validation Loss 0.18222818709909916
INFO:WNN:Epoch 3: Training Loss 0.1238804029514237 	 Validation Loss 0.4620048999786377
INFO:WNN:Epoch 4: Training Loss 0.19923287399467968 	 Validation Loss 0.0808003880083561
INFO:WNN:Epoch 5: Training Loss 0.0947148474376826 	 Validation Loss 0.5721169486641884
INFO:WNN:Epoch 6: Training Loss 0.3767570218160039 	 Validation Loss 0.5095838308334351
INFO:WNN:Epoch 7: Training Loss 0.17778320270146997 	 Validation Loss 0.0543077252805233
INFO:WNN:Epoch 8: Training Loss 0.07732189803694685 	 Validation Loss 0.04851946048438549
INFO:WNN:Epoch 9: Training Loss 0.15472319659671657 	 Validation Loss 0.18119186908006668
INFO:WNN:Epoch 10: Training Loss 0.1481334461298372 	 Validation Loss 0.10884395614266396
INFO:WNN:Epoch 11: Training Loss 0.1747068513761319 	 Validation Loss 0.23760190978646278
INFO:WNN:Epoch 12: Training Loss 0.31157764360042556 	 Validation Loss 0.7512696385383606
INFO:WNN:Epoch 13: Training Loss 0.3083417777393368 	 Validation Loss 0.3128329962491989
INFO:WNN:Epoch 14: Training Loss 0.2513644572879587 	 Validation Loss 0.8022939115762711
INFO:WNN:Epoch 15: Training Loss 0.3677205828328927 	 Validation Loss 1.1527304947376251
INFO:WNN:Epoch 16: Training Loss 0.4150953084629561 	 Validation Loss 0.246757660061121
INFO:WNN:Epoch 17: Training Loss 0.20348027379146688 	 Validation Loss 0.5547560825943947
INFO:WNN:Epoch 18: Training Loss 0.2292081348631265 	 Validation Loss 0.4854405149817467
INFO:WNN:Epoch 19: Training Loss 0.21067526373302653 	 Validation Loss 0.7355822175741196
threshold tensor(1.4527, grad_fn=<MulBackward0>)
