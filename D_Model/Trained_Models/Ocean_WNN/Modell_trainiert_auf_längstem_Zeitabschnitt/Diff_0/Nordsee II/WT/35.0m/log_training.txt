INFO:WNN:Epoch 0: Training Loss 0.341377416692142 	 Validation Loss 0.07618172653019428
INFO:WNN:Epoch 1: Training Loss 0.8014570161522854 	 Validation Loss 1.2205211520195007
INFO:WNN:Epoch 2: Training Loss 0.40383735845292296 	 Validation Loss 0.20990187767893076
INFO:WNN:Epoch 3: Training Loss 0.21319035035447173 	 Validation Loss 0.5961937606334686
INFO:WNN:Epoch 4: Training Loss 0.3163526511218931 	 Validation Loss 0.1405861172825098
INFO:WNN:Epoch 5: Training Loss 0.21739706510700108 	 Validation Loss 0.9543117433786392
INFO:WNN:Epoch 6: Training Loss 0.630889429877113 	 Validation Loss 0.26321183890104294
INFO:WNN:Epoch 7: Training Loss 0.3778999819464627 	 Validation Loss 0.08696546778082848
INFO:WNN:Epoch 8: Training Loss 0.5046165130832898 	 Validation Loss 1.0044515132904053
INFO:WNN:Epoch 9: Training Loss 0.3652162229908364 	 Validation Loss 1.2315580248832703
INFO:WNN:Epoch 10: Training Loss 0.27827785403600763 	 Validation Loss 0.9998370185494423
INFO:WNN:Epoch 11: Training Loss 0.42521975213839186 	 Validation Loss 1.5279643535614014
threshold tensor(2.3172, grad_fn=<MulBackward0>)
