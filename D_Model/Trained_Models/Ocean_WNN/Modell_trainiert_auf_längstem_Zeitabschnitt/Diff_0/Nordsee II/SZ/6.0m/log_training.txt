INFO:WNN:Epoch 0: Training Loss 0.16793158184736967 	 Validation Loss 0.1522406041622162
INFO:WNN:Epoch 1: Training Loss 0.27908400062005967 	 Validation Loss 0.08792416306096129
INFO:WNN:Epoch 2: Training Loss 0.279334149012963 	 Validation Loss 0.06768528651446104
INFO:WNN:Epoch 3: Training Loss 0.22663552284939215 	 Validation Loss 0.07452690228819847
INFO:WNN:Epoch 4: Training Loss 0.15443694521673024 	 Validation Loss 0.17203893512487411
INFO:WNN:Epoch 5: Training Loss 0.21014942966091135 	 Validation Loss 0.047566731460392475
INFO:WNN:Epoch 6: Training Loss 0.1397720011882484 	 Validation Loss 0.05240604281425476
INFO:WNN:Epoch 7: Training Loss 0.17333089673775248 	 Validation Loss 0.18846222013235092
INFO:WNN:Epoch 8: Training Loss 0.2190781420795247 	 Validation Loss 0.4588581621646881
INFO:WNN:Epoch 9: Training Loss 0.30575126758776605 	 Validation Loss 0.0322353292722255
INFO:WNN:Epoch 10: Training Loss 0.21201895689591765 	 Validation Loss 0.029036606661975384
INFO:WNN:Epoch 11: Training Loss 0.11098989966558293 	 Validation Loss 0.2133469134569168
INFO:WNN:Epoch 12: Training Loss 0.22662393318023533 	 Validation Loss 1.0491224825382233
INFO:WNN:Epoch 13: Training Loss 0.4544105976819992 	 Validation Loss 0.06411039223894477
INFO:WNN:Epoch 14: Training Loss 0.1702143132376174 	 Validation Loss 0.07572252675890923
INFO:WNN:Epoch 15: Training Loss 0.18583347299136221 	 Validation Loss 0.7186183035373688
INFO:WNN:Epoch 16: Training Loss 0.43630770531793434 	 Validation Loss 0.10414865240454674
INFO:WNN:Epoch 17: Training Loss 0.34887439051332575 	 Validation Loss 0.4825531542301178
INFO:WNN:Epoch 18: Training Loss 0.4576917191346486 	 Validation Loss 0.02257610863307491
INFO:WNN:Epoch 19: Training Loss 0.19008522251776108 	 Validation Loss 0.01828716794261709
INFO:WNN:Epoch 20: Training Loss 0.1402976059956321 	 Validation Loss 0.024991659447550774
INFO:WNN:Epoch 21: Training Loss 0.06352804228663445 	 Validation Loss 0.024802242871373892
INFO:WNN:Epoch 22: Training Loss 0.03969911066815257 	 Validation Loss 0.016609250858891755
INFO:WNN:Epoch 23: Training Loss 0.02975621453030423 	 Validation Loss 0.015404414385557175
INFO:WNN:Epoch 24: Training Loss 0.025719508160060894 	 Validation Loss 0.013434713648166507
INFO:WNN:Epoch 25: Training Loss 0.024680605269774485 	 Validation Loss 0.013023879728280008
INFO:WNN:Epoch 26: Training Loss 0.023374309317053605 	 Validation Loss 0.012615694548003376
INFO:WNN:Epoch 27: Training Loss 0.024816170063180227 	 Validation Loss 0.012272086867596954
INFO:WNN:Epoch 28: Training Loss 0.024387854704400524 	 Validation Loss 0.013123411568813026
INFO:WNN:Epoch 29: Training Loss 0.026660697573485475 	 Validation Loss 0.013665622798725963
INFO:WNN:Epoch 30: Training Loss 0.027530538878636435 	 Validation Loss 0.015208694385364652
INFO:WNN:Epoch 31: Training Loss 0.02980849864737441 	 Validation Loss 0.016964915208518505
INFO:WNN:Epoch 32: Training Loss 0.03281267210453128 	 Validation Loss 0.019413210568018258
INFO:WNN:Epoch 33: Training Loss 0.03297104866942391 	 Validation Loss 0.020258096978068352
INFO:WNN:Epoch 34: Training Loss 0.03648150763910962 	 Validation Loss 0.021648032357916236
INFO:WNN:Epoch 35: Training Loss 0.038457274165314935 	 Validation Loss 0.016169609501957893
INFO:WNN:Epoch 36: Training Loss 0.04135434376075864 	 Validation Loss 0.01998034177813679
INFO:WNN:Epoch 37: Training Loss 0.04011138489780327 	 Validation Loss 0.012530666077509522
threshold tensor(0.1903, grad_fn=<MulBackward0>)
