INFO:WNN:Epoch 0: Training Loss 0.36193493022941625 	 Validation Loss 0.04446917027235031
INFO:WNN:Epoch 1: Training Loss 0.08660443289241251 	 Validation Loss 0.02516654971987009
INFO:WNN:Epoch 2: Training Loss 0.09663597895548894 	 Validation Loss 0.02383144572377205
INFO:WNN:Epoch 3: Training Loss 0.1856391649120129 	 Validation Loss 0.04185275640338659
INFO:WNN:Epoch 4: Training Loss 0.2694342215903677 	 Validation Loss 0.07691063731908798
INFO:WNN:Epoch 5: Training Loss 0.2740140158969622 	 Validation Loss 0.05036335624754429
INFO:WNN:Epoch 6: Training Loss 0.15944457312042898 	 Validation Loss 0.027226030826568604
INFO:WNN:Epoch 7: Training Loss 0.10555236872572166 	 Validation Loss 0.03299177810549736
INFO:WNN:Epoch 8: Training Loss 0.11817717298757859 	 Validation Loss 0.028209946118295193
INFO:WNN:Epoch 9: Training Loss 0.06567070668993089 	 Validation Loss 0.014282673597335815
INFO:WNN:Epoch 10: Training Loss 0.09364297626038584 	 Validation Loss 0.019451466389000416
INFO:WNN:Epoch 11: Training Loss 0.08992419116055736 	 Validation Loss 0.031651792116463184
INFO:WNN:Epoch 12: Training Loss 0.08906115473319705 	 Validation Loss 0.032323574647307396
INFO:WNN:Epoch 13: Training Loss 0.08543002505141956 	 Validation Loss 0.020386027172207832
INFO:WNN:Epoch 14: Training Loss 0.06672568214484133 	 Validation Loss 0.026321781799197197
INFO:WNN:Epoch 15: Training Loss 0.0846886364922214 	 Validation Loss 0.030222357250750065
INFO:WNN:Epoch 16: Training Loss 0.07501106473724715 	 Validation Loss 0.02054911945015192
INFO:WNN:Epoch 17: Training Loss 0.05220822143690804 	 Validation Loss 0.012222844874486327
INFO:WNN:Epoch 18: Training Loss 0.09816914805784248 	 Validation Loss 0.03781687095761299
INFO:WNN:Epoch 19: Training Loss 0.08495696245406109 	 Validation Loss 0.04012764059007168
INFO:WNN:Epoch 20: Training Loss 0.04901235052742637 	 Validation Loss 0.012914021033793688
INFO:WNN:Epoch 21: Training Loss 0.09848132388791643 	 Validation Loss 0.03378715179860592
INFO:WNN:Epoch 22: Training Loss 0.0730227143682826 	 Validation Loss 0.041776781901717186
INFO:WNN:Epoch 23: Training Loss 0.041359427247348673 	 Validation Loss 0.01065683295018971
INFO:WNN:Epoch 24: Training Loss 0.05428070066353449 	 Validation Loss 0.01007613237015903
INFO:WNN:Epoch 25: Training Loss 0.0651831178066249 	 Validation Loss 0.020048609469085932
INFO:WNN:Epoch 26: Training Loss 0.08373759015320012 	 Validation Loss 0.03184574469923973
INFO:WNN:Epoch 27: Training Loss 0.13321762016186348 	 Validation Loss 0.045101894065737724
INFO:WNN:Epoch 28: Training Loss 0.10754160781820807 	 Validation Loss 0.028108232654631138
INFO:WNN:Epoch 29: Training Loss 0.15858754666092303 	 Validation Loss 0.024424880743026733
INFO:WNN:Epoch 30: Training Loss 0.21648079079862398 	 Validation Loss 0.0283556105569005
INFO:WNN:Epoch 31: Training Loss 0.23082832983121848 	 Validation Loss 0.035924035124480724
INFO:WNN:Epoch 32: Training Loss 0.16328517012208557 	 Validation Loss 0.03325440175831318
INFO:WNN:Epoch 33: Training Loss 0.20004064124077559 	 Validation Loss 0.0365934856235981
INFO:WNN:Epoch 34: Training Loss 0.10604728987583747 	 Validation Loss 0.01817406713962555
INFO:WNN:Epoch 35: Training Loss 0.17413420172838065 	 Validation Loss 0.14658690243959427
threshold tensor(0.4467, grad_fn=<MulBackward0>)
