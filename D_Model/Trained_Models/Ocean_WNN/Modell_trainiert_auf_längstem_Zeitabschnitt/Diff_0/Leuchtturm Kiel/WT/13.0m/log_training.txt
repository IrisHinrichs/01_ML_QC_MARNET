INFO:WNN:Epoch 0: Training Loss 0.4233321605643141 	 Validation Loss 0.4881650358438492
INFO:WNN:Epoch 1: Training Loss 0.7940503675272339 	 Validation Loss 0.02207684237509966
INFO:WNN:Epoch 2: Training Loss 0.7545731620193692 	 Validation Loss 2.0268364548683167
INFO:WNN:Epoch 3: Training Loss 0.5960277913254686 	 Validation Loss 0.19573906809091568
INFO:WNN:Epoch 4: Training Loss 0.3950815662246896 	 Validation Loss 0.6500752083957195
INFO:WNN:Epoch 5: Training Loss 0.6044642069828114 	 Validation Loss 1.4774359315633774
INFO:WNN:Epoch 6: Training Loss 0.8155840768304188 	 Validation Loss 1.7877807319164276
INFO:WNN:Epoch 7: Training Loss 0.8090215696720406 	 Validation Loss 1.272355079650879
INFO:WNN:Epoch 8: Training Loss 0.3900978299570852 	 Validation Loss 0.8602443337440491
INFO:WNN:Epoch 9: Training Loss 0.3377788222860545 	 Validation Loss 0.24827063456177711
INFO:WNN:Epoch 10: Training Loss 0.16168277935867081 	 Validation Loss 0.5020597502589226
INFO:WNN:Epoch 11: Training Loss 0.2647068379446864 	 Validation Loss 0.10588467679917812
INFO:WNN:Epoch 12: Training Loss 0.2748997347516706 	 Validation Loss 0.5007349848747253
threshold tensor(1.8213, grad_fn=<MulBackward0>)
