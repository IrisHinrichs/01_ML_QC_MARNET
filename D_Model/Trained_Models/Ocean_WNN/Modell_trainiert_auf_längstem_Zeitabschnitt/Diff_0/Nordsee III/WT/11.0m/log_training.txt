INFO:WNN:Epoch 0: Training Loss 0.09012965210290118 	 Validation Loss 2.032607063651085
INFO:WNN:Epoch 1: Training Loss 0.013718665824412848 	 Validation Loss 1.6860713437199593
INFO:WNN:Epoch 2: Training Loss 0.018066567150085713 	 Validation Loss 1.3346390277147293
INFO:WNN:Epoch 3: Training Loss 0.010282285896017018 	 Validation Loss 1.0434850603342056
INFO:WNN:Epoch 4: Training Loss 0.014563768491798051 	 Validation Loss 1.2276852279901505
INFO:WNN:Epoch 5: Training Loss 0.021953307522573705 	 Validation Loss 1.7946540415287018
INFO:WNN:Epoch 6: Training Loss 0.02517125855383435 	 Validation Loss 2.245479539036751
INFO:WNN:Epoch 7: Training Loss 0.018110797648797885 	 Validation Loss 2.3828964233398438
INFO:WNN:Epoch 8: Training Loss 0.010652255007616159 	 Validation Loss 2.325277164578438
INFO:WNN:Epoch 9: Training Loss 0.008666156147338563 	 Validation Loss 2.364349514245987
INFO:WNN:Epoch 10: Training Loss 0.008609528288202868 	 Validation Loss 2.3925220519304276
INFO:WNN:Epoch 11: Training Loss 0.009351345043714073 	 Validation Loss 2.387184590101242
INFO:WNN:Epoch 12: Training Loss 0.01014578222847459 	 Validation Loss 2.3518743067979813
INFO:WNN:Epoch 13: Training Loss 0.010518418702607354 	 Validation Loss 2.2822124660015106
INFO:WNN:Epoch 14: Training Loss 0.010742970405386366 	 Validation Loss 2.2247965931892395
threshold tensor(12.6096, grad_fn=<MulBackward0>)
