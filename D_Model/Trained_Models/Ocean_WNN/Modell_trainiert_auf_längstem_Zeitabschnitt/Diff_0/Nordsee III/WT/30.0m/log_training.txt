INFO:WNN:Epoch 0: Training Loss 0.24698426702192852 	 Validation Loss 0.7059504787127177
INFO:WNN:Epoch 1: Training Loss 0.19552785099617073 	 Validation Loss 0.15111387769381204
INFO:WNN:Epoch 2: Training Loss 0.08747845511617405 	 Validation Loss 1.7691999872525532
INFO:WNN:Epoch 3: Training Loss 0.13309597911512747 	 Validation Loss 0.023378790666659672
INFO:WNN:Epoch 4: Training Loss 0.0560345594172499 	 Validation Loss 0.049433243150512375
INFO:WNN:Epoch 5: Training Loss 0.029273460391310176 	 Validation Loss 0.27254191413521767
INFO:WNN:Epoch 6: Training Loss 0.02728440124275429 	 Validation Loss 0.2637426455815633
INFO:WNN:Epoch 7: Training Loss 0.02920657359229933 	 Validation Loss 0.09284094348549843
INFO:WNN:Epoch 8: Training Loss 0.014553290525717395 	 Validation Loss 0.020655435820420582
INFO:WNN:Epoch 9: Training Loss 0.018328127876988478 	 Validation Loss 0.03220009493331114
INFO:WNN:Epoch 10: Training Loss 0.017185049720241555 	 Validation Loss 0.17568724850813547
INFO:WNN:Epoch 11: Training Loss 0.01860381343368707 	 Validation Loss 0.05720389696458975
INFO:WNN:Epoch 12: Training Loss 0.014860882402198123 	 Validation Loss 0.15442863727609316
INFO:WNN:Epoch 13: Training Loss 0.02617780998573705 	 Validation Loss 0.028912481541434925
INFO:WNN:Epoch 14: Training Loss 0.029256600999672498 	 Validation Loss 0.3244594174126784
INFO:WNN:Epoch 15: Training Loss 0.03754412657248655 	 Validation Loss 0.11925483122467995
INFO:WNN:Epoch 16: Training Loss 0.022529292715314245 	 Validation Loss 0.16907082870602608
INFO:WNN:Epoch 17: Training Loss 0.024532902540106857 	 Validation Loss 0.09504284088810284
INFO:WNN:Epoch 18: Training Loss 0.020088776763129448 	 Validation Loss 0.11344865957895915
INFO:WNN:Epoch 19: Training Loss 0.020073379592836966 	 Validation Loss 0.07202954031527042
threshold tensor(0.2818, grad_fn=<MulBackward0>)
