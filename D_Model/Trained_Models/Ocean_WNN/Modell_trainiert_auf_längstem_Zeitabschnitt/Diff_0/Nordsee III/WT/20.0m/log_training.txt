INFO:WNN:Epoch 0: Training Loss 0.1861200247359063 	 Validation Loss 2.7333165605862937
INFO:WNN:Epoch 1: Training Loss 0.10458593061193824 	 Validation Loss 3.3243824938933053
INFO:WNN:Epoch 2: Training Loss 0.050052831205539404 	 Validation Loss 3.489951034386953
INFO:WNN:Epoch 3: Training Loss 0.10756795735630606 	 Validation Loss 3.543624540170034
INFO:WNN:Epoch 4: Training Loss 0.06754094708843955 	 Validation Loss 3.258556842803955
INFO:WNN:Epoch 5: Training Loss 0.11633663338475994 	 Validation Loss 4.004717071851094
INFO:WNN:Epoch 6: Training Loss 0.04743744518740901 	 Validation Loss 3.020976076523463
INFO:WNN:Epoch 7: Training Loss 0.038429121829436294 	 Validation Loss 3.0579804877440133
INFO:WNN:Epoch 8: Training Loss 0.039889143395703285 	 Validation Loss 2.6704481740792594
INFO:WNN:Epoch 9: Training Loss 0.036748961838228365 	 Validation Loss 3.0205078721046448
INFO:WNN:Epoch 10: Training Loss 0.025220683350094728 	 Validation Loss 2.7982610861460366
INFO:WNN:Epoch 11: Training Loss 0.02413048021428819 	 Validation Loss 2.744431177775065
threshold tensor(15.5655, grad_fn=<MulBackward0>)
