INFO:WNN:Epoch 0: Training Loss 0.4481682718138803 	 Validation Loss 0.5811029523611069
INFO:WNN:Epoch 1: Training Loss 0.28529759792780335 	 Validation Loss 0.3627565950155258
INFO:WNN:Epoch 2: Training Loss 0.1539358396760442 	 Validation Loss 0.28726469725370407
INFO:WNN:Epoch 3: Training Loss 0.2499013715846972 	 Validation Loss 0.14292050153017044
INFO:WNN:Epoch 4: Training Loss 0.11228078999556601 	 Validation Loss 0.19229615479707718
INFO:WNN:Epoch 5: Training Loss 0.17850192890248515 	 Validation Loss 0.14515246450901031
INFO:WNN:Epoch 6: Training Loss 0.1595925861461596 	 Validation Loss 0.11832964047789574
INFO:WNN:Epoch 7: Training Loss 0.11937990598380566 	 Validation Loss 0.19140998274087906
INFO:WNN:Epoch 8: Training Loss 0.1430759376592257 	 Validation Loss 0.11167025193572044
INFO:WNN:Epoch 9: Training Loss 0.09600974856452509 	 Validation Loss 0.08058315888047218
INFO:WNN:Epoch 10: Training Loss 0.07804643867579712 	 Validation Loss 0.11953205242753029
INFO:WNN:Epoch 11: Training Loss 0.10682873076505282 	 Validation Loss 0.14855648204684258
INFO:WNN:Epoch 12: Training Loss 0.13546012426641854 	 Validation Loss 0.08897534385323524
INFO:WNN:Epoch 13: Training Loss 0.09346662827936764 	 Validation Loss 0.09730549529194832
INFO:WNN:Epoch 14: Training Loss 0.09192986305887726 	 Validation Loss 0.19043291732668877
INFO:WNN:Epoch 15: Training Loss 0.14475840948183427 	 Validation Loss 0.11806195229291916
INFO:WNN:Epoch 16: Training Loss 0.13703001906502654 	 Validation Loss 0.07117081247270107
INFO:WNN:Epoch 17: Training Loss 0.10908613368784162 	 Validation Loss 0.35005079954862595
INFO:WNN:Epoch 18: Training Loss 0.22773193047297272 	 Validation Loss 0.18165439367294312
INFO:WNN:Epoch 19: Training Loss 0.18637467590583998 	 Validation Loss 0.09207883849740028
INFO:WNN:Epoch 20: Training Loss 0.13682695181871002 	 Validation Loss 0.09117472544312477
INFO:WNN:Epoch 21: Training Loss 0.11366784200072289 	 Validation Loss 0.08811065927147865
INFO:WNN:Epoch 22: Training Loss 0.13650167614898898 	 Validation Loss 0.09046292677521706
INFO:WNN:Epoch 23: Training Loss 0.19272530426017262 	 Validation Loss 0.13434933498501778
INFO:WNN:Epoch 24: Training Loss 0.238597627856176 	 Validation Loss 0.15069402009248734
INFO:WNN:Epoch 25: Training Loss 0.2649912373162806 	 Validation Loss 0.15707730874419212
INFO:WNN:Epoch 26: Training Loss 0.18831973751498896 	 Validation Loss 0.222460575401783
INFO:WNN:Epoch 27: Training Loss 0.18065862518481232 	 Validation Loss 0.1567239686846733
threshold tensor(1.0404, grad_fn=<MulBackward0>)
