INFO:WNN:Epoch 0: Training Loss 0.030304224538527567 	 Validation Loss 0.06885233573848382
INFO:WNN:Epoch 1: Training Loss 0.06477178774573683 	 Validation Loss 0.24477735022082925
INFO:WNN:Epoch 2: Training Loss 0.012963140725685073 	 Validation Loss 0.08529721206286922
INFO:WNN:Epoch 3: Training Loss 0.012597848735125082 	 Validation Loss 0.063711094961036
INFO:WNN:Epoch 4: Training Loss 0.007424174027985975 	 Validation Loss 0.050605295051354915
INFO:WNN:Epoch 5: Training Loss 0.006106681333793365 	 Validation Loss 0.17756624519824982
INFO:WNN:Epoch 6: Training Loss 0.010741972714680267 	 Validation Loss 0.2840935061685741
INFO:WNN:Epoch 7: Training Loss 0.018607122953039026 	 Validation Loss 0.2959194602444768
INFO:WNN:Epoch 8: Training Loss 0.010159602723462394 	 Validation Loss 0.5178549312986434
INFO:WNN:Epoch 9: Training Loss 0.008919487698804292 	 Validation Loss 0.19228442618623376
INFO:WNN:Epoch 10: Training Loss 0.018605686723725805 	 Validation Loss 0.6111861979588866
INFO:WNN:Epoch 11: Training Loss 0.009786117690317531 	 Validation Loss 0.4163681548088789
INFO:WNN:Epoch 12: Training Loss 0.0029118590173886705 	 Validation Loss 0.29594269720837474
INFO:WNN:Epoch 13: Training Loss 0.005449640477817674 	 Validation Loss 0.17158593970816582
INFO:WNN:Epoch 14: Training Loss 0.001988245563444637 	 Validation Loss 0.18209802429191768
INFO:WNN:Epoch 15: Training Loss 0.002142539044531875 	 Validation Loss 0.06947501155082136
threshold tensor(0.3523, grad_fn=<MulBackward0>)
