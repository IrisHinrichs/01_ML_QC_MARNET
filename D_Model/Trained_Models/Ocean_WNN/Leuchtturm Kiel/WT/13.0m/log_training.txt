INFO:WNN:Epoch 0: Training Loss 0.02678178559349468 	 Validation Loss 0.0019265868604634306
INFO:WNN:Epoch 1: Training Loss 0.007617678466991746 	 Validation Loss 0.001538172859000042
INFO:WNN:Epoch 2: Training Loss 0.003640871666613903 	 Validation Loss 0.0009823812579270452
INFO:WNN:Epoch 3: Training Loss 0.0025789344894391005 	 Validation Loss 0.0008953155456765671
INFO:WNN:Epoch 4: Training Loss 0.002346580010699943 	 Validation Loss 0.0009537686637486331
INFO:WNN:Epoch 5: Training Loss 0.003154613038348952 	 Validation Loss 0.0010628690197336255
INFO:WNN:Epoch 6: Training Loss 0.004746108403182458 	 Validation Loss 0.001550218907141243
INFO:WNN:Epoch 7: Training Loss 0.004986197163703736 	 Validation Loss 0.0021965912928862963
INFO:WNN:Epoch 8: Training Loss 0.004056582890913795 	 Validation Loss 0.001680303001194261
INFO:WNN:Epoch 9: Training Loss 0.003187294649208969 	 Validation Loss 0.0014927288875696831
INFO:WNN:Epoch 10: Training Loss 0.004344653990548356 	 Validation Loss 0.0014623908268731611
INFO:WNN:Epoch 11: Training Loss 0.0044874672445682036 	 Validation Loss 0.003471174670266919
INFO:WNN:Epoch 12: Training Loss 0.0043023322601062645 	 Validation Loss 0.001789868094419944
INFO:WNN:Epoch 13: Training Loss 0.004012193856904687 	 Validation Loss 0.0025883050439006183
INFO:WNN:Epoch 14: Training Loss 0.0022607153659637263 	 Validation Loss 0.002494504318747204
threshold tensor(0.0214, grad_fn=<MulBackward0>)
