INFO:WNN:Epoch 0: Training Loss 0.02559260082077736 	 Validation Loss 0.009779861287825042
INFO:WNN:Epoch 1: Training Loss 0.02805920323578313 	 Validation Loss 0.03570232854690403
INFO:WNN:Epoch 2: Training Loss 0.013290915034577116 	 Validation Loss 0.05164335675362963
INFO:WNN:Epoch 3: Training Loss 0.011867580013354254 	 Validation Loss 0.043174681941309245
INFO:WNN:Epoch 4: Training Loss 0.013570188607068285 	 Validation Loss 0.04778257993893931
INFO:WNN:Epoch 5: Training Loss 0.006626381524022766 	 Validation Loss 0.056892087806772906
INFO:WNN:Epoch 6: Training Loss 0.002369948439858267 	 Validation Loss 0.12090901893679984
INFO:WNN:Epoch 7: Training Loss 0.0032264784250030866 	 Validation Loss 0.1112125079962425
INFO:WNN:Epoch 8: Training Loss 0.005345393095670552 	 Validation Loss 0.12723378775990568
INFO:WNN:Epoch 9: Training Loss 0.0060952100005811135 	 Validation Loss 0.15400277117441874
INFO:WNN:Epoch 10: Training Loss 0.00599178887836093 	 Validation Loss 0.10707914418890141
INFO:WNN:Epoch 11: Training Loss 0.0053584995731783165 	 Validation Loss 0.16149636694171932
threshold tensor(1.0451, grad_fn=<MulBackward0>)
