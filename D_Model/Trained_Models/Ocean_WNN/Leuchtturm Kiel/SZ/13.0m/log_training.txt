INFO:WNN:Epoch 0: Training Loss 0.011238443571675867 	 Validation Loss 0.0004965892030668329
INFO:WNN:Epoch 1: Training Loss 0.001748299588826729 	 Validation Loss 0.0006104322765168035
INFO:WNN:Epoch 2: Training Loss 0.001609765460987388 	 Validation Loss 0.00035160171501047444
INFO:WNN:Epoch 3: Training Loss 0.0015229485808002771 	 Validation Loss 0.00023370946769318834
INFO:WNN:Epoch 4: Training Loss 0.0016531410630144273 	 Validation Loss 0.00023443204179329769
INFO:WNN:Epoch 5: Training Loss 0.0016501445321201345 	 Validation Loss 0.00023292775851757597
INFO:WNN:Epoch 6: Training Loss 0.001615072351924315 	 Validation Loss 0.00024206640745205732
INFO:WNN:Epoch 7: Training Loss 0.0016107121548492769 	 Validation Loss 0.0002686652480861085
INFO:WNN:Epoch 8: Training Loss 0.001538086652375777 	 Validation Loss 0.00023313399708513316
INFO:WNN:Epoch 9: Training Loss 0.0016744599103943258 	 Validation Loss 0.0003042282573915145
INFO:WNN:Epoch 10: Training Loss 0.0015787692595752203 	 Validation Loss 0.0002625223372092478
INFO:WNN:Epoch 11: Training Loss 0.0013347576153356483 	 Validation Loss 0.00020040368644913542
INFO:WNN:Epoch 12: Training Loss 0.0013463707991724207 	 Validation Loss 0.00023497720695786484
INFO:WNN:Epoch 13: Training Loss 0.0013253000650243496 	 Validation Loss 0.0002366717887412051
INFO:WNN:Epoch 14: Training Loss 0.001696057968348239 	 Validation Loss 0.0003009706276770885
INFO:WNN:Epoch 15: Training Loss 0.0017480884243599821 	 Validation Loss 0.0002966708318581368
INFO:WNN:Epoch 16: Training Loss 0.001511641573003936 	 Validation Loss 0.00036475019908266404
INFO:WNN:Epoch 17: Training Loss 0.0018228582437859945 	 Validation Loss 0.0005165410866538878
INFO:WNN:Epoch 18: Training Loss 0.0022055386054755663 	 Validation Loss 0.0004951526776721948
INFO:WNN:Epoch 19: Training Loss 0.0019046233416231382 	 Validation Loss 0.00030605197309796495
INFO:WNN:Epoch 20: Training Loss 0.0011767161895302081 	 Validation Loss 0.00015471402707589732
INFO:WNN:Epoch 21: Training Loss 0.0009340799188758747 	 Validation Loss 0.000298169422421779
INFO:WNN:Epoch 22: Training Loss 0.0011420528257285014 	 Validation Loss 0.0001327257796219783
INFO:WNN:Epoch 23: Training Loss 0.0012285929866596814 	 Validation Loss 0.00012431662457856874
INFO:WNN:Epoch 24: Training Loss 0.0010572394245414055 	 Validation Loss 0.00014904980321261974
INFO:WNN:Epoch 25: Training Loss 0.001038017740841752 	 Validation Loss 0.00028284509903642174
INFO:WNN:Epoch 26: Training Loss 0.0014391481296482345 	 Validation Loss 0.0002897322162311866
INFO:WNN:Epoch 27: Training Loss 0.0017857255201694786 	 Validation Loss 0.0002686686522679338
INFO:WNN:Epoch 28: Training Loss 0.001743877164900681 	 Validation Loss 0.00017230055206596262
INFO:WNN:Epoch 29: Training Loss 0.0014806994738457231 	 Validation Loss 0.00020956686569206795
INFO:WNN:Epoch 30: Training Loss 0.001333189379876404 	 Validation Loss 0.0003027357915925677
INFO:WNN:Epoch 31: Training Loss 0.001617582999006477 	 Validation Loss 0.0003733482208190253
INFO:WNN:Epoch 32: Training Loss 0.0018564138799810758 	 Validation Loss 0.0005549366514969734
INFO:WNN:Epoch 33: Training Loss 0.0025716415153230355 	 Validation Loss 0.00033796991169765533
INFO:WNN:Epoch 34: Training Loss 0.0014039762422672277 	 Validation Loss 0.0004479941395629794
threshold tensor(0.0110, grad_fn=<MulBackward0>)
