INFO:WNN:Epoch 0: Training Loss 0.039657256434461136 	 Validation Loss 0.030773490933435305
INFO:WNN:Epoch 1: Training Loss 0.02344272140180692 	 Validation Loss 0.052067788051707406
INFO:WNN:Epoch 2: Training Loss 0.020500378873503696 	 Validation Loss 0.05950748973659107
INFO:WNN:Epoch 3: Training Loss 0.016204492209138922 	 Validation Loss 0.048825234706912725
INFO:WNN:Epoch 4: Training Loss 0.018237667450403724 	 Validation Loss 0.046153678957905085
INFO:WNN:Epoch 5: Training Loss 0.017556478836922906 	 Validation Loss 0.030833099303500994
INFO:WNN:Epoch 6: Training Loss 0.027460512765033994 	 Validation Loss 0.02745309578520911
INFO:WNN:Epoch 7: Training Loss 0.019148895847488 	 Validation Loss 0.036500178809676855
INFO:WNN:Epoch 8: Training Loss 0.022405599742062174 	 Validation Loss 0.028378804347344806
INFO:WNN:Epoch 9: Training Loss 0.01992421842945847 	 Validation Loss 0.01911889641944851
INFO:WNN:Epoch 10: Training Loss 0.019782036433193404 	 Validation Loss 0.012787925744695323
INFO:WNN:Epoch 11: Training Loss 0.019796327768395152 	 Validation Loss 0.008134561125189066
INFO:WNN:Epoch 12: Training Loss 0.0181272468930379 	 Validation Loss 0.030781241932085583
INFO:WNN:Epoch 13: Training Loss 0.01849194459982055 	 Validation Loss 0.022570353533540453
INFO:WNN:Epoch 14: Training Loss 0.012894405788616635 	 Validation Loss 0.01228747277387551
INFO:WNN:Epoch 15: Training Loss 0.013222407363802912 	 Validation Loss 0.01001677435955831
INFO:WNN:Epoch 16: Training Loss 0.008913365065102251 	 Validation Loss 0.01591795603079455
INFO:WNN:Epoch 17: Training Loss 0.006101848598728583 	 Validation Loss 0.010086516583604472
INFO:WNN:Epoch 18: Training Loss 0.006600958315874987 	 Validation Loss 0.018820760771632195
INFO:WNN:Epoch 19: Training Loss 0.005623928308173513 	 Validation Loss 0.005610472389629909
INFO:WNN:Epoch 20: Training Loss 0.004905155517217981 	 Validation Loss 0.012280497699975967
INFO:WNN:Epoch 21: Training Loss 0.005217235428762461 	 Validation Loss 0.006460478462811027
INFO:WNN:Epoch 22: Training Loss 0.0046579126795292655 	 Validation Loss 0.004646591975220612
INFO:WNN:Epoch 23: Training Loss 0.004810085764312624 	 Validation Loss 0.0018285445902230485
INFO:WNN:Epoch 24: Training Loss 0.0048750661483679255 	 Validation Loss 0.004457138512017471
INFO:WNN:Epoch 25: Training Loss 0.004613946043089247 	 Validation Loss 0.004568497683586819
INFO:WNN:Epoch 26: Training Loss 0.004874185772608213 	 Validation Loss 0.0023759957070329358
INFO:WNN:Epoch 27: Training Loss 0.005467982325311683 	 Validation Loss 0.00366222216481609
INFO:WNN:Epoch 28: Training Loss 0.005343742319102882 	 Validation Loss 0.0019321578687855176
INFO:WNN:Epoch 29: Training Loss 0.007796623866082742 	 Validation Loss 0.019066660265837396
INFO:WNN:Epoch 30: Training Loss 0.00805885726955379 	 Validation Loss 0.006197242964325207
INFO:WNN:Epoch 31: Training Loss 0.010685263989636531 	 Validation Loss 0.017234819808176587
INFO:WNN:Epoch 32: Training Loss 0.010733081884189652 	 Validation Loss 0.010466624051332474
INFO:WNN:Epoch 33: Training Loss 0.009367580342558749 	 Validation Loss 0.010278625679867608
INFO:WNN:Epoch 34: Training Loss 0.009954695041345146 	 Validation Loss 0.014904554733740432
threshold tensor(0.1072, grad_fn=<MulBackward0>)
