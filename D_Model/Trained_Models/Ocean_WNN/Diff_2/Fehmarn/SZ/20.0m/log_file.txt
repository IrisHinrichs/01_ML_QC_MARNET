INFO:WNN:Epoch 0: Training Loss 0.8495025111155378 	 Validation Loss 0.7261783480644226
INFO:WNN:Epoch 1: Training Loss 0.6316383217150966 	 Validation Loss 0.6081164479255676
INFO:WNN:Epoch 2: Training Loss 0.5618192735645506 	 Validation Loss 0.5515879988670349
INFO:WNN:Epoch 3: Training Loss 0.5120236691501405 	 Validation Loss 0.5143522024154663
INFO:WNN:Epoch 4: Training Loss 0.47826342781384784 	 Validation Loss 0.49390506744384766
INFO:WNN:Epoch 5: Training Loss 0.44121157626310986 	 Validation Loss 0.5012838840484619
INFO:WNN:Epoch 6: Training Loss 0.41752490980757606 	 Validation Loss 0.4974823296070099
INFO:WNN:Epoch 7: Training Loss 0.38515879379378426 	 Validation Loss 0.495586097240448
INFO:WNN:Epoch 8: Training Loss 0.36495184815592235 	 Validation Loss 0.49633699655532837
INFO:WNN:Epoch 9: Training Loss 0.3433092658718427 	 Validation Loss 0.5045527815818787
INFO:WNN:Epoch 10: Training Loss 0.3329777220884959 	 Validation Loss 0.5020672082901001
INFO:WNN:Epoch 11: Training Loss 0.3128419584698147 	 Validation Loss 0.5049712657928467
INFO:WNN:Epoch 12: Training Loss 0.31207187804910874 	 Validation Loss 0.5190935730934143
INFO:WNN:Epoch 13: Training Loss 0.3000703967279858 	 Validation Loss 0.5196219086647034
INFO:WNN:Epoch 14: Training Loss 0.2919488681687249 	 Validation Loss 0.5452604293823242
threshold tensor(4.1664, grad_fn=<MulBackward0>)
