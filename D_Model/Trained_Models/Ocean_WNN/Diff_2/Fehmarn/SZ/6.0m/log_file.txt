INFO:WNN:Epoch 0: Training Loss 1.2723079721132915 	 Validation Loss 0.1751980185508728
INFO:WNN:Epoch 1: Training Loss 1.015776554743449 	 Validation Loss 0.15779568254947662
INFO:WNN:Epoch 2: Training Loss 0.8765532573064169 	 Validation Loss 0.16493423283100128
INFO:WNN:Epoch 3: Training Loss 0.7728055119514465 	 Validation Loss 0.20087094604969025
INFO:WNN:Epoch 4: Training Loss 0.6885223984718323 	 Validation Loss 0.223163902759552
INFO:WNN:Epoch 5: Training Loss 0.6146673758824667 	 Validation Loss 0.2331882268190384
INFO:WNN:Epoch 6: Training Loss 0.5439653098583221 	 Validation Loss 0.22225823998451233
INFO:WNN:Epoch 7: Training Loss 0.4800880451997121 	 Validation Loss 0.19255557656288147
INFO:WNN:Epoch 8: Training Loss 0.4266159733136495 	 Validation Loss 0.1619860827922821
INFO:WNN:Epoch 9: Training Loss 0.3807499408721924 	 Validation Loss 0.1410798579454422
INFO:WNN:Epoch 10: Training Loss 0.34027673800786334 	 Validation Loss 0.13404439389705658
INFO:WNN:Epoch 11: Training Loss 0.30455557505289715 	 Validation Loss 0.1357470005750656
INFO:WNN:Epoch 12: Training Loss 0.27181874712308246 	 Validation Loss 0.13699235022068024
INFO:WNN:Epoch 13: Training Loss 0.24352374176184335 	 Validation Loss 0.14052990078926086
INFO:WNN:Epoch 14: Training Loss 0.21829305837551752 	 Validation Loss 0.1469748169183731
INFO:WNN:Epoch 15: Training Loss 0.19676435987154642 	 Validation Loss 0.15200939774513245
INFO:WNN:Epoch 16: Training Loss 0.17950841784477234 	 Validation Loss 0.15460996329784393
INFO:WNN:Epoch 17: Training Loss 0.16461725533008575 	 Validation Loss 0.15483255684375763
INFO:WNN:Epoch 18: Training Loss 0.15298563738663992 	 Validation Loss 0.1526370495557785
INFO:WNN:Epoch 19: Training Loss 0.1431943861146768 	 Validation Loss 0.15129096806049347
INFO:WNN:Epoch 20: Training Loss 0.13344417264064154 	 Validation Loss 0.15205933153629303
threshold tensor(0.8487, grad_fn=<MulBackward0>)
