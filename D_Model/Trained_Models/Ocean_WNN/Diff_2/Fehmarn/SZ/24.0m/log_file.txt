INFO:WNN:Epoch 0: Training Loss 0.9643953740596771 	 Validation Loss 0.36394765973091125
INFO:WNN:Epoch 1: Training Loss 0.8071732372045517 	 Validation Loss 0.3894113600254059
INFO:WNN:Epoch 2: Training Loss 0.7052067369222641 	 Validation Loss 0.4183555543422699
INFO:WNN:Epoch 3: Training Loss 0.6347436755895615 	 Validation Loss 0.421863317489624
INFO:WNN:Epoch 4: Training Loss 0.5713079422712326 	 Validation Loss 0.41968831419944763
INFO:WNN:Epoch 5: Training Loss 0.5157009363174438 	 Validation Loss 0.4041976034641266
INFO:WNN:Epoch 6: Training Loss 0.4585709720849991 	 Validation Loss 0.37958231568336487
INFO:WNN:Epoch 7: Training Loss 0.410717710852623 	 Validation Loss 0.34625089168548584
INFO:WNN:Epoch 8: Training Loss 0.3718740791082382 	 Validation Loss 0.30944421887397766
INFO:WNN:Epoch 9: Training Loss 0.34086496382951736 	 Validation Loss 0.27606436610221863
INFO:WNN:Epoch 10: Training Loss 0.3116137310862541 	 Validation Loss 0.2474541813135147
INFO:WNN:Epoch 11: Training Loss 0.28180697560310364 	 Validation Loss 0.2315678745508194
INFO:WNN:Epoch 12: Training Loss 0.2543400153517723 	 Validation Loss 0.2264365404844284
INFO:WNN:Epoch 13: Training Loss 0.23102114349603653 	 Validation Loss 0.22585570812225342
INFO:WNN:Epoch 14: Training Loss 0.21325789391994476 	 Validation Loss 0.22153322398662567
INFO:WNN:Epoch 15: Training Loss 0.19708582758903503 	 Validation Loss 0.2143830507993698
INFO:WNN:Epoch 16: Training Loss 0.18124452978372574 	 Validation Loss 0.20687727630138397
INFO:WNN:Epoch 17: Training Loss 0.16540254652500153 	 Validation Loss 0.19946004450321198
INFO:WNN:Epoch 18: Training Loss 0.15109702944755554 	 Validation Loss 0.19157277047634125
INFO:WNN:Epoch 19: Training Loss 0.13803384453058243 	 Validation Loss 0.18535791337490082
INFO:WNN:Epoch 20: Training Loss 0.12613407522439957 	 Validation Loss 0.1823229044675827
INFO:WNN:Epoch 21: Training Loss 0.11508116498589516 	 Validation Loss 0.17956866323947906
INFO:WNN:Epoch 22: Training Loss 0.10491689667105675 	 Validation Loss 0.17327876389026642
INFO:WNN:Epoch 23: Training Loss 0.09524257481098175 	 Validation Loss 0.16427357494831085
INFO:WNN:Epoch 24: Training Loss 0.08627615869045258 	 Validation Loss 0.15596766769886017
INFO:WNN:Epoch 25: Training Loss 0.07811406813561916 	 Validation Loss 0.14944256842136383
INFO:WNN:Epoch 26: Training Loss 0.07087279483675957 	 Validation Loss 0.1440816968679428
INFO:WNN:Epoch 27: Training Loss 0.06434779427945614 	 Validation Loss 0.13998931646347046
INFO:WNN:Epoch 28: Training Loss 0.058386292308568954 	 Validation Loss 0.13745583593845367
INFO:WNN:Epoch 29: Training Loss 0.052665370516479015 	 Validation Loss 0.13629500567913055
INFO:WNN:Epoch 30: Training Loss 0.04722082242369652 	 Validation Loss 0.13590435683727264
INFO:WNN:Epoch 31: Training Loss 0.04221601132303476 	 Validation Loss 0.1357891708612442
INFO:WNN:Epoch 32: Training Loss 0.03766237385571003 	 Validation Loss 0.13546495139598846
INFO:WNN:Epoch 33: Training Loss 0.03342353506013751 	 Validation Loss 0.1349036544561386
INFO:WNN:Epoch 34: Training Loss 0.029545610304921865 	 Validation Loss 0.13477462530136108
INFO:WNN:Epoch 35: Training Loss 0.026137383189052343 	 Validation Loss 0.13607245683670044
INFO:WNN:Epoch 36: Training Loss 0.023209371604025364 	 Validation Loss 0.13884733617305756
INFO:WNN:Epoch 37: Training Loss 0.02068695821799338 	 Validation Loss 0.14213575422763824
INFO:WNN:Epoch 38: Training Loss 0.018456985475495458 	 Validation Loss 0.14512091875076294
INFO:WNN:Epoch 39: Training Loss 0.016456092707812786 	 Validation Loss 0.14751771092414856
INFO:WNN:Epoch 40: Training Loss 0.014640047680586576 	 Validation Loss 0.14931495487689972
threshold tensor(0.8650, grad_fn=<MulBackward0>)
