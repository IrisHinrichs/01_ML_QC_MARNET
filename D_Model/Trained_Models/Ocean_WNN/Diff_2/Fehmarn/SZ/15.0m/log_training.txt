INFO:WNN:Epoch 0: Training Loss 0.9096067678928376 	 Validation Loss 0.6323998421430588
INFO:WNN:Epoch 1: Training Loss 0.68288390904665 	 Validation Loss 0.5383236259222031
INFO:WNN:Epoch 2: Training Loss 0.5790507304668426 	 Validation Loss 0.5344901382923126
INFO:WNN:Epoch 3: Training Loss 0.526353742480278 	 Validation Loss 0.5387193262577057
INFO:WNN:Epoch 4: Training Loss 0.4850629258155823 	 Validation Loss 0.5415138900279999
INFO:WNN:Epoch 5: Training Loss 0.4464220455288887 	 Validation Loss 0.5437640845775604
INFO:WNN:Epoch 6: Training Loss 0.41283264368772504 	 Validation Loss 0.546913206577301
INFO:WNN:Epoch 7: Training Loss 0.38560585796833036 	 Validation Loss 0.5510712265968323
INFO:WNN:Epoch 8: Training Loss 0.36387170195579527 	 Validation Loss 0.5576385706663132
INFO:WNN:Epoch 9: Training Loss 0.34361442148685456 	 Validation Loss 0.5715906918048859
INFO:WNN:Epoch 10: Training Loss 0.3190149602293968 	 Validation Loss 0.5848389118909836
INFO:WNN:Epoch 11: Training Loss 0.29459484547376635 	 Validation Loss 0.591193825006485
INFO:WNN:Epoch 12: Training Loss 0.27664468735456466 	 Validation Loss 0.6011625826358795
threshold tensor(5.7657, grad_fn=<MulBackward0>)
