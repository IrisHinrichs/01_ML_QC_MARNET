INFO:WNN:Epoch 0: Training Loss 1.1469976305961609 	 Validation Loss 0.27092278003692627
INFO:WNN:Epoch 1: Training Loss 0.8804507851600647 	 Validation Loss 0.2125544250011444
INFO:WNN:Epoch 2: Training Loss 0.7626606822013855 	 Validation Loss 0.1999024897813797
INFO:WNN:Epoch 3: Training Loss 0.6879986027876536 	 Validation Loss 0.21471929550170898
INFO:WNN:Epoch 4: Training Loss 0.6320773561795553 	 Validation Loss 0.21266064047813416
INFO:WNN:Epoch 5: Training Loss 0.5843321432669958 	 Validation Loss 0.19984965026378632
INFO:WNN:Epoch 6: Training Loss 0.5427641322215399 	 Validation Loss 0.19344556331634521
INFO:WNN:Epoch 7: Training Loss 0.5009070138136545 	 Validation Loss 0.19361825287342072
INFO:WNN:Epoch 8: Training Loss 0.46831708153088886 	 Validation Loss 0.1846262514591217
INFO:WNN:Epoch 9: Training Loss 0.4398072262605031 	 Validation Loss 0.18365420401096344
INFO:WNN:Epoch 10: Training Loss 0.4089716946085294 	 Validation Loss 0.19362258911132812
INFO:WNN:Epoch 11: Training Loss 0.38226545105377835 	 Validation Loss 0.19629164040088654
INFO:WNN:Epoch 12: Training Loss 0.35936230421066284 	 Validation Loss 0.18885238468647003
INFO:WNN:Epoch 13: Training Loss 0.33652176211277646 	 Validation Loss 0.18575820326805115
INFO:WNN:Epoch 14: Training Loss 0.3151754029095173 	 Validation Loss 0.18592679500579834
INFO:WNN:Epoch 15: Training Loss 0.29548799246549606 	 Validation Loss 0.18237559497356415
INFO:WNN:Epoch 16: Training Loss 0.27581528822580975 	 Validation Loss 0.1804991513490677
INFO:WNN:Epoch 17: Training Loss 0.257080780963103 	 Validation Loss 0.18092389404773712
INFO:WNN:Epoch 18: Training Loss 0.2400827861080567 	 Validation Loss 0.1781376600265503
INFO:WNN:Epoch 19: Training Loss 0.22434780560433865 	 Validation Loss 0.17401771247386932
INFO:WNN:Epoch 20: Training Loss 0.20926777366548777 	 Validation Loss 0.17339003086090088
INFO:WNN:Epoch 21: Training Loss 0.19506080518476665 	 Validation Loss 0.1752840131521225
INFO:WNN:Epoch 22: Training Loss 0.18165930709801614 	 Validation Loss 0.17715568840503693
INFO:WNN:Epoch 23: Training Loss 0.16883714275900275 	 Validation Loss 0.1791335493326187
INFO:WNN:Epoch 24: Training Loss 0.1569792607721562 	 Validation Loss 0.18117929995059967
INFO:WNN:Epoch 25: Training Loss 0.14593136108790836 	 Validation Loss 0.1823999136686325
INFO:WNN:Epoch 26: Training Loss 0.13542485877405852 	 Validation Loss 0.18341116607189178
INFO:WNN:Epoch 27: Training Loss 0.12547305084687346 	 Validation Loss 0.18555890023708344
INFO:WNN:Epoch 28: Training Loss 0.11602992999056976 	 Validation Loss 0.18861889839172363
INFO:WNN:Epoch 29: Training Loss 0.10698436674041052 	 Validation Loss 0.19178958237171173
INFO:WNN:Epoch 30: Training Loss 0.09830767256789841 	 Validation Loss 0.19490905106067657
threshold tensor(1.1137, grad_fn=<MulBackward0>)
