INFO:WNN:Epoch 0: Training Loss 0.835144892334938 	 Validation Loss 1.4187190532684326
INFO:WNN:Epoch 1: Training Loss 0.6680107936263084 	 Validation Loss 1.4424631595611572
INFO:WNN:Epoch 2: Training Loss 0.5948594957590103 	 Validation Loss 1.4661835432052612
INFO:WNN:Epoch 3: Training Loss 0.5538294762372971 	 Validation Loss 1.4232442378997803
INFO:WNN:Epoch 4: Training Loss 0.518093965947628 	 Validation Loss 1.3268318176269531
INFO:WNN:Epoch 5: Training Loss 0.4845278933644295 	 Validation Loss 1.2351027727127075
INFO:WNN:Epoch 6: Training Loss 0.4536508060991764 	 Validation Loss 1.1656863689422607
INFO:WNN:Epoch 7: Training Loss 0.42370402067899704 	 Validation Loss 1.111504316329956
INFO:WNN:Epoch 8: Training Loss 0.39520538970828056 	 Validation Loss 1.075947880744934
INFO:WNN:Epoch 9: Training Loss 0.36922093853354454 	 Validation Loss 1.0578309297561646
INFO:WNN:Epoch 10: Training Loss 0.3416878990828991 	 Validation Loss 1.052937626838684
INFO:WNN:Epoch 11: Training Loss 0.3149314671754837 	 Validation Loss 1.0520942211151123
INFO:WNN:Epoch 12: Training Loss 0.28795943409204483 	 Validation Loss 1.060219407081604
INFO:WNN:Epoch 13: Training Loss 0.26305197551846504 	 Validation Loss 1.0812501907348633
INFO:WNN:Epoch 14: Training Loss 0.24186423793435097 	 Validation Loss 1.1063326597213745
INFO:WNN:Epoch 15: Training Loss 0.22346027195453644 	 Validation Loss 1.1341620683670044
INFO:WNN:Epoch 16: Training Loss 0.2066539265215397 	 Validation Loss 1.1653605699539185
INFO:WNN:Epoch 17: Training Loss 0.19161849655210972 	 Validation Loss 1.1957950592041016
INFO:WNN:Epoch 18: Training Loss 0.17842945735901594 	 Validation Loss 1.2253450155258179
INFO:WNN:Epoch 19: Training Loss 0.1659434800967574 	 Validation Loss 1.2580269575119019
threshold tensor(10.0346, grad_fn=<MulBackward0>)
