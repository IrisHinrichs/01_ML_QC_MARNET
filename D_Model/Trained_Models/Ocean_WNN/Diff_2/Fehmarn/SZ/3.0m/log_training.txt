INFO:WNN:Epoch 0: Training Loss 0.7778842708525749 	 Validation Loss 1.9319990873336792
INFO:WNN:Epoch 1: Training Loss 0.6139699058034099 	 Validation Loss 1.828685998916626
INFO:WNN:Epoch 2: Training Loss 0.524259576932169 	 Validation Loss 1.7323753833770752
INFO:WNN:Epoch 3: Training Loss 0.4510002282376473 	 Validation Loss 1.6593080759048462
INFO:WNN:Epoch 4: Training Loss 0.39436123247903127 	 Validation Loss 1.6326286792755127
INFO:WNN:Epoch 5: Training Loss 0.3561275673027222 	 Validation Loss 1.6447553634643555
INFO:WNN:Epoch 6: Training Loss 0.32509287547033566 	 Validation Loss 1.6501516103744507
INFO:WNN:Epoch 7: Training Loss 0.3022820609979905 	 Validation Loss 1.6617438793182373
INFO:WNN:Epoch 8: Training Loss 0.28157757165340275 	 Validation Loss 1.677572250366211
INFO:WNN:Epoch 9: Training Loss 0.2692620808688494 	 Validation Loss 1.6959336996078491
INFO:WNN:Epoch 10: Training Loss 0.2522242463265474 	 Validation Loss 1.7238396406173706
INFO:WNN:Epoch 11: Training Loss 0.2489243043729892 	 Validation Loss 1.7563457489013672
INFO:WNN:Epoch 12: Training Loss 0.23286925858029953 	 Validation Loss 1.791529893875122
INFO:WNN:Epoch 13: Training Loss 0.2329842482621853 	 Validation Loss 1.8255863189697266
INFO:WNN:Epoch 14: Training Loss 0.21479480656293723 	 Validation Loss 1.8467077016830444
INFO:WNN:Epoch 15: Training Loss 0.2138018891788446 	 Validation Loss 1.8826720714569092
threshold tensor(25.8871, grad_fn=<MulBackward0>)
