INFO:WNN:Epoch 0: Training Loss 1.072584718465805 	 Validation Loss 0.018341664224863052
INFO:WNN:Epoch 1: Training Loss 0.8296512365341187 	 Validation Loss 0.030991094186902046
INFO:WNN:Epoch 2: Training Loss 0.715390756726265 	 Validation Loss 0.029612110927700996
INFO:WNN:Epoch 3: Training Loss 0.6389732286334038 	 Validation Loss 0.0212898887693882
INFO:WNN:Epoch 4: Training Loss 0.5685776323080063 	 Validation Loss 0.020277757197618484
INFO:WNN:Epoch 5: Training Loss 0.5118272602558136 	 Validation Loss 0.02008070796728134
INFO:WNN:Epoch 6: Training Loss 0.4608922675251961 	 Validation Loss 0.021597648039460182
INFO:WNN:Epoch 7: Training Loss 0.4111066684126854 	 Validation Loss 0.025317419320344925
INFO:WNN:Epoch 8: Training Loss 0.36391160637140274 	 Validation Loss 0.027298204600811005
INFO:WNN:Epoch 9: Training Loss 0.32069509476423264 	 Validation Loss 0.0283439289778471
INFO:WNN:Epoch 10: Training Loss 0.28322578221559525 	 Validation Loss 0.029672708362340927
INFO:WNN:Epoch 11: Training Loss 0.25129231065511703 	 Validation Loss 0.03214466944336891
threshold tensor(0.2183, grad_fn=<MulBackward0>)
