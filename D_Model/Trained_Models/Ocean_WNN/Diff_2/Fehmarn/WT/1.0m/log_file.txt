INFO:WNN:Epoch 0: Training Loss 1.142916951328516 	 Validation Loss 0.2376357614994049
INFO:WNN:Epoch 1: Training Loss 0.9272470474243164 	 Validation Loss 0.22703905403614044
INFO:WNN:Epoch 2: Training Loss 0.8015835285186768 	 Validation Loss 0.21427799761295319
INFO:WNN:Epoch 3: Training Loss 0.7127262987196445 	 Validation Loss 0.21710887551307678
INFO:WNN:Epoch 4: Training Loss 0.636913612484932 	 Validation Loss 0.22043591737747192
INFO:WNN:Epoch 5: Training Loss 0.566160399466753 	 Validation Loss 0.22309012711048126
INFO:WNN:Epoch 6: Training Loss 0.50312265381217 	 Validation Loss 0.22029897570610046
INFO:WNN:Epoch 7: Training Loss 0.44370268657803535 	 Validation Loss 0.2202991545200348
INFO:WNN:Epoch 8: Training Loss 0.38920629024505615 	 Validation Loss 0.21904918551445007
INFO:WNN:Epoch 9: Training Loss 0.3411441780626774 	 Validation Loss 0.21609599888324738
INFO:WNN:Epoch 10: Training Loss 0.29824014753103256 	 Validation Loss 0.21548576653003693
INFO:WNN:Epoch 11: Training Loss 0.26056292466819286 	 Validation Loss 0.2170594483613968
INFO:WNN:Epoch 12: Training Loss 0.22841141186654568 	 Validation Loss 0.21833138167858124
INFO:WNN:Epoch 13: Training Loss 0.20107751432806253 	 Validation Loss 0.21983833611011505
threshold tensor(2.1812, grad_fn=<MulBackward0>)
