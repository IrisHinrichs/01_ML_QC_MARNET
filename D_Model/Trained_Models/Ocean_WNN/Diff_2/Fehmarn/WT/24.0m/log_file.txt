INFO:WNN:Epoch 0: Training Loss 0.6475267931818962 	 Validation Loss 0.9382794499397278
INFO:WNN:Epoch 1: Training Loss 0.5296673203508059 	 Validation Loss 1.0398682355880737
INFO:WNN:Epoch 2: Training Loss 0.47023177923013765 	 Validation Loss 1.0531376600265503
INFO:WNN:Epoch 3: Training Loss 0.42492454561094445 	 Validation Loss 0.9258599877357483
INFO:WNN:Epoch 4: Training Loss 0.37692721125980216 	 Validation Loss 0.7612259387969971
INFO:WNN:Epoch 5: Training Loss 0.3379193637520075 	 Validation Loss 0.7061494588851929
INFO:WNN:Epoch 6: Training Loss 0.29350533126853406 	 Validation Loss 0.7485283017158508
INFO:WNN:Epoch 7: Training Loss 0.2624264704063535 	 Validation Loss 0.7863599061965942
INFO:WNN:Epoch 8: Training Loss 0.23532117763534188 	 Validation Loss 0.7875673770904541
INFO:WNN:Epoch 9: Training Loss 0.21345436852425337 	 Validation Loss 0.779557466506958
INFO:WNN:Epoch 10: Training Loss 0.1948644348497813 	 Validation Loss 0.7657980918884277
INFO:WNN:Epoch 11: Training Loss 0.17936864673780897 	 Validation Loss 0.7410733699798584
INFO:WNN:Epoch 12: Training Loss 0.16422760067507625 	 Validation Loss 0.7150799632072449
INFO:WNN:Epoch 13: Training Loss 0.15196806006133556 	 Validation Loss 0.6777849197387695
INFO:WNN:Epoch 14: Training Loss 0.14098803357531628 	 Validation Loss 0.6350303888320923
INFO:WNN:Epoch 15: Training Loss 0.13109568075742573 	 Validation Loss 0.6087329983711243
INFO:WNN:Epoch 16: Training Loss 0.12240928213577718 	 Validation Loss 0.5966362357139587
INFO:WNN:Epoch 17: Training Loss 0.11396771661626796 	 Validation Loss 0.5834543704986572
INFO:WNN:Epoch 18: Training Loss 0.10702307863296785 	 Validation Loss 0.559828519821167
INFO:WNN:Epoch 19: Training Loss 0.10113228135742247 	 Validation Loss 0.5397017598152161
INFO:WNN:Epoch 20: Training Loss 0.09560557934067522 	 Validation Loss 0.5290191769599915
INFO:WNN:Epoch 21: Training Loss 0.09076241937388356 	 Validation Loss 0.5108124613761902
INFO:WNN:Epoch 22: Training Loss 0.08595672558294609 	 Validation Loss 0.49802470207214355
INFO:WNN:Epoch 23: Training Loss 0.08137308708683122 	 Validation Loss 0.4998116195201874
INFO:WNN:Epoch 24: Training Loss 0.07731376262381673 	 Validation Loss 0.4987832009792328
INFO:WNN:Epoch 25: Training Loss 0.07354677113956616 	 Validation Loss 0.4998861849308014
INFO:WNN:Epoch 26: Training Loss 0.07000800617970526 	 Validation Loss 0.5022245049476624
INFO:WNN:Epoch 27: Training Loss 0.06654232232055317 	 Validation Loss 0.5048733949661255
INFO:WNN:Epoch 28: Training Loss 0.06331435190319705 	 Validation Loss 0.5039410591125488
INFO:WNN:Epoch 29: Training Loss 0.06016917216281096 	 Validation Loss 0.5008589625358582
INFO:WNN:Epoch 30: Training Loss 0.05719403057203939 	 Validation Loss 0.49800750613212585
INFO:WNN:Epoch 31: Training Loss 0.05425450734522504 	 Validation Loss 0.4933943748474121
INFO:WNN:Epoch 32: Training Loss 0.05153743508465899 	 Validation Loss 0.4906013011932373
INFO:WNN:Epoch 33: Training Loss 0.04912555761014422 	 Validation Loss 0.4930681586265564
threshold tensor(2.5092, grad_fn=<MulBackward0>)
