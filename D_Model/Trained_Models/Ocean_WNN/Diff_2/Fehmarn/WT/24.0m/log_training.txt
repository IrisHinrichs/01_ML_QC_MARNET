INFO:WNN:Epoch 0: Training Loss 0.8134765694073091 	 Validation Loss 0.6488107144832611
INFO:WNN:Epoch 1: Training Loss 0.6496049360786047 	 Validation Loss 0.6156392693519592
INFO:WNN:Epoch 2: Training Loss 0.550211369823147 	 Validation Loss 0.6361382007598877
INFO:WNN:Epoch 3: Training Loss 0.4715404039662745 	 Validation Loss 0.6751395761966705
INFO:WNN:Epoch 4: Training Loss 0.40491799893788993 	 Validation Loss 0.7017393012841543
INFO:WNN:Epoch 5: Training Loss 0.3507894786178238 	 Validation Loss 0.7228241562843323
INFO:WNN:Epoch 6: Training Loss 0.3080925515904609 	 Validation Loss 0.7338045934836069
INFO:WNN:Epoch 7: Training Loss 0.2746313266042206 	 Validation Loss 0.762579987446467
INFO:WNN:Epoch 8: Training Loss 0.24814310301250467 	 Validation Loss 0.7867690324783325
INFO:WNN:Epoch 9: Training Loss 0.22316656882564226 	 Validation Loss 0.8149969180425009
INFO:WNN:Epoch 10: Training Loss 0.21513104143862924 	 Validation Loss 0.8542715112368265
INFO:WNN:Epoch 11: Training Loss 0.20531363090655455 	 Validation Loss 0.8975435793399811
INFO:WNN:Epoch 12: Training Loss 0.20067061858976054 	 Validation Loss 0.8919462462266287
threshold tensor(15.9552, grad_fn=<MulBackward0>)
