INFO:WNN:Epoch 0: Training Loss 0.5120024995671378 	 Validation Loss 2.8060169219970703
INFO:WNN:Epoch 1: Training Loss 0.38182561265097725 	 Validation Loss 2.3416850566864014
INFO:WNN:Epoch 2: Training Loss 0.3246271130111482 	 Validation Loss 1.9914900064468384
INFO:WNN:Epoch 3: Training Loss 0.28935427632596755 	 Validation Loss 1.9923635721206665
INFO:WNN:Epoch 4: Training Loss 0.2696334703101052 	 Validation Loss 1.9165366888046265
INFO:WNN:Epoch 5: Training Loss 0.2523546169201533 	 Validation Loss 1.9184259176254272
INFO:WNN:Epoch 6: Training Loss 0.23791033029556274 	 Validation Loss 1.9063812494277954
INFO:WNN:Epoch 7: Training Loss 0.2233916918436686 	 Validation Loss 1.9526695013046265
INFO:WNN:Epoch 8: Training Loss 0.2111621093418863 	 Validation Loss 1.9764450788497925
INFO:WNN:Epoch 9: Training Loss 0.19894795450899336 	 Validation Loss 2.033086061477661
INFO:WNN:Epoch 10: Training Loss 0.1878912871082624 	 Validation Loss 2.057584285736084
INFO:WNN:Epoch 11: Training Loss 0.17632931388086742 	 Validation Loss 2.099666118621826
INFO:WNN:Epoch 12: Training Loss 0.16647851053211424 	 Validation Loss 2.101391553878784
INFO:WNN:Epoch 13: Training Loss 0.15611599634091058 	 Validation Loss 2.1215343475341797
threshold tensor(19.2919, grad_fn=<MulBackward0>)
