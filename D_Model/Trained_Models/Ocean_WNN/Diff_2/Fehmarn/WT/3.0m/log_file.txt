INFO:WNN:Epoch 0: Training Loss 1.1270354818552732 	 Validation Loss 0.1688464879989624
INFO:WNN:Epoch 1: Training Loss 0.8806113135069609 	 Validation Loss 0.1644599884748459
INFO:WNN:Epoch 2: Training Loss 0.7684199195355177 	 Validation Loss 0.1528295874595642
INFO:WNN:Epoch 3: Training Loss 0.6827209088951349 	 Validation Loss 0.13370662927627563
INFO:WNN:Epoch 4: Training Loss 0.6098874546587467 	 Validation Loss 0.12264291942119598
INFO:WNN:Epoch 5: Training Loss 0.550388865172863 	 Validation Loss 0.12795135378837585
INFO:WNN:Epoch 6: Training Loss 0.49179709888994694 	 Validation Loss 0.13555900752544403
INFO:WNN:Epoch 7: Training Loss 0.44238395243883133 	 Validation Loss 0.1325133591890335
INFO:WNN:Epoch 8: Training Loss 0.39749286603182554 	 Validation Loss 0.13009372353553772
INFO:WNN:Epoch 9: Training Loss 0.3556056618690491 	 Validation Loss 0.13265128433704376
INFO:WNN:Epoch 10: Training Loss 0.316188583150506 	 Validation Loss 0.13300621509552002
INFO:WNN:Epoch 11: Training Loss 0.28235136065632105 	 Validation Loss 0.13405275344848633
INFO:WNN:Epoch 12: Training Loss 0.2532769441604614 	 Validation Loss 0.13819855451583862
INFO:WNN:Epoch 13: Training Loss 0.22859336622059345 	 Validation Loss 0.1441144198179245
INFO:WNN:Epoch 14: Training Loss 0.20817137649282813 	 Validation Loss 0.1490686982870102
INFO:WNN:Epoch 15: Training Loss 0.19011155795305967 	 Validation Loss 0.15513139963150024
threshold tensor(1.6952, grad_fn=<MulBackward0>)
