INFO:WNN:Epoch 0: Training Loss 0.9184439909747906 	 Validation Loss 0.26294827461242676
INFO:WNN:Epoch 1: Training Loss 0.7428373143904738 	 Validation Loss 0.27676755686601
INFO:WNN:Epoch 2: Training Loss 0.6711946056327887 	 Validation Loss 0.26639196773370105
INFO:WNN:Epoch 3: Training Loss 0.6054397277120087 	 Validation Loss 0.2645028879245122
INFO:WNN:Epoch 4: Training Loss 0.5450680323152078 	 Validation Loss 0.26675650974114734
INFO:WNN:Epoch 5: Training Loss 0.47575844907098347 	 Validation Loss 0.2740904937187831
INFO:WNN:Epoch 6: Training Loss 0.40890973940905595 	 Validation Loss 0.2801795353492101
INFO:WNN:Epoch 7: Training Loss 0.35461419655217064 	 Validation Loss 0.28509505093097687
INFO:WNN:Epoch 8: Training Loss 0.3143817883812719 	 Validation Loss 0.27854089935620624
INFO:WNN:Epoch 9: Training Loss 0.28962063923892045 	 Validation Loss 0.27550339698791504
INFO:WNN:Epoch 10: Training Loss 0.2769341882732179 	 Validation Loss 0.2769442896048228
INFO:WNN:Epoch 11: Training Loss 0.2957512450714906 	 Validation Loss 0.2772847016652425
threshold tensor(3.3399, grad_fn=<MulBackward0>)
