INFO:WNN:Epoch 0: Training Loss 1.054230272769928 	 Validation Loss 0.2994420528411865
INFO:WNN:Epoch 1: Training Loss 0.790312871336937 	 Validation Loss 0.3407549262046814
INFO:WNN:Epoch 2: Training Loss 0.6725076362490654 	 Validation Loss 0.3914331793785095
INFO:WNN:Epoch 3: Training Loss 0.5990541987121105 	 Validation Loss 0.36339235305786133
INFO:WNN:Epoch 4: Training Loss 0.5231648404151201 	 Validation Loss 0.28381118178367615
INFO:WNN:Epoch 5: Training Loss 0.45849229022860527 	 Validation Loss 0.22547881305217743
INFO:WNN:Epoch 6: Training Loss 0.40052049048244953 	 Validation Loss 0.2168668508529663
INFO:WNN:Epoch 7: Training Loss 0.3540486805140972 	 Validation Loss 0.23043839633464813
INFO:WNN:Epoch 8: Training Loss 0.3166889641433954 	 Validation Loss 0.2405187040567398
INFO:WNN:Epoch 9: Training Loss 0.2844840195029974 	 Validation Loss 0.2283938229084015
INFO:WNN:Epoch 10: Training Loss 0.2536492180079222 	 Validation Loss 0.21358785033226013
INFO:WNN:Epoch 11: Training Loss 0.2283807573840022 	 Validation Loss 0.21297681331634521
INFO:WNN:Epoch 12: Training Loss 0.2082913825288415 	 Validation Loss 0.21816961467266083
INFO:WNN:Epoch 13: Training Loss 0.19131240295246243 	 Validation Loss 0.22015158832073212
INFO:WNN:Epoch 14: Training Loss 0.177232627524063 	 Validation Loss 0.2212463617324829
INFO:WNN:Epoch 15: Training Loss 0.16665402986109257 	 Validation Loss 0.22781208157539368
INFO:WNN:Epoch 16: Training Loss 0.15780382615048438 	 Validation Loss 0.23611581325531006
INFO:WNN:Epoch 17: Training Loss 0.14954027844942175 	 Validation Loss 0.24106772243976593
INFO:WNN:Epoch 18: Training Loss 0.14260142581770197 	 Validation Loss 0.2427164763212204
INFO:WNN:Epoch 19: Training Loss 0.13660361463553272 	 Validation Loss 0.24611152708530426
INFO:WNN:Epoch 20: Training Loss 0.13099413228337653 	 Validation Loss 0.2498549222946167
INFO:WNN:Epoch 21: Training Loss 0.12623492140846793 	 Validation Loss 0.2511259913444519
threshold tensor(1.5590, grad_fn=<MulBackward0>)
