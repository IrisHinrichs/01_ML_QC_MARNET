INFO:WNN:Epoch 0: Training Loss 1.1824823170900345 	 Validation Loss 0.07672744244337082
INFO:WNN:Epoch 1: Training Loss 0.9256283491849899 	 Validation Loss 0.07602109760046005
INFO:WNN:Epoch 2: Training Loss 0.7997852265834808 	 Validation Loss 0.08056256920099258
INFO:WNN:Epoch 3: Training Loss 0.7000982835888863 	 Validation Loss 0.08215846866369247
INFO:WNN:Epoch 4: Training Loss 0.6120105497539043 	 Validation Loss 0.0830119177699089
INFO:WNN:Epoch 5: Training Loss 0.5369857102632523 	 Validation Loss 0.08303660899400711
INFO:WNN:Epoch 6: Training Loss 0.4745236113667488 	 Validation Loss 0.08297106623649597
INFO:WNN:Epoch 7: Training Loss 0.4184874929487705 	 Validation Loss 0.08317317068576813
INFO:WNN:Epoch 8: Training Loss 0.3655910026282072 	 Validation Loss 0.08245544880628586
INFO:WNN:Epoch 9: Training Loss 0.3204515352845192 	 Validation Loss 0.08007330447435379
INFO:WNN:Epoch 10: Training Loss 0.2831296417862177 	 Validation Loss 0.07967279106378555
INFO:WNN:Epoch 11: Training Loss 0.2527645714581013 	 Validation Loss 0.08088017255067825
threshold tensor(0.4822, grad_fn=<MulBackward0>)
