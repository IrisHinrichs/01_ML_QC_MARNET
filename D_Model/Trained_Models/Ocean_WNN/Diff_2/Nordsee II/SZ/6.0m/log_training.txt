INFO:WNN:Epoch 0: Training Loss 0.9548643212765455 	 Validation Loss 0.4180970620363951
INFO:WNN:Epoch 1: Training Loss 0.7221328495846441 	 Validation Loss 0.3622468998655677
INFO:WNN:Epoch 2: Training Loss 0.6174207844305784 	 Validation Loss 0.3589156623929739
INFO:WNN:Epoch 3: Training Loss 0.5583260390752306 	 Validation Loss 0.35726394690573215
INFO:WNN:Epoch 4: Training Loss 0.5053437608294189 	 Validation Loss 0.36003672052174807
INFO:WNN:Epoch 5: Training Loss 0.4589001721081634 	 Validation Loss 0.3707855297252536
INFO:WNN:Epoch 6: Training Loss 0.4113193588176121 	 Validation Loss 0.38881849963217974
INFO:WNN:Epoch 7: Training Loss 0.37193405255675316 	 Validation Loss 0.4098825650289655
INFO:WNN:Epoch 8: Training Loss 0.3389386418275535 	 Validation Loss 0.4293723860755563
INFO:WNN:Epoch 9: Training Loss 0.31197619166535634 	 Validation Loss 0.44478746224194765
INFO:WNN:Epoch 10: Training Loss 0.2884805597520123 	 Validation Loss 0.45525174867361784
INFO:WNN:Epoch 11: Training Loss 0.2682856540583695 	 Validation Loss 0.463390382938087
INFO:WNN:Epoch 12: Training Loss 0.2519706923825045 	 Validation Loss 0.4702909216284752
threshold tensor(11.5689, grad_fn=<MulBackward0>)
