INFO:WNN:Epoch 0: Training Loss 1.173162579536438 	 Validation Loss 0.4267171621322632
INFO:WNN:Epoch 1: Training Loss 0.908366839090983 	 Validation Loss 0.5297687649726868
INFO:WNN:Epoch 2: Training Loss 0.8893839418888092 	 Validation Loss 0.5230175256729126
INFO:WNN:Epoch 3: Training Loss 0.8393912812074026 	 Validation Loss 0.43336716294288635
INFO:WNN:Epoch 4: Training Loss 0.7810984154542288 	 Validation Loss 0.4011741876602173
INFO:WNN:Epoch 5: Training Loss 0.7410289545853933 	 Validation Loss 0.4313814043998718
INFO:WNN:Epoch 6: Training Loss 0.6939793527126312 	 Validation Loss 0.501095712184906
INFO:WNN:Epoch 7: Training Loss 0.6501620511213938 	 Validation Loss 0.5848895311355591
INFO:WNN:Epoch 8: Training Loss 0.6169721931219101 	 Validation Loss 0.6406431794166565
INFO:WNN:Epoch 9: Training Loss 0.5795052697261175 	 Validation Loss 0.6577737927436829
INFO:WNN:Epoch 10: Training Loss 0.5353284676869711 	 Validation Loss 0.6651367545127869
INFO:WNN:Epoch 11: Training Loss 0.4916899998982747 	 Validation Loss 0.6863516569137573
INFO:WNN:Epoch 12: Training Loss 0.4488822668790817 	 Validation Loss 0.7236512303352356
INFO:WNN:Epoch 13: Training Loss 0.4083981265624364 	 Validation Loss 0.7663027048110962
INFO:WNN:Epoch 14: Training Loss 0.37364382296800613 	 Validation Loss 0.7975687384605408
INFO:WNN:Epoch 15: Training Loss 0.34263771524031955 	 Validation Loss 0.8099534511566162
threshold tensor(4.4698, grad_fn=<MulBackward0>)
