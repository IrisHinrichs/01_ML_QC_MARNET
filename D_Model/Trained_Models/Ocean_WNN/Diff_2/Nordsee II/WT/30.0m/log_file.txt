INFO:WNN:Epoch 0: Training Loss 1.3610087434450786 	 Validation Loss 0.18086546659469604
INFO:WNN:Epoch 1: Training Loss 1.1102513819932938 	 Validation Loss 0.16198691725730896
INFO:WNN:Epoch 2: Training Loss 0.9564540286858877 	 Validation Loss 0.1530107706785202
INFO:WNN:Epoch 3: Training Loss 0.8321097840865453 	 Validation Loss 0.18199577927589417
INFO:WNN:Epoch 4: Training Loss 0.7393870701392492 	 Validation Loss 0.19567786157131195
INFO:WNN:Epoch 5: Training Loss 0.6467663645744324 	 Validation Loss 0.21702447533607483
INFO:WNN:Epoch 6: Training Loss 0.574491411447525 	 Validation Loss 0.24244087934494019
INFO:WNN:Epoch 7: Training Loss 0.5159037758906683 	 Validation Loss 0.27614468336105347
INFO:WNN:Epoch 8: Training Loss 0.46574703852335614 	 Validation Loss 0.29723691940307617
INFO:WNN:Epoch 9: Training Loss 0.4164946675300598 	 Validation Loss 0.31351134181022644
INFO:WNN:Epoch 10: Training Loss 0.37831281622250873 	 Validation Loss 0.3240525424480438
INFO:WNN:Epoch 11: Training Loss 0.34417713185151416 	 Validation Loss 0.3269575834274292
INFO:WNN:Epoch 12: Training Loss 0.31268740197022754 	 Validation Loss 0.31704220175743103
INFO:WNN:Epoch 13: Training Loss 0.28258517881234485 	 Validation Loss 0.3071933090686798
threshold tensor(1.5723, grad_fn=<MulBackward0>)
