INFO:WNN:Epoch 0: Training Loss 0.7298046890646219 	 Validation Loss 0.03210236504673958
INFO:WNN:Epoch 1: Training Loss 0.5509114746625224 	 Validation Loss 0.021489089354872704
INFO:WNN:Epoch 2: Training Loss 0.46659377807130414 	 Validation Loss 0.024322493001818657
INFO:WNN:Epoch 3: Training Loss 0.4110616585239768 	 Validation Loss 0.02780304104089737
INFO:WNN:Epoch 4: Training Loss 0.36474852248405415 	 Validation Loss 0.02777544967830181
INFO:WNN:Epoch 5: Training Loss 0.322089136345312 	 Validation Loss 0.032281555235385895
INFO:WNN:Epoch 6: Training Loss 0.2820874329966803 	 Validation Loss 0.03711019828915596
INFO:WNN:Epoch 7: Training Loss 0.24793573166243732 	 Validation Loss 0.03633476793766022
INFO:WNN:Epoch 8: Training Loss 0.2189993841263155 	 Validation Loss 0.039697907865047455
INFO:WNN:Epoch 9: Training Loss 0.19276734720915556 	 Validation Loss 0.04451954737305641
INFO:WNN:Epoch 10: Training Loss 0.17095543102671704 	 Validation Loss 0.045833032578229904
INFO:WNN:Epoch 11: Training Loss 0.15194360818713903 	 Validation Loss 0.04911511391401291
INFO:WNN:Epoch 12: Training Loss 0.13475707080215216 	 Validation Loss 0.05055063217878342
threshold tensor(0.2232, grad_fn=<MulBackward0>)
