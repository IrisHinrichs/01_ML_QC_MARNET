INFO:WNN:Epoch 0: Training Loss 1.1419449129274912 	 Validation Loss 0.23572161048650742
INFO:WNN:Epoch 1: Training Loss 0.9217053437162013 	 Validation Loss 0.22397633269429207
INFO:WNN:Epoch 2: Training Loss 0.7695404360336917 	 Validation Loss 0.24513224512338638
INFO:WNN:Epoch 3: Training Loss 0.6610096506774426 	 Validation Loss 0.25447483733296394
INFO:WNN:Epoch 4: Training Loss 0.5615035064873242 	 Validation Loss 0.26098305359482765
INFO:WNN:Epoch 5: Training Loss 0.4744801556780225 	 Validation Loss 0.271010085940361
INFO:WNN:Epoch 6: Training Loss 0.4084880082380204 	 Validation Loss 0.2755059488117695
INFO:WNN:Epoch 7: Training Loss 0.3579260352111998 	 Validation Loss 0.2870475910604
INFO:WNN:Epoch 8: Training Loss 0.32002167864924386 	 Validation Loss 0.2956022694706917
INFO:WNN:Epoch 9: Training Loss 0.2863902247377804 	 Validation Loss 0.2944231443107128
INFO:WNN:Epoch 10: Training Loss 0.2536477858111972 	 Validation Loss 0.29112881049513817
INFO:WNN:Epoch 11: Training Loss 0.22528000246910823 	 Validation Loss 0.29471927881240845
threshold tensor(3.8857, grad_fn=<MulBackward0>)
