INFO:WNN:Epoch 0: Training Loss 0.8170567527413368 	 Validation Loss 0.03096598945558071
INFO:WNN:Epoch 1: Training Loss 0.6581150566538175 	 Validation Loss 0.016181819140911102
INFO:WNN:Epoch 2: Training Loss 0.5782100924601158 	 Validation Loss 0.019525613635778427
INFO:WNN:Epoch 3: Training Loss 0.5178121874729792 	 Validation Loss 0.027696115896105766
INFO:WNN:Epoch 4: Training Loss 0.46322119422256947 	 Validation Loss 0.019651001319289207
INFO:WNN:Epoch 5: Training Loss 0.40638736945887405 	 Validation Loss 0.021869705989956856
INFO:WNN:Epoch 6: Training Loss 0.350363381827871 	 Validation Loss 0.030551904812455177
INFO:WNN:Epoch 7: Training Loss 0.29875978641211987 	 Validation Loss 0.028333673253655434
INFO:WNN:Epoch 8: Training Loss 0.2484517345825831 	 Validation Loss 0.029249614104628563
INFO:WNN:Epoch 9: Training Loss 0.20217759472628435 	 Validation Loss 0.03706331551074982
INFO:WNN:Epoch 10: Training Loss 0.1649451603492101 	 Validation Loss 0.03837541118264198
INFO:WNN:Epoch 11: Training Loss 0.1347774857034286 	 Validation Loss 0.03700600191950798
INFO:WNN:Epoch 12: Training Loss 0.10892365624507268 	 Validation Loss 0.041914768517017365
threshold tensor(0.1751, grad_fn=<MulBackward0>)
