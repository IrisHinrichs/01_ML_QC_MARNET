INFO:WNN:Epoch 0: Training Loss 0.9262761473655701 	 Validation Loss 0.5174944996833801
INFO:WNN:Epoch 1: Training Loss 0.7056393793651036 	 Validation Loss 0.42571505904197693
INFO:WNN:Epoch 2: Training Loss 0.5873376727104187 	 Validation Loss 0.3673555850982666
INFO:WNN:Epoch 3: Training Loss 0.5044431218079158 	 Validation Loss 0.3482115566730499
INFO:WNN:Epoch 4: Training Loss 0.44363337755203247 	 Validation Loss 0.33399975299835205
INFO:WNN:Epoch 5: Training Loss 0.39098516532352995 	 Validation Loss 0.312791645526886
INFO:WNN:Epoch 6: Training Loss 0.347559711762837 	 Validation Loss 0.3038625717163086
INFO:WNN:Epoch 7: Training Loss 0.31534835270472933 	 Validation Loss 0.3003365695476532
INFO:WNN:Epoch 8: Training Loss 0.28726276542459217 	 Validation Loss 0.30143919587135315
INFO:WNN:Epoch 9: Training Loss 0.25947216153144836 	 Validation Loss 0.307297945022583
INFO:WNN:Epoch 10: Training Loss 0.23520553963524954 	 Validation Loss 0.3119248151779175
INFO:WNN:Epoch 11: Training Loss 0.21415237018040248 	 Validation Loss 0.3155854642391205
INFO:WNN:Epoch 12: Training Loss 0.19565764335649355 	 Validation Loss 0.3197033703327179
INFO:WNN:Epoch 13: Training Loss 0.1790489038186414 	 Validation Loss 0.32420557737350464
INFO:WNN:Epoch 14: Training Loss 0.16411937853055342 	 Validation Loss 0.3289773464202881
INFO:WNN:Epoch 15: Training Loss 0.1512229469205652 	 Validation Loss 0.3326558768749237
INFO:WNN:Epoch 16: Training Loss 0.14011989826602594 	 Validation Loss 0.33559703826904297
threshold tensor(2.8156, grad_fn=<MulBackward0>)
