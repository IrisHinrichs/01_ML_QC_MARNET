INFO:WNN:Epoch 0: Training Loss 1.130232994755109 	 Validation Loss 0.7532641887664795
INFO:WNN:Epoch 1: Training Loss 0.9367983738581339 	 Validation Loss 0.7963632345199585
INFO:WNN:Epoch 2: Training Loss 0.823149691025416 	 Validation Loss 0.863760232925415
INFO:WNN:Epoch 3: Training Loss 0.7363864878813425 	 Validation Loss 0.9387432336807251
INFO:WNN:Epoch 4: Training Loss 0.6573302497466406 	 Validation Loss 0.9679176807403564
INFO:WNN:Epoch 5: Training Loss 0.5855298986037573 	 Validation Loss 0.9682178497314453
INFO:WNN:Epoch 6: Training Loss 0.514766052365303 	 Validation Loss 0.9445619583129883
INFO:WNN:Epoch 7: Training Loss 0.45494963725407916 	 Validation Loss 0.8915859460830688
INFO:WNN:Epoch 8: Training Loss 0.3961767107248306 	 Validation Loss 0.832153856754303
INFO:WNN:Epoch 9: Training Loss 0.3414054910341899 	 Validation Loss 0.7855672240257263
INFO:WNN:Epoch 10: Training Loss 0.2910756965478261 	 Validation Loss 0.7559251189231873
INFO:WNN:Epoch 11: Training Loss 0.24780062337716421 	 Validation Loss 0.7336609959602356
threshold tensor(4.3699, grad_fn=<MulBackward0>)
