INFO:WNN:Epoch 0: Training Loss 0.7761370142300924 	 Validation Loss 0.7608610987663269
INFO:WNN:Epoch 1: Training Loss 0.5818252824246883 	 Validation Loss 0.6440989971160889
INFO:WNN:Epoch 2: Training Loss 0.5262361206114292 	 Validation Loss 0.5946970582008362
INFO:WNN:Epoch 3: Training Loss 0.485359995936354 	 Validation Loss 0.562667191028595
INFO:WNN:Epoch 4: Training Loss 0.4480813567837079 	 Validation Loss 0.5388725399971008
INFO:WNN:Epoch 5: Training Loss 0.4219925105571747 	 Validation Loss 0.5222033262252808
INFO:WNN:Epoch 6: Training Loss 0.39783281708757084 	 Validation Loss 0.4974712133407593
INFO:WNN:Epoch 7: Training Loss 0.3706509005278349 	 Validation Loss 0.47409045696258545
INFO:WNN:Epoch 8: Training Loss 0.3494359875718753 	 Validation Loss 0.47184720635414124
INFO:WNN:Epoch 9: Training Loss 0.3307504610468944 	 Validation Loss 0.5012221336364746
INFO:WNN:Epoch 10: Training Loss 0.31335602219526965 	 Validation Loss 0.5515206456184387
INFO:WNN:Epoch 11: Training Loss 0.2954594725742936 	 Validation Loss 0.5996512770652771
INFO:WNN:Epoch 12: Training Loss 0.2741175278400381 	 Validation Loss 0.6327986121177673
INFO:WNN:Epoch 13: Training Loss 0.25566780660301447 	 Validation Loss 0.6576796770095825
INFO:WNN:Epoch 14: Training Loss 0.23889303929172456 	 Validation Loss 0.6799684762954712
INFO:WNN:Epoch 15: Training Loss 0.2215626100078225 	 Validation Loss 0.688854455947876
INFO:WNN:Epoch 16: Training Loss 0.2034049577002103 	 Validation Loss 0.6730025410652161
INFO:WNN:Epoch 17: Training Loss 0.1870734435506165 	 Validation Loss 0.6442763805389404
INFO:WNN:Epoch 18: Training Loss 0.17152587851402737 	 Validation Loss 0.6117662191390991
threshold tensor(1.9040, grad_fn=<MulBackward0>)
