INFO:WNN:Epoch 0: Training Loss 0.8379423946142197 	 Validation Loss 0.988610029220581
INFO:WNN:Epoch 1: Training Loss 0.6498775660991669 	 Validation Loss 0.9453876614570618
INFO:WNN:Epoch 2: Training Loss 0.5852137304842472 	 Validation Loss 0.9253012537956238
INFO:WNN:Epoch 3: Training Loss 0.5335277244448662 	 Validation Loss 0.893608033657074
INFO:WNN:Epoch 4: Training Loss 0.47869389727711675 	 Validation Loss 0.8269486427307129
INFO:WNN:Epoch 5: Training Loss 0.4264983911067247 	 Validation Loss 0.7677955627441406
INFO:WNN:Epoch 6: Training Loss 0.38868117425590754 	 Validation Loss 0.7475749850273132
INFO:WNN:Epoch 7: Training Loss 0.350357954762876 	 Validation Loss 0.749377429485321
INFO:WNN:Epoch 8: Training Loss 0.32116298312321306 	 Validation Loss 0.7611269950866699
INFO:WNN:Epoch 9: Training Loss 0.29739269260317086 	 Validation Loss 0.7731612324714661
INFO:WNN:Epoch 10: Training Loss 0.27735569775104524 	 Validation Loss 0.7679416537284851
INFO:WNN:Epoch 11: Training Loss 0.27057555317878723 	 Validation Loss 0.7828027606010437
INFO:WNN:Epoch 12: Training Loss 0.277767676115036 	 Validation Loss 0.7616484761238098
INFO:WNN:Epoch 13: Training Loss 0.26124606728553773 	 Validation Loss 0.7974666953086853
INFO:WNN:Epoch 14: Training Loss 0.2244730442762375 	 Validation Loss 0.779155433177948
INFO:WNN:Epoch 15: Training Loss 0.21992920637130736 	 Validation Loss 0.7622200846672058
INFO:WNN:Epoch 16: Training Loss 0.21878974735736847 	 Validation Loss 0.8005824089050293
threshold tensor(9.3295, grad_fn=<MulBackward0>)
