INFO:WNN:Epoch 0: Training Loss 0.9679100990295411 	 Validation Loss 0.16243742406368256
INFO:WNN:Epoch 1: Training Loss 0.7348830789327622 	 Validation Loss 0.15568973124027252
INFO:WNN:Epoch 2: Training Loss 0.6241155862808228 	 Validation Loss 0.15410731732845306
INFO:WNN:Epoch 3: Training Loss 0.5504642754793168 	 Validation Loss 0.16298775374889374
INFO:WNN:Epoch 4: Training Loss 0.4881014049053192 	 Validation Loss 0.17107993364334106
INFO:WNN:Epoch 5: Training Loss 0.43726941496133803 	 Validation Loss 0.16789604723453522
INFO:WNN:Epoch 6: Training Loss 0.3940914899110794 	 Validation Loss 0.15775294601917267
INFO:WNN:Epoch 7: Training Loss 0.3565028801560402 	 Validation Loss 0.15118110179901123
INFO:WNN:Epoch 8: Training Loss 0.3206931293010712 	 Validation Loss 0.14584556221961975
INFO:WNN:Epoch 9: Training Loss 0.28698930591344834 	 Validation Loss 0.14246875047683716
INFO:WNN:Epoch 10: Training Loss 0.2569382041692734 	 Validation Loss 0.14352953433990479
INFO:WNN:Epoch 11: Training Loss 0.22832368686795235 	 Validation Loss 0.144900843501091
INFO:WNN:Epoch 12: Training Loss 0.20371944457292557 	 Validation Loss 0.14670883119106293
INFO:WNN:Epoch 13: Training Loss 0.18157175853848456 	 Validation Loss 0.1484808772802353
INFO:WNN:Epoch 14: Training Loss 0.16074007004499435 	 Validation Loss 0.1495334953069687
INFO:WNN:Epoch 15: Training Loss 0.14192267432808875 	 Validation Loss 0.1508525013923645
INFO:WNN:Epoch 16: Training Loss 0.12428996786475181 	 Validation Loss 0.15131843090057373
INFO:WNN:Epoch 17: Training Loss 0.1086077805608511 	 Validation Loss 0.1511387676000595
INFO:WNN:Epoch 18: Training Loss 0.09522051587700844 	 Validation Loss 0.1512676477432251
INFO:WNN:Epoch 19: Training Loss 0.08337297216057778 	 Validation Loss 0.15221436321735382
threshold tensor(1.0166, grad_fn=<MulBackward0>)
