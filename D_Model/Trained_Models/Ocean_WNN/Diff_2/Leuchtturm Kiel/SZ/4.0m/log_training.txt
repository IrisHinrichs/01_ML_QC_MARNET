INFO:WNN:Epoch 0: Training Loss 0.857557855967787 	 Validation Loss 0.5604219133965671
INFO:WNN:Epoch 1: Training Loss 0.678720623336082 	 Validation Loss 0.6050209433306009
INFO:WNN:Epoch 2: Training Loss 0.6000674565559223 	 Validation Loss 0.5912421124521643
INFO:WNN:Epoch 3: Training Loss 0.5398162874127073 	 Validation Loss 0.6232041222974658
INFO:WNN:Epoch 4: Training Loss 0.4812474028421714 	 Validation Loss 0.5901888539083302
INFO:WNN:Epoch 5: Training Loss 0.4600813588689244 	 Validation Loss 0.6007449412718415
INFO:WNN:Epoch 6: Training Loss 0.4252031452820769 	 Validation Loss 0.5736245741136372
INFO:WNN:Epoch 7: Training Loss 0.4010836973172864 	 Validation Loss 0.6025489708408713
INFO:WNN:Epoch 8: Training Loss 0.37683826758866273 	 Validation Loss 0.5871982695534825
INFO:WNN:Epoch 9: Training Loss 0.36472278959043913 	 Validation Loss 0.6062840041704476
INFO:WNN:Epoch 10: Training Loss 0.3493933829345873 	 Validation Loss 0.6019216114655137
INFO:WNN:Epoch 11: Training Loss 0.34292164388748386 	 Validation Loss 0.6281700059771538
threshold tensor(8.3880, grad_fn=<MulBackward0>)
