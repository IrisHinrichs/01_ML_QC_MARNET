INFO:WNN:Epoch 0: Training Loss 0.4583457269602352 	 Validation Loss 1.5719873020425439
INFO:WNN:Epoch 1: Training Loss 0.3452765945759084 	 Validation Loss 1.5434038387611508
INFO:WNN:Epoch 2: Training Loss 0.3026541815035873 	 Validation Loss 1.4822237631306052
INFO:WNN:Epoch 3: Training Loss 0.2697105039325025 	 Validation Loss 1.4804107192903757
INFO:WNN:Epoch 4: Training Loss 0.24097747376395595 	 Validation Loss 1.4849840104579926
INFO:WNN:Epoch 5: Training Loss 0.2240038617617554 	 Validation Loss 1.5086295595392585
INFO:WNN:Epoch 6: Training Loss 0.20459949266579416 	 Validation Loss 1.5400413377210498
INFO:WNN:Epoch 7: Training Loss 0.19737574582298598 	 Validation Loss 1.5592713756486773
INFO:WNN:Epoch 8: Training Loss 0.19307859614491463 	 Validation Loss 1.5608002822846174
INFO:WNN:Epoch 9: Training Loss 0.18586604628298017 	 Validation Loss 1.5703548565506935
INFO:WNN:Epoch 10: Training Loss 0.1663315546595388 	 Validation Loss 1.560061814263463
INFO:WNN:Epoch 11: Training Loss 0.1538175514174832 	 Validation Loss 1.5680769495666027
INFO:WNN:Epoch 12: Training Loss 0.15129415835771295 	 Validation Loss 1.5710857808589935
INFO:WNN:Epoch 13: Training Loss 0.1460555876708693 	 Validation Loss 1.5731466840952635
threshold tensor(47.1672, grad_fn=<MulBackward0>)
