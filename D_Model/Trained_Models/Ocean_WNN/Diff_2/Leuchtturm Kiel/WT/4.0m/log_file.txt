INFO:WNN:Epoch 0: Training Loss 0.5322370178559247 	 Validation Loss 2.207374095916748
INFO:WNN:Epoch 1: Training Loss 0.40402454926687126 	 Validation Loss 1.9208933115005493
INFO:WNN:Epoch 2: Training Loss 0.3517239996615578 	 Validation Loss 1.7432750463485718
INFO:WNN:Epoch 3: Training Loss 0.3326507543816286 	 Validation Loss 1.7597209215164185
INFO:WNN:Epoch 4: Training Loss 0.28901494601193595 	 Validation Loss 1.7472411394119263
INFO:WNN:Epoch 5: Training Loss 0.2774684731574619 	 Validation Loss 1.8055521249771118
INFO:WNN:Epoch 6: Training Loss 0.2447256924420157 	 Validation Loss 1.8361436128616333
INFO:WNN:Epoch 7: Training Loss 0.22874807782799883 	 Validation Loss 1.8428875207901
INFO:WNN:Epoch 8: Training Loss 0.21236644367523053 	 Validation Loss 1.872143030166626
INFO:WNN:Epoch 9: Training Loss 0.1986175339997691 	 Validation Loss 1.8884491920471191
INFO:WNN:Epoch 10: Training Loss 0.18939656704006827 	 Validation Loss 1.921086072921753
INFO:WNN:Epoch 11: Training Loss 0.18327374120845513 	 Validation Loss 1.9295905828475952
INFO:WNN:Epoch 12: Training Loss 0.169819192851291 	 Validation Loss 1.950684905052185
INFO:WNN:Epoch 13: Training Loss 0.1705529398339636 	 Validation Loss 1.956231713294983
threshold tensor(19.7604, grad_fn=<MulBackward0>)
