INFO:WNN:Epoch 0: Training Loss 0.822365575070892 	 Validation Loss 0.7345688492059708
INFO:WNN:Epoch 1: Training Loss 0.6969349536276053 	 Validation Loss 0.7355884611606598
INFO:WNN:Epoch 2: Training Loss 0.6530534377883351 	 Validation Loss 0.7481748759746552
INFO:WNN:Epoch 3: Training Loss 0.6111401433627757 	 Validation Loss 0.7414433658123016
INFO:WNN:Epoch 4: Training Loss 0.5671700556718168 	 Validation Loss 0.7414197325706482
INFO:WNN:Epoch 5: Training Loss 0.5226052375658164 	 Validation Loss 0.7482811287045479
INFO:WNN:Epoch 6: Training Loss 0.4796822645834514 	 Validation Loss 0.7650343477725983
INFO:WNN:Epoch 7: Training Loss 0.4435676077292079 	 Validation Loss 0.7909186333417892
INFO:WNN:Epoch 8: Training Loss 0.4144345339801576 	 Validation Loss 0.8056213855743408
INFO:WNN:Epoch 9: Training Loss 0.38851091141502064 	 Validation Loss 0.8216160461306572
INFO:WNN:Epoch 10: Training Loss 0.3663798267879183 	 Validation Loss 0.8360192477703094
INFO:WNN:Epoch 11: Training Loss 0.3470330254899131 	 Validation Loss 0.8527188077569008
threshold tensor(11.5493, grad_fn=<MulBackward0>)
