INFO:WNN:Epoch 0: Training Loss 1.010823417868879 	 Validation Loss 0.2395622581243515
INFO:WNN:Epoch 1: Training Loss 0.8379267611437373 	 Validation Loss 0.23356011509895325
INFO:WNN:Epoch 2: Training Loss 0.7531687406202158 	 Validation Loss 0.23874332010746002
INFO:WNN:Epoch 3: Training Loss 0.6867236000382237 	 Validation Loss 0.2451220452785492
INFO:WNN:Epoch 4: Training Loss 0.6314960707806878 	 Validation Loss 0.25491517782211304
INFO:WNN:Epoch 5: Training Loss 0.5844836953199573 	 Validation Loss 0.2698013484477997
INFO:WNN:Epoch 6: Training Loss 0.5467927328621348 	 Validation Loss 0.2783896327018738
INFO:WNN:Epoch 7: Training Loss 0.5139567056256864 	 Validation Loss 0.2751394510269165
INFO:WNN:Epoch 8: Training Loss 0.48138313999192583 	 Validation Loss 0.2797808349132538
INFO:WNN:Epoch 9: Training Loss 0.44895151138512623 	 Validation Loss 0.298507422208786
INFO:WNN:Epoch 10: Training Loss 0.4211688819858763 	 Validation Loss 0.3092442452907562
INFO:WNN:Epoch 11: Training Loss 0.39946357688556117 	 Validation Loss 0.3055059313774109
threshold tensor(2.1350, grad_fn=<MulBackward0>)
