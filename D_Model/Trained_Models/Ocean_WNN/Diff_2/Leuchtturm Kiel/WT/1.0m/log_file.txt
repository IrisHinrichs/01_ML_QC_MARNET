INFO:WNN:Epoch 0: Training Loss 0.9917152490880754 	 Validation Loss 0.2446811944246292
INFO:WNN:Epoch 1: Training Loss 0.8042577910754416 	 Validation Loss 0.24642765522003174
INFO:WNN:Epoch 2: Training Loss 0.7169855770965418 	 Validation Loss 0.2563805878162384
INFO:WNN:Epoch 3: Training Loss 0.6536112440129122 	 Validation Loss 0.25811800360679626
INFO:WNN:Epoch 4: Training Loss 0.6073570023808215 	 Validation Loss 0.27091896533966064
INFO:WNN:Epoch 5: Training Loss 0.5676144067611959 	 Validation Loss 0.2814287543296814
INFO:WNN:Epoch 6: Training Loss 0.5342262908816338 	 Validation Loss 0.2958710789680481
INFO:WNN:Epoch 7: Training Loss 0.5020347918487258 	 Validation Loss 0.29806289076805115
INFO:WNN:Epoch 8: Training Loss 0.47558674154182273 	 Validation Loss 0.3037935495376587
INFO:WNN:Epoch 9: Training Loss 0.4493954146487845 	 Validation Loss 0.301257848739624
INFO:WNN:Epoch 10: Training Loss 0.426352811873787 	 Validation Loss 0.30237236618995667
INFO:WNN:Epoch 11: Training Loss 0.40490963247915107 	 Validation Loss 0.3012934625148773
threshold tensor(2.6914, grad_fn=<MulBackward0>)
