INFO:WNN:Epoch 0: Training Loss 1.6860017716884612 	 Validation Loss 0.40100744366645813
INFO:WNN:Epoch 1: Training Loss 1.2883801132440567 	 Validation Loss 0.40907275676727295
INFO:WNN:Epoch 2: Training Loss 1.0536062359809875 	 Validation Loss 0.4346025586128235
INFO:WNN:Epoch 3: Training Loss 0.8526912450790405 	 Validation Loss 0.4707660675048828
INFO:WNN:Epoch 4: Training Loss 0.6737400203943252 	 Validation Loss 0.5159702897071838
INFO:WNN:Epoch 5: Training Loss 0.5264624297618866 	 Validation Loss 0.5635213851928711
INFO:WNN:Epoch 6: Training Loss 0.4176305651664734 	 Validation Loss 0.5968635082244873
INFO:WNN:Epoch 7: Training Loss 0.35817926824092866 	 Validation Loss 0.600962221622467
INFO:WNN:Epoch 8: Training Loss 0.3182051360607147 	 Validation Loss 0.5830510854721069
INFO:WNN:Epoch 9: Training Loss 0.27944644540548325 	 Validation Loss 0.559050440788269
INFO:WNN:Epoch 10: Training Loss 0.24738284051418305 	 Validation Loss 0.5343935489654541
INFO:WNN:Epoch 11: Training Loss 0.22320068180561065 	 Validation Loss 0.5107529759407043
threshold tensor(7.0791, grad_fn=<MulBackward0>)
