INFO:WNN:Epoch 0: Training Loss 0.45917416413625084 	 Validation Loss 2.317234516143799
INFO:WNN:Epoch 1: Training Loss 0.3504456194738547 	 Validation Loss 1.9926592111587524
INFO:WNN:Epoch 2: Training Loss 0.3577804264922937 	 Validation Loss 1.7750087976455688
INFO:WNN:Epoch 3: Training Loss 0.2953003842383623 	 Validation Loss 1.7511767148971558
INFO:WNN:Epoch 4: Training Loss 0.24833902530372143 	 Validation Loss 1.726393699645996
INFO:WNN:Epoch 5: Training Loss 0.22291868999600412 	 Validation Loss 1.6138293743133545
INFO:WNN:Epoch 6: Training Loss 0.20245758270223935 	 Validation Loss 1.5731732845306396
INFO:WNN:Epoch 7: Training Loss 0.19596708826720716 	 Validation Loss 1.562367558479309
INFO:WNN:Epoch 8: Training Loss 0.19063753969967365 	 Validation Loss 1.5748541355133057
INFO:WNN:Epoch 9: Training Loss 0.19699519351124764 	 Validation Loss 1.5529730319976807
INFO:WNN:Epoch 10: Training Loss 0.19088402998944123 	 Validation Loss 1.6449238061904907
INFO:WNN:Epoch 11: Training Loss 0.1738613658895095 	 Validation Loss 1.5879392623901367
INFO:WNN:Epoch 12: Training Loss 0.17177141917248567 	 Validation Loss 1.6766247749328613
INFO:WNN:Epoch 13: Training Loss 0.17467754557728768 	 Validation Loss 1.60800039768219
INFO:WNN:Epoch 14: Training Loss 0.19718946566184362 	 Validation Loss 1.755968451499939
INFO:WNN:Epoch 15: Training Loss 0.18228684924542904 	 Validation Loss 1.7320181131362915
INFO:WNN:Epoch 16: Training Loss 0.17487318677206834 	 Validation Loss 1.76248037815094
threshold tensor(13.6022, grad_fn=<MulBackward0>)
