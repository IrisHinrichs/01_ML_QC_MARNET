INFO:WNN:Epoch 0: Training Loss 0.14681585156358778 	 Validation Loss 1.2808781862258911
INFO:WNN:Epoch 1: Training Loss 0.11272522434592247 	 Validation Loss 1.2643064260482788
INFO:WNN:Epoch 2: Training Loss 0.10356739396229386 	 Validation Loss 1.245582938194275
INFO:WNN:Epoch 3: Training Loss 0.0954857292235829 	 Validation Loss 1.2693555355072021
INFO:WNN:Epoch 4: Training Loss 0.09007944416953251 	 Validation Loss 1.300959587097168
INFO:WNN:Epoch 5: Training Loss 0.08545250771567225 	 Validation Loss 1.3193475008010864
INFO:WNN:Epoch 6: Training Loss 0.0813844125950709 	 Validation Loss 1.3010421991348267
INFO:WNN:Epoch 7: Training Loss 0.0780083267018199 	 Validation Loss 1.2438222169876099
INFO:WNN:Epoch 8: Training Loss 0.07440390792908147 	 Validation Loss 1.2048335075378418
INFO:WNN:Epoch 9: Training Loss 0.07323910761624575 	 Validation Loss 1.185223937034607
INFO:WNN:Epoch 10: Training Loss 0.07076401100493968 	 Validation Loss 1.1935938596725464
INFO:WNN:Epoch 11: Training Loss 0.06977460568305105 	 Validation Loss 1.2028075456619263
INFO:WNN:Epoch 12: Training Loss 0.06795792432967573 	 Validation Loss 1.219104290008545
INFO:WNN:Epoch 13: Training Loss 0.06693508510943502 	 Validation Loss 1.2278664112091064
INFO:WNN:Epoch 14: Training Loss 0.06565469322958961 	 Validation Loss 1.2356722354888916
INFO:WNN:Epoch 15: Training Loss 0.06446776143275201 	 Validation Loss 1.2430143356323242
INFO:WNN:Epoch 16: Training Loss 0.0634775769431144 	 Validation Loss 1.2582908868789673
INFO:WNN:Epoch 17: Training Loss 0.06219454971142113 	 Validation Loss 1.2778078317642212
INFO:WNN:Epoch 18: Training Loss 0.061412820767145604 	 Validation Loss 1.3039978742599487
INFO:WNN:Epoch 19: Training Loss 0.060158683510962874 	 Validation Loss 1.3332066535949707
threshold tensor(15.4422, grad_fn=<MulBackward0>)
