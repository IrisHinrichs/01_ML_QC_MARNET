INFO:WNN:Epoch 0: Training Loss 1.1005717049751962 	 Validation Loss 0.2634273370107015
INFO:WNN:Epoch 1: Training Loss 0.8914632136268276 	 Validation Loss 0.21117748816808066
INFO:WNN:Epoch 2: Training Loss 0.718842053519828 	 Validation Loss 0.21195544799168906
INFO:WNN:Epoch 3: Training Loss 0.6081594430974552 	 Validation Loss 0.21550732354323068
INFO:WNN:Epoch 4: Training Loss 0.5122397187565054 	 Validation Loss 0.2218716392914454
INFO:WNN:Epoch 5: Training Loss 0.43709771877952985 	 Validation Loss 0.2224524269501368
INFO:WNN:Epoch 6: Training Loss 0.38292666737522396 	 Validation Loss 0.22717982033888498
INFO:WNN:Epoch 7: Training Loss 0.34467801824212074 	 Validation Loss 0.2271495759487152
INFO:WNN:Epoch 8: Training Loss 0.3256603960480009 	 Validation Loss 0.2353782852490743
INFO:WNN:Epoch 9: Training Loss 0.3280409307352134 	 Validation Loss 0.23278239369392395
INFO:WNN:Epoch 10: Training Loss 0.3284851182784353 	 Validation Loss 0.24675079186757407
INFO:WNN:Epoch 11: Training Loss 0.31809943350298064 	 Validation Loss 0.2427497257788976
INFO:WNN:Epoch 12: Training Loss 0.30489143069301333 	 Validation Loss 0.25196095804373425
threshold tensor(2.3609, grad_fn=<MulBackward0>)
