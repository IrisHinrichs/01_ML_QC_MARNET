INFO:WNN:Epoch 0: Training Loss 1.1675114411239822 	 Validation Loss 0.013484682887792587
INFO:WNN:Epoch 1: Training Loss 0.9435361549258232 	 Validation Loss 0.009829779155552387
INFO:WNN:Epoch 2: Training Loss 0.801200257614255 	 Validation Loss 0.013172461651265621
INFO:WNN:Epoch 3: Training Loss 0.6875306541721026 	 Validation Loss 0.017476249486207962
INFO:WNN:Epoch 4: Training Loss 0.5974727347493172 	 Validation Loss 0.018670588731765747
INFO:WNN:Epoch 5: Training Loss 0.5142113007605076 	 Validation Loss 0.02128155715763569
INFO:WNN:Epoch 6: Training Loss 0.436774973757565 	 Validation Loss 0.019301526248455048
INFO:WNN:Epoch 7: Training Loss 0.36751740518957376 	 Validation Loss 0.01847994700074196
INFO:WNN:Epoch 8: Training Loss 0.30831232015043497 	 Validation Loss 0.017486080527305603
INFO:WNN:Epoch 9: Training Loss 0.26059073644379777 	 Validation Loss 0.016185197979211807
INFO:WNN:Epoch 10: Training Loss 0.22307486118127903 	 Validation Loss 0.015841521322727203
INFO:WNN:Epoch 11: Training Loss 0.1938222236931324 	 Validation Loss 0.014756410382688046
INFO:WNN:Epoch 12: Training Loss 0.16998982398460308 	 Validation Loss 0.014028898440301418
threshold tensor(0.0794, grad_fn=<MulBackward0>)
