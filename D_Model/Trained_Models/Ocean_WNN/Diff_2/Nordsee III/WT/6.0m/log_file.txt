INFO:WNN:Epoch 0: Training Loss 0.9901180160897118 	 Validation Loss 0.18826165795326233
INFO:WNN:Epoch 1: Training Loss 0.7806839538472039 	 Validation Loss 0.21909770369529724
INFO:WNN:Epoch 2: Training Loss 0.6434873363801411 	 Validation Loss 0.2078181803226471
INFO:WNN:Epoch 3: Training Loss 0.5194578138845307 	 Validation Loss 0.17614248394966125
INFO:WNN:Epoch 4: Training Loss 0.42453189407076153 	 Validation Loss 0.16269510984420776
INFO:WNN:Epoch 5: Training Loss 0.36122783592769075 	 Validation Loss 0.15656714141368866
INFO:WNN:Epoch 6: Training Loss 0.313541048339435 	 Validation Loss 0.154217928647995
INFO:WNN:Epoch 7: Training Loss 0.27651646520410267 	 Validation Loss 0.15131227672100067
INFO:WNN:Epoch 8: Training Loss 0.24529411430869782 	 Validation Loss 0.15405668318271637
INFO:WNN:Epoch 9: Training Loss 0.21921536752155849 	 Validation Loss 0.15551142394542694
INFO:WNN:Epoch 10: Training Loss 0.1981136596628598 	 Validation Loss 0.1570061296224594
INFO:WNN:Epoch 11: Training Loss 0.18136407328503473 	 Validation Loss 0.1574312299489975
INFO:WNN:Epoch 12: Training Loss 0.16764780240399496 	 Validation Loss 0.16194775700569153
INFO:WNN:Epoch 13: Training Loss 0.15602819195815495 	 Validation Loss 0.1632547825574875
INFO:WNN:Epoch 14: Training Loss 0.14555118445839202 	 Validation Loss 0.17018228769302368
INFO:WNN:Epoch 15: Training Loss 0.1364142139043127 	 Validation Loss 0.1698957234621048
INFO:WNN:Epoch 16: Training Loss 0.1279464704649789 	 Validation Loss 0.17991861701011658
INFO:WNN:Epoch 17: Training Loss 0.12162911200097629 	 Validation Loss 0.17275159060955048
threshold tensor(1.2042, grad_fn=<MulBackward0>)
