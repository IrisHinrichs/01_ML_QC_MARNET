INFO:WNN:Epoch 0: Training Loss 0.944221074382464 	 Validation Loss 1.4920635223388672
INFO:WNN:Epoch 1: Training Loss 0.7542491058508555 	 Validation Loss 1.478833556175232
INFO:WNN:Epoch 2: Training Loss 0.6307891259590784 	 Validation Loss 1.426827073097229
INFO:WNN:Epoch 3: Training Loss 0.5490546549359957 	 Validation Loss 1.4072699546813965
INFO:WNN:Epoch 4: Training Loss 0.49296830346186954 	 Validation Loss 1.3845100402832031
INFO:WNN:Epoch 5: Training Loss 0.45354407529036206 	 Validation Loss 1.3152199983596802
INFO:WNN:Epoch 6: Training Loss 0.41514140864213306 	 Validation Loss 1.2167507410049438
INFO:WNN:Epoch 7: Training Loss 0.3773800979057948 	 Validation Loss 1.1190166473388672
INFO:WNN:Epoch 8: Training Loss 0.3353376214702924 	 Validation Loss 1.0497550964355469
INFO:WNN:Epoch 9: Training Loss 0.29746123651663464 	 Validation Loss 1.0046805143356323
INFO:WNN:Epoch 10: Training Loss 0.26510914663473767 	 Validation Loss 0.9731380343437195
INFO:WNN:Epoch 11: Training Loss 0.2346425453821818 	 Validation Loss 0.9369975924491882
INFO:WNN:Epoch 12: Training Loss 0.2041690026720365 	 Validation Loss 0.8793186545372009
INFO:WNN:Epoch 13: Training Loss 0.17619172980388006 	 Validation Loss 0.8167405724525452
INFO:WNN:Epoch 14: Training Loss 0.15429971118768057 	 Validation Loss 0.7735932469367981
INFO:WNN:Epoch 15: Training Loss 0.13569518675406775 	 Validation Loss 0.754582405090332
INFO:WNN:Epoch 16: Training Loss 0.1190243015686671 	 Validation Loss 0.7573063969612122
INFO:WNN:Epoch 17: Training Loss 0.10561478075881799 	 Validation Loss 0.7703313827514648
INFO:WNN:Epoch 18: Training Loss 0.0948333836471041 	 Validation Loss 0.7772933840751648
INFO:WNN:Epoch 19: Training Loss 0.0857743186255296 	 Validation Loss 0.7780842781066895
INFO:WNN:Epoch 20: Training Loss 0.07816579658538103 	 Validation Loss 0.7766634821891785
INFO:WNN:Epoch 21: Training Loss 0.07195082477604349 	 Validation Loss 0.7713146209716797
INFO:WNN:Epoch 22: Training Loss 0.06653834568957488 	 Validation Loss 0.7635255455970764
INFO:WNN:Epoch 23: Training Loss 0.06192513927817345 	 Validation Loss 0.7527294158935547
INFO:WNN:Epoch 24: Training Loss 0.05777596488284568 	 Validation Loss 0.7392837405204773
INFO:WNN:Epoch 25: Training Loss 0.054145075070361294 	 Validation Loss 0.7294805645942688
INFO:WNN:Epoch 26: Training Loss 0.05088274856097996 	 Validation Loss 0.7255584597587585
INFO:WNN:Epoch 27: Training Loss 0.047821579656253256 	 Validation Loss 0.7268259525299072
INFO:WNN:Epoch 28: Training Loss 0.04507765612409761 	 Validation Loss 0.7314121127128601
INFO:WNN:Epoch 29: Training Loss 0.042444256910433374 	 Validation Loss 0.7364189624786377
INFO:WNN:Epoch 30: Training Loss 0.039955821043501295 	 Validation Loss 0.742575466632843
INFO:WNN:Epoch 31: Training Loss 0.03755460241033385 	 Validation Loss 0.7496553063392639
INFO:WNN:Epoch 32: Training Loss 0.03524887947908913 	 Validation Loss 0.7568077445030212
INFO:WNN:Epoch 33: Training Loss 0.033082106131284185 	 Validation Loss 0.7645397186279297
INFO:WNN:Epoch 34: Training Loss 0.031053476792294532 	 Validation Loss 0.7726704478263855
INFO:WNN:Epoch 35: Training Loss 0.029139148129615933 	 Validation Loss 0.7814700603485107
INFO:WNN:Epoch 36: Training Loss 0.027344896084590193 	 Validation Loss 0.7903020977973938
threshold tensor(3.4619, grad_fn=<MulBackward0>)
