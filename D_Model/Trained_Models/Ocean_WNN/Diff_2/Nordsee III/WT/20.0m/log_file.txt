INFO:WNN:Epoch 0: Training Loss 0.9736116727193197 	 Validation Loss 0.31790560483932495
INFO:WNN:Epoch 1: Training Loss 0.7234761118888855 	 Validation Loss 0.25194939970970154
INFO:WNN:Epoch 2: Training Loss 0.608256017168363 	 Validation Loss 0.19899357855319977
INFO:WNN:Epoch 3: Training Loss 0.5132408638795217 	 Validation Loss 0.17663845419883728
INFO:WNN:Epoch 4: Training Loss 0.444396011531353 	 Validation Loss 0.17836853861808777
INFO:WNN:Epoch 5: Training Loss 0.3950067882736524 	 Validation Loss 0.1688186079263687
INFO:WNN:Epoch 6: Training Loss 0.35419615109761554 	 Validation Loss 0.15807726979255676
INFO:WNN:Epoch 7: Training Loss 0.31866414844989777 	 Validation Loss 0.15435422956943512
INFO:WNN:Epoch 8: Training Loss 0.28603166590134305 	 Validation Loss 0.1564970165491104
INFO:WNN:Epoch 9: Training Loss 0.25828609491388005 	 Validation Loss 0.15735465288162231
INFO:WNN:Epoch 10: Training Loss 0.23457670460144678 	 Validation Loss 0.15715663135051727
INFO:WNN:Epoch 11: Training Loss 0.21094919244448343 	 Validation Loss 0.15985317528247833
INFO:WNN:Epoch 12: Training Loss 0.18944775064786276 	 Validation Loss 0.15895341336727142
INFO:WNN:Epoch 13: Training Loss 0.16947976127266884 	 Validation Loss 0.1658455729484558
INFO:WNN:Epoch 14: Training Loss 0.149820846815904 	 Validation Loss 0.16377578675746918
INFO:WNN:Epoch 15: Training Loss 0.13155842448274294 	 Validation Loss 0.17632725834846497
INFO:WNN:Epoch 16: Training Loss 0.11420013631383578 	 Validation Loss 0.1693485677242279
INFO:WNN:Epoch 17: Training Loss 0.09884705829123656 	 Validation Loss 0.1893225461244583
threshold tensor(1.6571, grad_fn=<MulBackward0>)
