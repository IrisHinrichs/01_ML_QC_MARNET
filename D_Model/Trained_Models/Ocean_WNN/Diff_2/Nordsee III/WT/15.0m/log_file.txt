INFO:WNN:Epoch 0: Training Loss 1.2110022803147633 	 Validation Loss 0.006708238273859024
INFO:WNN:Epoch 1: Training Loss 0.9863629539807638 	 Validation Loss 0.00376724055968225
INFO:WNN:Epoch 2: Training Loss 0.8665468692779541 	 Validation Loss 0.0034748634789139032
INFO:WNN:Epoch 3: Training Loss 0.7784396708011627 	 Validation Loss 0.005649556405842304
INFO:WNN:Epoch 4: Training Loss 0.7010573744773865 	 Validation Loss 0.004721891600638628
INFO:WNN:Epoch 5: Training Loss 0.6263469060262045 	 Validation Loss 0.005042350385338068
INFO:WNN:Epoch 6: Training Loss 0.5563045342763265 	 Validation Loss 0.006873861886560917
INFO:WNN:Epoch 7: Training Loss 0.4982621371746063 	 Validation Loss 0.00688560726121068
INFO:WNN:Epoch 8: Training Loss 0.4524789055188497 	 Validation Loss 0.008552991785109043
INFO:WNN:Epoch 9: Training Loss 0.41462066769599915 	 Validation Loss 0.012582821771502495
INFO:WNN:Epoch 10: Training Loss 0.37790432572364807 	 Validation Loss 0.014173861593008041
INFO:WNN:Epoch 11: Training Loss 0.3376062909762065 	 Validation Loss 0.015119271352887154
INFO:WNN:Epoch 12: Training Loss 0.29893653591473895 	 Validation Loss 0.017183221876621246
INFO:WNN:Epoch 13: Training Loss 0.26601434747378033 	 Validation Loss 0.017023567110300064
threshold tensor(0.1129, grad_fn=<MulBackward0>)
