INFO:WNN:Epoch 0: Training Loss 1.01787069439888 	 Validation Loss 0.07547106593847275
INFO:WNN:Epoch 1: Training Loss 0.880362331867218 	 Validation Loss 0.05628615990281105
INFO:WNN:Epoch 2: Training Loss 0.7938799858093262 	 Validation Loss 0.08471130579710007
INFO:WNN:Epoch 3: Training Loss 0.74186772108078 	 Validation Loss 0.09618312865495682
INFO:WNN:Epoch 4: Training Loss 0.6901824474334717 	 Validation Loss 0.11196364462375641
INFO:WNN:Epoch 5: Training Loss 0.6449854522943497 	 Validation Loss 0.10946056246757507
INFO:WNN:Epoch 6: Training Loss 0.5926901549100876 	 Validation Loss 0.1075059249997139
INFO:WNN:Epoch 7: Training Loss 0.5511958748102188 	 Validation Loss 0.11108025163412094
INFO:WNN:Epoch 8: Training Loss 0.5138678252696991 	 Validation Loss 0.10928166657686234
INFO:WNN:Epoch 9: Training Loss 0.4745677411556244 	 Validation Loss 0.1141764372587204
INFO:WNN:Epoch 10: Training Loss 0.44108518958091736 	 Validation Loss 0.123245470225811
INFO:WNN:Epoch 11: Training Loss 0.41046008467674255 	 Validation Loss 0.13577373325824738
INFO:WNN:Epoch 12: Training Loss 0.3844001889228821 	 Validation Loss 0.1476902961730957
threshold tensor(0.6785, grad_fn=<MulBackward0>)
