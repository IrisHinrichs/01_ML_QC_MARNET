INFO:WNN:Epoch 0: Training Loss 0.9484625319285053 	 Validation Loss 1.292192240556081
INFO:WNN:Epoch 1: Training Loss 0.8262796802712339 	 Validation Loss 1.1258296966552734
INFO:WNN:Epoch 2: Training Loss 0.808520475721785 	 Validation Loss 1.1120279431343079
INFO:WNN:Epoch 3: Training Loss 0.7500903382365193 	 Validation Loss 1.0931472778320312
INFO:WNN:Epoch 4: Training Loss 0.728490237519145 	 Validation Loss 1.0765742262204487
INFO:WNN:Epoch 5: Training Loss 0.6732976751668113 	 Validation Loss 1.0849148631095886
INFO:WNN:Epoch 6: Training Loss 0.6883861967495509 	 Validation Loss 1.1167869567871094
INFO:WNN:Epoch 7: Training Loss 0.6914869346256767 	 Validation Loss 1.1004169980684917
INFO:WNN:Epoch 8: Training Loss 0.6807678789964744 	 Validation Loss 1.0940162340799968
INFO:WNN:Epoch 9: Training Loss 0.633536876312324 	 Validation Loss 1.1269290645917256
INFO:WNN:Epoch 10: Training Loss 0.6102401828127247 	 Validation Loss 1.166626771291097
INFO:WNN:Epoch 11: Training Loss 0.5805201486817428 	 Validation Loss 1.1772431929906209
INFO:WNN:Epoch 12: Training Loss 0.56974009594747 	 Validation Loss 1.1638381878534954
threshold tensor(9.3497, grad_fn=<MulBackward0>)
