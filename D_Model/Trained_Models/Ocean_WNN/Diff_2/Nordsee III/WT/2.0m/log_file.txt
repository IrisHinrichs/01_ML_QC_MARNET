INFO:WNN:Epoch 0: Training Loss 0.8643971731265386 	 Validation Loss 0.4828997254371643
INFO:WNN:Epoch 1: Training Loss 0.6546960064520438 	 Validation Loss 0.40579965710639954
INFO:WNN:Epoch 2: Training Loss 0.564410300552845 	 Validation Loss 0.35950490832328796
INFO:WNN:Epoch 3: Training Loss 0.48785939036558074 	 Validation Loss 0.3402920365333557
INFO:WNN:Epoch 4: Training Loss 0.43277315435310204 	 Validation Loss 0.33189141750335693
INFO:WNN:Epoch 5: Training Loss 0.381481299487253 	 Validation Loss 0.3278912901878357
INFO:WNN:Epoch 6: Training Loss 0.33883011850217976 	 Validation Loss 0.3300708532333374
INFO:WNN:Epoch 7: Training Loss 0.3038396442929904 	 Validation Loss 0.3353125751018524
INFO:WNN:Epoch 8: Training Loss 0.2750603736688693 	 Validation Loss 0.3433343768119812
INFO:WNN:Epoch 9: Training Loss 0.25059148160119854 	 Validation Loss 0.3510891795158386
INFO:WNN:Epoch 10: Training Loss 0.22945335805416106 	 Validation Loss 0.3529709577560425
INFO:WNN:Epoch 11: Training Loss 0.20997034336129825 	 Validation Loss 0.35691037774086
INFO:WNN:Epoch 12: Training Loss 0.19142204150557518 	 Validation Loss 0.3671804368495941
INFO:WNN:Epoch 13: Training Loss 0.17395467292517425 	 Validation Loss 0.3741222023963928
INFO:WNN:Epoch 14: Training Loss 0.15950558421512445 	 Validation Loss 0.37765413522720337
threshold tensor(3.9778, grad_fn=<MulBackward0>)
