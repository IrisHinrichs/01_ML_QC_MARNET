INFO:WNN:Epoch 0: Training Loss 1.0837435428984463 	 Validation Loss 0.5650768280029297
INFO:WNN:Epoch 1: Training Loss 0.8796897763386369 	 Validation Loss 0.5367237329483032
INFO:WNN:Epoch 2: Training Loss 0.7750630890950561 	 Validation Loss 0.5614254474639893
INFO:WNN:Epoch 3: Training Loss 0.7045135824009776 	 Validation Loss 0.5908365249633789
INFO:WNN:Epoch 4: Training Loss 0.6417515031062067 	 Validation Loss 0.5490685105323792
INFO:WNN:Epoch 5: Training Loss 0.5870428588241339 	 Validation Loss 0.46472930908203125
INFO:WNN:Epoch 6: Training Loss 0.5386804488953203 	 Validation Loss 0.4145044684410095
INFO:WNN:Epoch 7: Training Loss 0.49223376577720046 	 Validation Loss 0.3936854898929596
INFO:WNN:Epoch 8: Training Loss 0.44662648683879524 	 Validation Loss 0.39038094878196716
INFO:WNN:Epoch 9: Training Loss 0.4053374994546175 	 Validation Loss 0.4037630558013916
INFO:WNN:Epoch 10: Training Loss 0.38080036640167236 	 Validation Loss 0.4205833077430725
INFO:WNN:Epoch 11: Training Loss 0.4164977658074349 	 Validation Loss 0.41428256034851074
INFO:WNN:Epoch 12: Training Loss 0.4612804453354329 	 Validation Loss 0.4500870704650879
INFO:WNN:Epoch 13: Training Loss 0.355224919738248 	 Validation Loss 0.4943523108959198
INFO:WNN:Epoch 14: Training Loss 0.31092399870976806 	 Validation Loss 0.4006173312664032
INFO:WNN:Epoch 15: Training Loss 0.27763839857652783 	 Validation Loss 0.4416079521179199
INFO:WNN:Epoch 16: Training Loss 0.24892495572566986 	 Validation Loss 0.4602298438549042
INFO:WNN:Epoch 17: Training Loss 0.2455782489851117 	 Validation Loss 0.4354230761528015
INFO:WNN:Epoch 18: Training Loss 0.22449971176683903 	 Validation Loss 0.4791371524333954
threshold tensor(2.9506, grad_fn=<MulBackward0>)
