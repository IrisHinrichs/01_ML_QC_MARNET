INFO:WNN:Epoch 0: Training Loss 0.34427957878159804 	 Validation Loss 0.0704268217086792
INFO:WNN:Epoch 1: Training Loss 0.7781249772579897 	 Validation Loss 1.1546894013881683
INFO:WNN:Epoch 2: Training Loss 0.32555314655681805 	 Validation Loss 0.182228222489357
INFO:WNN:Epoch 3: Training Loss 0.12388040415992561 	 Validation Loss 0.46200475096702576
INFO:WNN:Epoch 4: Training Loss 0.19923285352775738 	 Validation Loss 0.08080034703016281
INFO:WNN:Epoch 5: Training Loss 0.09471485905704044 	 Validation Loss 0.5721170380711555
INFO:WNN:Epoch 6: Training Loss 0.3767572386811177 	 Validation Loss 0.5095837116241455
INFO:WNN:Epoch 7: Training Loss 0.17778334314824037 	 Validation Loss 0.05430791713297367
INFO:WNN:Epoch 8: Training Loss 0.07732211547859368 	 Validation Loss 0.04851941019296646
INFO:WNN:Epoch 9: Training Loss 0.15472380421678758 	 Validation Loss 0.18118901550769806
INFO:WNN:Epoch 10: Training Loss 0.14813432826555245 	 Validation Loss 0.10884688422083855
INFO:WNN:Epoch 11: Training Loss 0.17471124245119946 	 Validation Loss 0.2376057244837284
INFO:WNN:Epoch 12: Training Loss 0.31158522041958003 	 Validation Loss 0.7512694001197815
INFO:WNN:Epoch 13: Training Loss 0.3083390570245683 	 Validation Loss 0.3127816282212734
INFO:WNN:Epoch 14: Training Loss 0.2513330153832656 	 Validation Loss 0.8022589385509491
INFO:WNN:Epoch 15: Training Loss 0.3677086417031075 	 Validation Loss 1.1513672173023224
INFO:WNN:Epoch 16: Training Loss 0.41429172711269485 	 Validation Loss 0.24634286388754845
INFO:WNN:Epoch 17: Training Loss 0.20286830018934174 	 Validation Loss 0.5505548901855946
INFO:WNN:Epoch 18: Training Loss 0.2279012488877578 	 Validation Loss 0.48792628198862076
INFO:WNN:Epoch 19: Training Loss 0.2077888106882927 	 Validation Loss 0.8252629339694977
threshold tensor(1.6496, grad_fn=<MulBackward0>)
