INFO:WNN:Epoch 0: Training Loss 0.2593009643460391 	 Validation Loss 0.9712680876255035
INFO:WNN:Epoch 1: Training Loss 0.35204964908916736 	 Validation Loss 1.1068707406520844
INFO:WNN:Epoch 2: Training Loss 0.38471949932863936 	 Validation Loss 3.5274274349212646
INFO:WNN:Epoch 3: Training Loss 0.16555812697697547 	 Validation Loss 1.7974791526794434
INFO:WNN:Epoch 4: Training Loss 0.10754138611688784 	 Validation Loss 1.4765099883079529
INFO:WNN:Epoch 5: Training Loss 0.029772604845978396 	 Validation Loss 1.205468863248825
INFO:WNN:Epoch 6: Training Loss 0.013961307626838485 	 Validation Loss 0.3701883926987648
INFO:WNN:Epoch 7: Training Loss 0.022685695759719238 	 Validation Loss 0.7486534118652344
INFO:WNN:Epoch 8: Training Loss 0.01414038227085257 	 Validation Loss 0.34605786949396133
INFO:WNN:Epoch 9: Training Loss 0.02287294041889254 	 Validation Loss 0.6864261627197266
INFO:WNN:Epoch 10: Training Loss 0.012912793516685875 	 Validation Loss 0.25741933286190033
INFO:WNN:Epoch 11: Training Loss 0.020696273165716168 	 Validation Loss 0.4852291941642761
INFO:WNN:Epoch 12: Training Loss 0.021540301032170344 	 Validation Loss 0.47983577847480774
INFO:WNN:Epoch 13: Training Loss 0.047698952029653206 	 Validation Loss 0.8739955574274063
INFO:WNN:Epoch 14: Training Loss 0.07794397780162399 	 Validation Loss 0.5252450704574585
INFO:WNN:Epoch 15: Training Loss 0.17510174289539768 	 Validation Loss 0.894823431968689
INFO:WNN:Epoch 16: Training Loss 0.21026889362534953 	 Validation Loss 0.4683753401041031
INFO:WNN:Epoch 17: Training Loss 0.13203111518911706 	 Validation Loss 0.8809468895196915
INFO:WNN:Epoch 18: Training Loss 0.045165013393367794 	 Validation Loss 0.24169839918613434
INFO:WNN:Epoch 19: Training Loss 0.021126396110048518 	 Validation Loss 0.16934342682361603
INFO:WNN:Epoch 20: Training Loss 0.04698006727024525 	 Validation Loss 0.5396818667650223
INFO:WNN:Epoch 21: Training Loss 0.031390232926545046 	 Validation Loss 0.588614359498024
INFO:WNN:Epoch 22: Training Loss 0.05836668308378042 	 Validation Loss 0.9798668026924133
INFO:WNN:Epoch 23: Training Loss 0.05260303658724297 	 Validation Loss 0.8132924437522888
INFO:WNN:Epoch 24: Training Loss 0.043075655528809875 	 Validation Loss 0.14822790026664734
INFO:WNN:Epoch 25: Training Loss 0.03667111160272422 	 Validation Loss 0.9486351311206818
INFO:WNN:Epoch 26: Training Loss 0.06703041929479998 	 Validation Loss 1.739770233631134
INFO:WNN:Epoch 27: Training Loss 0.09612043615197763 	 Validation Loss 0.39394164085388184
INFO:WNN:Epoch 28: Training Loss 0.2159077137184795 	 Validation Loss 0.7804494053125381
INFO:WNN:Epoch 29: Training Loss 0.19509330108606568 	 Validation Loss 0.6728445738554001
INFO:WNN:Epoch 30: Training Loss 0.20112280324489498 	 Validation Loss 0.828429326415062
INFO:WNN:Epoch 31: Training Loss 0.2535677886335179 	 Validation Loss 0.8037627339363098
INFO:WNN:Epoch 32: Training Loss 0.41143822741287295 	 Validation Loss 0.8559491634368896
INFO:WNN:Epoch 33: Training Loss 0.4506666675770248 	 Validation Loss 1.3621723353862762
INFO:WNN:Epoch 34: Training Loss 0.4722630986943841 	 Validation Loss 1.1387555599212646
INFO:WNN:Epoch 35: Training Loss 0.3522477971976817 	 Validation Loss 3.186479330062866
threshold tensor(6.4330, grad_fn=<MulBackward0>)
