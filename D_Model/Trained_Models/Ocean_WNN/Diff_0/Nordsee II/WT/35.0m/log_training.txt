INFO:WNN:Epoch 0: Training Loss 0.3413774057879068 	 Validation Loss 0.07618172466754913
INFO:WNN:Epoch 1: Training Loss 0.801457000985032 	 Validation Loss 1.2205209732055664
INFO:WNN:Epoch 2: Training Loss 0.4038373796169513 	 Validation Loss 0.20990185905247927
INFO:WNN:Epoch 3: Training Loss 0.2131904501043859 	 Validation Loss 0.5961938351392746
INFO:WNN:Epoch 4: Training Loss 0.3163527269914214 	 Validation Loss 0.14058619365096092
INFO:WNN:Epoch 5: Training Loss 0.21739708435987787 	 Validation Loss 0.9543082416057587
INFO:WNN:Epoch 6: Training Loss 0.6308870517116573 	 Validation Loss 0.2632116377353668
INFO:WNN:Epoch 7: Training Loss 0.3778996543426599 	 Validation Loss 0.08696519210934639
INFO:WNN:Epoch 8: Training Loss 0.5046159023463371 	 Validation Loss 1.0044505596160889
INFO:WNN:Epoch 9: Training Loss 0.36521698867103886 	 Validation Loss 1.2315584272146225
INFO:WNN:Epoch 10: Training Loss 0.2782758585443454 	 Validation Loss 0.9998141303658485
INFO:WNN:Epoch 11: Training Loss 0.42520344055568177 	 Validation Loss 1.5277474522590637
threshold tensor(2.3169, grad_fn=<MulBackward0>)
