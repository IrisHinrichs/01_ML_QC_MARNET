INFO:WNN:Epoch 0: Training Loss 0.5000210681131908 	 Validation Loss 0.08501452952623367
INFO:WNN:Epoch 1: Training Loss 0.17385159113577434 	 Validation Loss 0.03340993449091911
INFO:WNN:Epoch 2: Training Loss 0.4060223871575935 	 Validation Loss 0.13116005063056946
INFO:WNN:Epoch 3: Training Loss 0.38214732573500704 	 Validation Loss 0.5198082327842712
INFO:WNN:Epoch 4: Training Loss 0.29026871187878506 	 Validation Loss 0.1422141194343567
INFO:WNN:Epoch 5: Training Loss 0.08934929647615977 	 Validation Loss 0.2023882120847702
INFO:WNN:Epoch 6: Training Loss 0.06357256768803511 	 Validation Loss 0.026800382882356644
INFO:WNN:Epoch 7: Training Loss 0.06048887675361974 	 Validation Loss 0.05695684254169464
INFO:WNN:Epoch 8: Training Loss 0.0634387047695262 	 Validation Loss 0.03212551027536392
INFO:WNN:Epoch 9: Training Loss 0.05789680180272886 	 Validation Loss 0.0243533868342638
INFO:WNN:Epoch 10: Training Loss 0.10455883853137493 	 Validation Loss 0.09973207116127014
INFO:WNN:Epoch 11: Training Loss 0.2395598292350769 	 Validation Loss 0.13705958425998688
INFO:WNN:Epoch 12: Training Loss 0.15419448632746935 	 Validation Loss 0.14995840191841125
INFO:WNN:Epoch 13: Training Loss 0.10933054903788227 	 Validation Loss 0.05999632179737091
INFO:WNN:Epoch 14: Training Loss 0.14665640059060284 	 Validation Loss 0.057956237345933914
INFO:WNN:Epoch 15: Training Loss 0.12386915925890207 	 Validation Loss 0.1303589940071106
INFO:WNN:Epoch 16: Training Loss 0.09892236082149404 	 Validation Loss 0.03332505747675896
INFO:WNN:Epoch 17: Training Loss 0.08109407499432564 	 Validation Loss 0.042014364153146744
INFO:WNN:Epoch 18: Training Loss 0.08275411118354116 	 Validation Loss 0.0631757602095604
INFO:WNN:Epoch 19: Training Loss 0.15799937131149427 	 Validation Loss 0.09386036545038223
INFO:WNN:Epoch 20: Training Loss 0.12049880543989795 	 Validation Loss 0.09833649545907974
threshold tensor(0.5704, grad_fn=<MulBackward0>)
