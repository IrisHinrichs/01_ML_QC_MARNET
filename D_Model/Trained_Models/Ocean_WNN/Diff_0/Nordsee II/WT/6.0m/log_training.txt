INFO:WNN:Epoch 0: Training Loss 0.5000210659844535 	 Validation Loss 0.08501452207565308
INFO:WNN:Epoch 1: Training Loss 0.17385160710130418 	 Validation Loss 0.03340994194149971
INFO:WNN:Epoch 2: Training Loss 0.4060224225478513 	 Validation Loss 0.13116005063056946
INFO:WNN:Epoch 3: Training Loss 0.38214730976947714 	 Validation Loss 0.5198082327842712
INFO:WNN:Epoch 4: Training Loss 0.2902687130761998 	 Validation Loss 0.1422140747308731
INFO:WNN:Epoch 5: Training Loss 0.08934930073363441 	 Validation Loss 0.20238815248012543
INFO:WNN:Epoch 6: Training Loss 0.06357257700126086 	 Validation Loss 0.0268003698438406
INFO:WNN:Epoch 7: Training Loss 0.06048891320824623 	 Validation Loss 0.056956950575113297
INFO:WNN:Epoch 8: Training Loss 0.06343875253306967 	 Validation Loss 0.03212553262710571
INFO:WNN:Epoch 9: Training Loss 0.057896778652710576 	 Validation Loss 0.024353396147489548
INFO:WNN:Epoch 10: Training Loss 0.1045589464317475 	 Validation Loss 0.09973223507404327
INFO:WNN:Epoch 11: Training Loss 0.2395604345947504 	 Validation Loss 0.13705973327159882
INFO:WNN:Epoch 12: Training Loss 0.154194780758449 	 Validation Loss 0.14995843172073364
INFO:WNN:Epoch 13: Training Loss 0.10933075060269662 	 Validation Loss 0.05999671295285225
INFO:WNN:Epoch 14: Training Loss 0.14665664998548372 	 Validation Loss 0.057954784482717514
INFO:WNN:Epoch 15: Training Loss 0.12387190060690045 	 Validation Loss 0.13035760819911957
INFO:WNN:Epoch 16: Training Loss 0.09892459998705558 	 Validation Loss 0.033326178789138794
INFO:WNN:Epoch 17: Training Loss 0.08109522118632283 	 Validation Loss 0.04201629012823105
INFO:WNN:Epoch 18: Training Loss 0.08275409269013576 	 Validation Loss 0.06317649781703949
INFO:WNN:Epoch 19: Training Loss 0.15799486124888062 	 Validation Loss 0.09385967254638672
INFO:WNN:Epoch 20: Training Loss 0.12049797203923975 	 Validation Loss 0.09832961857318878
threshold tensor(0.5704, grad_fn=<MulBackward0>)
