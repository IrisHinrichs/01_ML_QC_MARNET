INFO:WNN:Epoch 0: Training Loss 0.9603391041358312 	 Validation Loss 0.045845936983823776
INFO:WNN:Epoch 1: Training Loss 0.4987724497914314 	 Validation Loss 0.27614736557006836
INFO:WNN:Epoch 2: Training Loss 0.5400853306055069 	 Validation Loss 0.26734939217567444
INFO:WNN:Epoch 3: Training Loss 0.4049820763369401 	 Validation Loss 0.11945632845163345
INFO:WNN:Epoch 4: Training Loss 0.357110067581137 	 Validation Loss 0.04584987089037895
INFO:WNN:Epoch 5: Training Loss 0.3679482191801071 	 Validation Loss 0.044278811663389206
INFO:WNN:Epoch 6: Training Loss 0.3274011475344499 	 Validation Loss 0.08782088756561279
INFO:WNN:Epoch 7: Training Loss 0.2886271613339583 	 Validation Loss 0.13968849182128906
INFO:WNN:Epoch 8: Training Loss 0.2822944223880768 	 Validation Loss 0.12463872879743576
INFO:WNN:Epoch 9: Training Loss 0.26410324188570183 	 Validation Loss 0.07200922816991806
INFO:WNN:Epoch 10: Training Loss 0.24971710269649824 	 Validation Loss 0.0503552183508873
INFO:WNN:Epoch 11: Training Loss 0.23969181006153426 	 Validation Loss 0.05964747071266174
threshold tensor(0.2259, grad_fn=<MulBackward0>)
