INFO:WNN:Epoch 0: Training Loss 1.0892004172007244 	 Validation Loss 0.8398981690406799
INFO:WNN:Epoch 1: Training Loss 0.8304624110460281 	 Validation Loss 0.7414635419845581
INFO:WNN:Epoch 2: Training Loss 0.7142256200313568 	 Validation Loss 0.6976091861724854
INFO:WNN:Epoch 3: Training Loss 0.6433051278193792 	 Validation Loss 0.6421698927879333
INFO:WNN:Epoch 4: Training Loss 0.5959988733132681 	 Validation Loss 0.6359777450561523
INFO:WNN:Epoch 5: Training Loss 0.5561135113239288 	 Validation Loss 0.6377073526382446
INFO:WNN:Epoch 6: Training Loss 0.5050222525993983 	 Validation Loss 0.6219276785850525
INFO:WNN:Epoch 7: Training Loss 0.4692859450976054 	 Validation Loss 0.6175498962402344
INFO:WNN:Epoch 8: Training Loss 0.44731293618679047 	 Validation Loss 0.6167401671409607
INFO:WNN:Epoch 9: Training Loss 0.4224138508240382 	 Validation Loss 0.6237435936927795
INFO:WNN:Epoch 10: Training Loss 0.40269390245278675 	 Validation Loss 0.6382094025611877
INFO:WNN:Epoch 11: Training Loss 0.38515491783618927 	 Validation Loss 0.6467037796974182
INFO:WNN:Epoch 12: Training Loss 0.3675741950670878 	 Validation Loss 0.6552238464355469
INFO:WNN:Epoch 13: Training Loss 0.3511975208918254 	 Validation Loss 0.6616362929344177
INFO:WNN:Epoch 14: Training Loss 0.33371147016684216 	 Validation Loss 0.6599750518798828
threshold tensor(4.5516, grad_fn=<MulBackward0>)
