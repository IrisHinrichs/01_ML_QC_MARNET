INFO:WNN:Epoch 0: Training Loss 0.2945540595853042 	 Validation Loss 0.7116816341876984
INFO:WNN:Epoch 1: Training Loss 0.30418017481133575 	 Validation Loss 1.1283837854862213
INFO:WNN:Epoch 2: Training Loss 0.32468020769495826 	 Validation Loss 3.199531674385071
INFO:WNN:Epoch 3: Training Loss 0.24217149822895104 	 Validation Loss 1.8316897749900818
INFO:WNN:Epoch 4: Training Loss 0.11025018690270372 	 Validation Loss 0.8462437689304352
INFO:WNN:Epoch 5: Training Loss 0.05661273943648363 	 Validation Loss 0.9992094337940216
INFO:WNN:Epoch 6: Training Loss 0.022602501189491402 	 Validation Loss 0.28248708695173264
INFO:WNN:Epoch 7: Training Loss 0.016639316846218815 	 Validation Loss 0.18652793765068054
INFO:WNN:Epoch 8: Training Loss 0.014937239614179513 	 Validation Loss 0.1279493197798729
INFO:WNN:Epoch 9: Training Loss 0.01587681645954338 	 Validation Loss 0.11031796410679817
INFO:WNN:Epoch 10: Training Loss 0.01368994717146658 	 Validation Loss 0.1171063780784607
INFO:WNN:Epoch 11: Training Loss 0.013672978762770072 	 Validation Loss 0.09491486847400665
INFO:WNN:Epoch 12: Training Loss 0.014049696027844524 	 Validation Loss 0.10107826814055443
INFO:WNN:Epoch 13: Training Loss 0.012033154322125483 	 Validation Loss 0.08503945544362068
INFO:WNN:Epoch 14: Training Loss 0.012705140977535242 	 Validation Loss 0.08082287013530731
INFO:WNN:Epoch 15: Training Loss 0.01293852285501392 	 Validation Loss 0.06288652494549751
INFO:WNN:Epoch 16: Training Loss 0.0179389810145949 	 Validation Loss 0.07634000107645988
INFO:WNN:Epoch 17: Training Loss 0.021586908488340367 	 Validation Loss 0.13459626585245132
INFO:WNN:Epoch 18: Training Loss 0.0331892547243721 	 Validation Loss 0.20169845968484879
INFO:WNN:Epoch 19: Training Loss 0.055230158711007483 	 Validation Loss 0.5479292422533035
INFO:WNN:Epoch 20: Training Loss 0.07433392422778222 	 Validation Loss 0.9014226794242859
INFO:WNN:Epoch 21: Training Loss 0.029143672146650108 	 Validation Loss 0.23294243216514587
INFO:WNN:Epoch 22: Training Loss 0.02895453082965105 	 Validation Loss 0.08870247006416321
INFO:WNN:Epoch 23: Training Loss 0.03278572154279876 	 Validation Loss 0.09360367432236671
INFO:WNN:Epoch 24: Training Loss 0.03955242956484047 	 Validation Loss 0.16127079725265503
INFO:WNN:Epoch 25: Training Loss 0.05282971710160685 	 Validation Loss 0.4847448021173477
INFO:WNN:Epoch 26: Training Loss 0.06483518806877935 	 Validation Loss 0.5573531687259674
threshold tensor(1.9368, grad_fn=<MulBackward0>)
