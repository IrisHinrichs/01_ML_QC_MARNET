INFO:WNN:Epoch 0: Training Loss 0.7645416508118311 	 Validation Loss 0.2860805094242096
INFO:WNN:Epoch 1: Training Loss 0.4331388945380847 	 Validation Loss 0.42037057876586914
INFO:WNN:Epoch 2: Training Loss 0.39445216457049054 	 Validation Loss 0.335006445646286
INFO:WNN:Epoch 3: Training Loss 0.30941111221909523 	 Validation Loss 0.18880881369113922
INFO:WNN:Epoch 4: Training Loss 0.27610275025169057 	 Validation Loss 0.13405559957027435
INFO:WNN:Epoch 5: Training Loss 0.27269063393274945 	 Validation Loss 0.11343861371278763
INFO:WNN:Epoch 6: Training Loss 0.24078997472922006 	 Validation Loss 0.09300124645233154
INFO:WNN:Epoch 7: Training Loss 0.21501822272936502 	 Validation Loss 0.06694458425045013
INFO:WNN:Epoch 8: Training Loss 0.20380629443873963 	 Validation Loss 0.04486731439828873
INFO:WNN:Epoch 9: Training Loss 0.19465992987776795 	 Validation Loss 0.03753460943698883
INFO:WNN:Epoch 10: Training Loss 0.18563497718423605 	 Validation Loss 0.044483646750450134
INFO:WNN:Epoch 11: Training Loss 0.17725517166157564 	 Validation Loss 0.057534053921699524
INFO:WNN:Epoch 12: Training Loss 0.1674008808719615 	 Validation Loss 0.06045360118150711
INFO:WNN:Epoch 13: Training Loss 0.16293419152498245 	 Validation Loss 0.05628480762243271
INFO:WNN:Epoch 14: Training Loss 0.15765298918510476 	 Validation Loss 0.05159471184015274
INFO:WNN:Epoch 15: Training Loss 0.15141840822373828 	 Validation Loss 0.04667641967535019
INFO:WNN:Epoch 16: Training Loss 0.14720130735076964 	 Validation Loss 0.04198124259710312
INFO:WNN:Epoch 17: Training Loss 0.14266223355662078 	 Validation Loss 0.042098984122276306
INFO:WNN:Epoch 18: Training Loss 0.13902607125540575 	 Validation Loss 0.04728497937321663
INFO:WNN:Epoch 19: Training Loss 0.13430352928116918 	 Validation Loss 0.050414226949214935
INFO:WNN:Epoch 20: Training Loss 0.1303966616590818 	 Validation Loss 0.04775722697377205
threshold tensor(0.1994, grad_fn=<MulBackward0>)
