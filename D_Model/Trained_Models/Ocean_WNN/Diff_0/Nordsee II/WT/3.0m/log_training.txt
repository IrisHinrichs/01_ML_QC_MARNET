INFO:WNN:Epoch 0: Training Loss 0.4309033719201883 	 Validation Loss 0.07394609600305557
INFO:WNN:Epoch 1: Training Loss 0.24472411655976126 	 Validation Loss 0.1181180328130722
INFO:WNN:Epoch 2: Training Loss 0.7411756044874589 	 Validation Loss 0.08397716283798218
INFO:WNN:Epoch 3: Training Loss 0.6296662574245905 	 Validation Loss 0.03565412759780884
INFO:WNN:Epoch 4: Training Loss 0.3792211176517109 	 Validation Loss 0.09034696221351624
INFO:WNN:Epoch 5: Training Loss 0.14272513741937776 	 Validation Loss 0.09784618020057678
INFO:WNN:Epoch 6: Training Loss 0.31468511844674746 	 Validation Loss 0.0797838345170021
INFO:WNN:Epoch 7: Training Loss 0.2575395523570478 	 Validation Loss 0.2755506932735443
INFO:WNN:Epoch 8: Training Loss 0.12768340636976064 	 Validation Loss 0.02447875775396824
INFO:WNN:Epoch 9: Training Loss 0.0471069662210842 	 Validation Loss 0.029269013553857803
INFO:WNN:Epoch 10: Training Loss 0.02734916755774369 	 Validation Loss 0.015558358281850815
INFO:WNN:Epoch 11: Training Loss 0.017216473553950586 	 Validation Loss 0.011718581430613995
INFO:WNN:Epoch 12: Training Loss 0.030221290222834797 	 Validation Loss 0.031093807891011238
INFO:WNN:Epoch 13: Training Loss 0.03784875092096627 	 Validation Loss 0.017985528334975243
INFO:WNN:Epoch 14: Training Loss 0.03777926002318661 	 Validation Loss 0.022064879536628723
INFO:WNN:Epoch 15: Training Loss 0.02514359763202568 	 Validation Loss 0.0074577233754098415
INFO:WNN:Epoch 16: Training Loss 0.020146882456416885 	 Validation Loss 0.012494975700974464
INFO:WNN:Epoch 17: Training Loss 0.06046983263998603 	 Validation Loss 0.07227394729852676
INFO:WNN:Epoch 18: Training Loss 0.21766495884706577 	 Validation Loss 0.2985858619213104
INFO:WNN:Epoch 19: Training Loss 0.246836132183671 	 Validation Loss 0.01653524674475193
INFO:WNN:Epoch 20: Training Loss 0.18727167987575133 	 Validation Loss 0.04337069392204285
INFO:WNN:Epoch 21: Training Loss 0.16049445377041896 	 Validation Loss 0.01098628994077444
INFO:WNN:Epoch 22: Training Loss 0.12867576920737822 	 Validation Loss 0.05724340304732323
INFO:WNN:Epoch 23: Training Loss 0.3756014337142309 	 Validation Loss 0.2892583906650543
INFO:WNN:Epoch 24: Training Loss 0.5844485719998678 	 Validation Loss 0.04179118201136589
INFO:WNN:Epoch 25: Training Loss 0.20890947952090452 	 Validation Loss 0.04576906934380531
INFO:WNN:Epoch 26: Training Loss 0.2365386118995957 	 Validation Loss 0.024904334917664528
threshold tensor(0.1040, grad_fn=<MulBackward0>)
