INFO:WNN:Epoch 0: Training Loss 0.5795747339725494 	 Validation Loss 2.7282299995422363
INFO:WNN:Epoch 1: Training Loss 0.42205381393432617 	 Validation Loss 1.9567773342132568
INFO:WNN:Epoch 2: Training Loss 0.4250228703022003 	 Validation Loss 1.709997296333313
INFO:WNN:Epoch 3: Training Loss 0.3684323603908221 	 Validation Loss 1.7768961191177368
INFO:WNN:Epoch 4: Training Loss 0.3681650161743164 	 Validation Loss 1.90185546875
INFO:WNN:Epoch 5: Training Loss 0.3431050628423691 	 Validation Loss 1.958114743232727
INFO:WNN:Epoch 6: Training Loss 0.3393070325255394 	 Validation Loss 1.9190512895584106
INFO:WNN:Epoch 7: Training Loss 0.3333212261398633 	 Validation Loss 1.829437494277954
INFO:WNN:Epoch 8: Training Loss 0.3229485775033633 	 Validation Loss 1.7414367198944092
INFO:WNN:Epoch 9: Training Loss 0.31893594066301983 	 Validation Loss 1.6781044006347656
INFO:WNN:Epoch 10: Training Loss 0.31116506457328796 	 Validation Loss 1.662718415260315
INFO:WNN:Epoch 11: Training Loss 0.3090021684765816 	 Validation Loss 1.7067816257476807
INFO:WNN:Epoch 12: Training Loss 0.30348854263623554 	 Validation Loss 1.7799351215362549
INFO:WNN:Epoch 13: Training Loss 0.29842696835597354 	 Validation Loss 1.8381619453430176
threshold tensor(5.5827, grad_fn=<MulBackward0>)
