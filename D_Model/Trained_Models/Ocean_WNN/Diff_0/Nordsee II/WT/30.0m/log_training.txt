INFO:WNN:Epoch 0: Training Loss 0.2690655643915913 	 Validation Loss 1.2461951971054077
INFO:WNN:Epoch 1: Training Loss 0.4279536280131045 	 Validation Loss 1.448826014995575
INFO:WNN:Epoch 2: Training Loss 0.4625692366923128 	 Validation Loss 3.9841649532318115
INFO:WNN:Epoch 3: Training Loss 0.15803002330418772 	 Validation Loss 1.5898315906524658
INFO:WNN:Epoch 4: Training Loss 0.10872006268861394 	 Validation Loss 1.8050601780414581
INFO:WNN:Epoch 5: Training Loss 0.05353809341613669 	 Validation Loss 1.4442072808742523
INFO:WNN:Epoch 6: Training Loss 0.01361135145513496 	 Validation Loss 0.8990769386291504
INFO:WNN:Epoch 7: Training Loss 0.013251800912864079 	 Validation Loss 0.2891246899962425
INFO:WNN:Epoch 8: Training Loss 0.023230419311100075 	 Validation Loss 0.9804143309593201
INFO:WNN:Epoch 9: Training Loss 0.01006974351912504 	 Validation Loss 0.6493103206157684
INFO:WNN:Epoch 10: Training Loss 0.01616789044298154 	 Validation Loss 0.5169063955545425
INFO:WNN:Epoch 11: Training Loss 0.03035861566058884 	 Validation Loss 1.0762255489826202
INFO:WNN:Epoch 12: Training Loss 0.03633295059474525 	 Validation Loss 1.0668383240699768
INFO:WNN:Epoch 13: Training Loss 0.03309789523094272 	 Validation Loss 1.1621249616146088
INFO:WNN:Epoch 14: Training Loss 0.017438892684973933 	 Validation Loss 0.6624323725700378
INFO:WNN:Epoch 15: Training Loss 0.04875522619113326 	 Validation Loss 0.6252164095640182
INFO:WNN:Epoch 16: Training Loss 0.08911829277834234 	 Validation Loss 1.1591616868972778
INFO:WNN:Epoch 17: Training Loss 0.11511700033346035 	 Validation Loss 0.7974880039691925
INFO:WNN:Epoch 18: Training Loss 0.21444011094384527 	 Validation Loss 0.5207211375236511
threshold tensor(1.1913, grad_fn=<MulBackward0>)
