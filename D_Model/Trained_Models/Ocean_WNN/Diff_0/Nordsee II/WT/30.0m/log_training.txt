INFO:WNN:Epoch 0: Training Loss 0.26906557905507117 	 Validation Loss 1.24619522690773
INFO:WNN:Epoch 1: Training Loss 0.42795364249226014 	 Validation Loss 1.4488259553909302
INFO:WNN:Epoch 2: Training Loss 0.462569255939646 	 Validation Loss 3.984165072441101
INFO:WNN:Epoch 3: Training Loss 0.1580300237907674 	 Validation Loss 1.5898309648036957
INFO:WNN:Epoch 4: Training Loss 0.1087202412551657 	 Validation Loss 1.8050626814365387
INFO:WNN:Epoch 5: Training Loss 0.053538172969031926 	 Validation Loss 1.4442040622234344
INFO:WNN:Epoch 6: Training Loss 0.013612391509620162 	 Validation Loss 0.8990941643714905
INFO:WNN:Epoch 7: Training Loss 0.01325467693519992 	 Validation Loss 0.289085328578949
INFO:WNN:Epoch 8: Training Loss 0.023240504900059022 	 Validation Loss 0.9804677069187164
INFO:WNN:Epoch 9: Training Loss 0.010074736337022236 	 Validation Loss 0.6490447819232941
INFO:WNN:Epoch 10: Training Loss 0.016137760821341846 	 Validation Loss 0.5181964337825775
INFO:WNN:Epoch 11: Training Loss 0.03041538706384017 	 Validation Loss 1.0773780345916748
INFO:WNN:Epoch 12: Training Loss 0.03678171260041078 	 Validation Loss 1.0740851759910583
INFO:WNN:Epoch 13: Training Loss 0.03382715845024601 	 Validation Loss 1.1727239489555359
INFO:WNN:Epoch 14: Training Loss 0.018157408558181487 	 Validation Loss 0.6589034199714661
INFO:WNN:Epoch 15: Training Loss 0.04914132504685161 	 Validation Loss 0.6005036532878876
INFO:WNN:Epoch 16: Training Loss 0.08524642026168294 	 Validation Loss 1.1021993160247803
INFO:WNN:Epoch 17: Training Loss 0.12315783398662461 	 Validation Loss 0.8080081939697266
INFO:WNN:Epoch 18: Training Loss 0.22582093298600134 	 Validation Loss 0.531369537115097
threshold tensor(1.3319, grad_fn=<MulBackward0>)
