INFO:WNN:Epoch 0: Training Loss 0.3476220043376088 	 Validation Loss 0.8878951370716095
INFO:WNN:Epoch 1: Training Loss 0.1363732768998792 	 Validation Loss 0.9117453694343567
INFO:WNN:Epoch 2: Training Loss 0.10541315074078739 	 Validation Loss 0.4705861955881119
INFO:WNN:Epoch 3: Training Loss 0.06211565817163015 	 Validation Loss 0.27406565099954605
INFO:WNN:Epoch 4: Training Loss 0.055408048521106444 	 Validation Loss 0.17130033113062382
INFO:WNN:Epoch 5: Training Loss 0.05732408400702601 	 Validation Loss 0.26814965903759
INFO:WNN:Epoch 6: Training Loss 0.11698741733562201 	 Validation Loss 0.3679957315325737
INFO:WNN:Epoch 7: Training Loss 0.10358372173504904 	 Validation Loss 0.8109237849712372
INFO:WNN:Epoch 8: Training Loss 0.07323811967701961 	 Validation Loss 0.23068970441818237
INFO:WNN:Epoch 9: Training Loss 0.05522166233276948 	 Validation Loss 0.3940791040658951
INFO:WNN:Epoch 10: Training Loss 0.08584228908875957 	 Validation Loss 0.31537628173828125
INFO:WNN:Epoch 11: Training Loss 0.07663852886374418 	 Validation Loss 1.0013255774974823
INFO:WNN:Epoch 12: Training Loss 0.07692090206546709 	 Validation Loss 0.22548769786953926
INFO:WNN:Epoch 13: Training Loss 0.06609193918605645 	 Validation Loss 0.6992536783218384
INFO:WNN:Epoch 14: Training Loss 0.07001647514213498 	 Validation Loss 0.21590794250369072
INFO:WNN:Epoch 15: Training Loss 0.05682029124970237 	 Validation Loss 0.6647128164768219
threshold tensor(6.7022, grad_fn=<MulBackward0>)
