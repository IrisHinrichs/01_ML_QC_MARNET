INFO:WNN:Epoch 0: Training Loss 0.34762199968099594 	 Validation Loss 0.8878951668739319
INFO:WNN:Epoch 1: Training Loss 0.1363732760073617 	 Validation Loss 0.9117453694343567
INFO:WNN:Epoch 2: Training Loss 0.10541314971245204 	 Validation Loss 0.4705861955881119
INFO:WNN:Epoch 3: Training Loss 0.06211565708508715 	 Validation Loss 0.27406560629606247
INFO:WNN:Epoch 4: Training Loss 0.05540804580474893 	 Validation Loss 0.17130033671855927
INFO:WNN:Epoch 5: Training Loss 0.05732406594324857 	 Validation Loss 0.2681495472788811
INFO:WNN:Epoch 6: Training Loss 0.11698740707167114 	 Validation Loss 0.3679957240819931
INFO:WNN:Epoch 7: Training Loss 0.10358377235631148 	 Validation Loss 0.8109242618083954
INFO:WNN:Epoch 8: Training Loss 0.07323815670679323 	 Validation Loss 0.23068980127573013
INFO:WNN:Epoch 9: Training Loss 0.05522167715632046 	 Validation Loss 0.3940793573856354
INFO:WNN:Epoch 10: Training Loss 0.08584228143445216 	 Validation Loss 0.3153764680027962
INFO:WNN:Epoch 11: Training Loss 0.07663851398198555 	 Validation Loss 1.0013267695903778
INFO:WNN:Epoch 12: Training Loss 0.07692096853861585 	 Validation Loss 0.22548700124025345
INFO:WNN:Epoch 13: Training Loss 0.06609222067830463 	 Validation Loss 0.6992610394954681
INFO:WNN:Epoch 14: Training Loss 0.07001653984965135 	 Validation Loss 0.21590955182909966
INFO:WNN:Epoch 15: Training Loss 0.056819968352404736 	 Validation Loss 0.6647028028964996
threshold tensor(6.7022, grad_fn=<MulBackward0>)
