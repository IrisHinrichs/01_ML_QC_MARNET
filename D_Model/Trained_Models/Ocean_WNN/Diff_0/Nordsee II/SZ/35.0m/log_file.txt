INFO:WNN:Epoch 0: Training Loss 0.7951540797948837 	 Validation Loss 0.20440450310707092
INFO:WNN:Epoch 1: Training Loss 0.4170312210917473 	 Validation Loss 0.21209581196308136
INFO:WNN:Epoch 2: Training Loss 0.3367646336555481 	 Validation Loss 0.2008315622806549
INFO:WNN:Epoch 3: Training Loss 0.24614336714148521 	 Validation Loss 0.028335927054286003
INFO:WNN:Epoch 4: Training Loss 0.19142764620482922 	 Validation Loss 0.1204068511724472
INFO:WNN:Epoch 5: Training Loss 0.16832861863076687 	 Validation Loss 0.08081568032503128
INFO:WNN:Epoch 6: Training Loss 0.16560987010598183 	 Validation Loss 0.039094116538763046
INFO:WNN:Epoch 7: Training Loss 0.14514827821403742 	 Validation Loss 0.030476916581392288
INFO:WNN:Epoch 8: Training Loss 0.14105918630957603 	 Validation Loss 0.028927337378263474
INFO:WNN:Epoch 9: Training Loss 0.12748205941170454 	 Validation Loss 0.022732608020305634
INFO:WNN:Epoch 10: Training Loss 0.1218115221709013 	 Validation Loss 0.02841309644281864
INFO:WNN:Epoch 11: Training Loss 0.11492069158703089 	 Validation Loss 0.022330544888973236
INFO:WNN:Epoch 12: Training Loss 0.10815280489623547 	 Validation Loss 0.026075419038534164
INFO:WNN:Epoch 13: Training Loss 0.1060161730274558 	 Validation Loss 0.022522782906889915
INFO:WNN:Epoch 14: Training Loss 0.10406199656426907 	 Validation Loss 0.021336589008569717
INFO:WNN:Epoch 15: Training Loss 0.10150600224733353 	 Validation Loss 0.020167993381619453
INFO:WNN:Epoch 16: Training Loss 0.09882926009595394 	 Validation Loss 0.01899012364447117
INFO:WNN:Epoch 17: Training Loss 0.0968983806669712 	 Validation Loss 0.018814019858837128
INFO:WNN:Epoch 18: Training Loss 0.0953419879078865 	 Validation Loss 0.018516337499022484
INFO:WNN:Epoch 19: Training Loss 0.09351369366049767 	 Validation Loss 0.019085964187979698
INFO:WNN:Epoch 20: Training Loss 0.09197188075631857 	 Validation Loss 0.01863897033035755
INFO:WNN:Epoch 21: Training Loss 0.09082317631691694 	 Validation Loss 0.018444838002324104
INFO:WNN:Epoch 22: Training Loss 0.09004268236458302 	 Validation Loss 0.017567802220582962
INFO:WNN:Epoch 23: Training Loss 0.08942845556885004 	 Validation Loss 0.0210103876888752
INFO:WNN:Epoch 24: Training Loss 0.0897426325827837 	 Validation Loss 0.019213370978832245
INFO:WNN:Epoch 25: Training Loss 0.09658845327794552 	 Validation Loss 0.03884188085794449
INFO:WNN:Epoch 26: Training Loss 0.11550864204764366 	 Validation Loss 0.03848709166049957
INFO:WNN:Epoch 27: Training Loss 0.16513391956686974 	 Validation Loss 0.018147042021155357
INFO:WNN:Epoch 28: Training Loss 0.11866157967597246 	 Validation Loss 0.04673653468489647
INFO:WNN:Epoch 29: Training Loss 0.08850039076060057 	 Validation Loss 0.022215157747268677
INFO:WNN:Epoch 30: Training Loss 0.09591152146458626 	 Validation Loss 0.020250875502824783
INFO:WNN:Epoch 31: Training Loss 0.09079754538834095 	 Validation Loss 0.035820286720991135
INFO:WNN:Epoch 32: Training Loss 0.08566232305020094 	 Validation Loss 0.02145855873823166
INFO:WNN:Epoch 33: Training Loss 0.08695169538259506 	 Validation Loss 0.020870238542556763
threshold tensor(0.1262, grad_fn=<MulBackward0>)
