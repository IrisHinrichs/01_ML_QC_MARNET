INFO:WNN:Epoch 0: Training Loss 0.1679315852622191 	 Validation Loss 0.1522406041622162
INFO:WNN:Epoch 1: Training Loss 0.2790840477294599 	 Validation Loss 0.08792422985425219
INFO:WNN:Epoch 2: Training Loss 0.27933427901007235 	 Validation Loss 0.06768534705042839
INFO:WNN:Epoch 3: Training Loss 0.22663583965428793 	 Validation Loss 0.07452799379825592
INFO:WNN:Epoch 4: Training Loss 0.1544362783897668 	 Validation Loss 0.17203734070062637
INFO:WNN:Epoch 5: Training Loss 0.21014913862260678 	 Validation Loss 0.04756348626688123
INFO:WNN:Epoch 6: Training Loss 0.13976259576156735 	 Validation Loss 0.05240151286125183
INFO:WNN:Epoch 7: Training Loss 0.17332593273507277 	 Validation Loss 0.1884482577443123
INFO:WNN:Epoch 8: Training Loss 0.2190599498571828 	 Validation Loss 0.4588498920202255
INFO:WNN:Epoch 9: Training Loss 0.3057141109990577 	 Validation Loss 0.03222730499692261
INFO:WNN:Epoch 10: Training Loss 0.21206091798376292 	 Validation Loss 0.029152507660910487
INFO:WNN:Epoch 11: Training Loss 0.1109443295863457 	 Validation Loss 0.21765239536762238
INFO:WNN:Epoch 12: Training Loss 0.230563597753644 	 Validation Loss 1.0840366184711456
INFO:WNN:Epoch 13: Training Loss 0.45222937408834696 	 Validation Loss 0.0650640744715929
INFO:WNN:Epoch 14: Training Loss 0.15037829025338093 	 Validation Loss 0.05084303952753544
INFO:WNN:Epoch 15: Training Loss 0.13246592374828955 	 Validation Loss 0.24773837625980377
INFO:WNN:Epoch 16: Training Loss 0.22813429574792585 	 Validation Loss 0.1915716677904129
INFO:WNN:Epoch 17: Training Loss 0.24379085299248496 	 Validation Loss 0.42882387340068817
INFO:WNN:Epoch 18: Training Loss 0.3067533430488159 	 Validation Loss 0.0641474686563015
INFO:WNN:Epoch 19: Training Loss 0.2556659921538085 	 Validation Loss 0.04503213753923774
INFO:WNN:Epoch 20: Training Loss 0.19465775477389494 	 Validation Loss 0.023750392021611333
INFO:WNN:Epoch 21: Training Loss 0.09718319358944427 	 Validation Loss 0.026855570264160633
INFO:WNN:Epoch 22: Training Loss 0.05021728535211878 	 Validation Loss 0.017269799718633294
INFO:WNN:Epoch 23: Training Loss 0.033373943413607776 	 Validation Loss 0.013309527363162488
INFO:WNN:Epoch 24: Training Loss 0.027852141827073258 	 Validation Loss 0.012497292511397973
INFO:WNN:Epoch 25: Training Loss 0.026163592682375263 	 Validation Loss 0.012465770007111132
INFO:WNN:Epoch 26: Training Loss 0.024161166654569872 	 Validation Loss 0.014597718487493694
INFO:WNN:Epoch 27: Training Loss 0.024920127470977604 	 Validation Loss 0.018788778223097324
INFO:WNN:Epoch 28: Training Loss 0.02631076030471983 	 Validation Loss 0.02049568761140108
INFO:WNN:Epoch 29: Training Loss 0.030970569292549044 	 Validation Loss 0.03322088345885277
INFO:WNN:Epoch 30: Training Loss 0.03702778081302919 	 Validation Loss 0.021456908900290728
INFO:WNN:Epoch 31: Training Loss 0.04247751822307085 	 Validation Loss 0.029092781245708466
INFO:WNN:Epoch 32: Training Loss 0.0544544669513319 	 Validation Loss 0.033094809390604496
INFO:WNN:Epoch 33: Training Loss 0.03858554293401539 	 Validation Loss 0.02026567468419671
INFO:WNN:Epoch 34: Training Loss 0.04105203249491751 	 Validation Loss 0.032578544691205025
INFO:WNN:Epoch 35: Training Loss 0.044682040985208005 	 Validation Loss 0.02904498018324375
threshold tensor(0.2247, grad_fn=<MulBackward0>)
