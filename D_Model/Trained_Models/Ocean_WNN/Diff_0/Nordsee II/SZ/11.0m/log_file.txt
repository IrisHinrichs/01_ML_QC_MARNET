INFO:WNN:Epoch 0: Training Loss 0.3680821346739928 	 Validation Loss 0.8983973264694214
INFO:WNN:Epoch 1: Training Loss 0.3066840283572674 	 Validation Loss 0.6638291478157043
INFO:WNN:Epoch 2: Training Loss 0.15774028599262238 	 Validation Loss 0.5438275933265686
INFO:WNN:Epoch 3: Training Loss 0.13065359058479467 	 Validation Loss 0.5135683417320251
INFO:WNN:Epoch 4: Training Loss 0.11753913549085458 	 Validation Loss 0.3901570737361908
INFO:WNN:Epoch 5: Training Loss 0.12430429309606553 	 Validation Loss 0.369989812374115
INFO:WNN:Epoch 6: Training Loss 0.12581488688786824 	 Validation Loss 0.3341487944126129
INFO:WNN:Epoch 7: Training Loss 0.1457481812685728 	 Validation Loss 0.46268323063850403
INFO:WNN:Epoch 8: Training Loss 0.15713367027541 	 Validation Loss 0.42600300908088684
INFO:WNN:Epoch 9: Training Loss 0.17798213101923466 	 Validation Loss 0.7486414313316345
INFO:WNN:Epoch 10: Training Loss 0.1445219307517012 	 Validation Loss 0.6028774380683899
INFO:WNN:Epoch 11: Training Loss 0.13692551472534736 	 Validation Loss 0.5687660574913025
INFO:WNN:Epoch 12: Training Loss 0.10150338100890319 	 Validation Loss 0.44579991698265076
INFO:WNN:Epoch 13: Training Loss 0.09620022134234509 	 Validation Loss 0.47263363003730774
INFO:WNN:Epoch 14: Training Loss 0.08984399518618981 	 Validation Loss 0.3998330235481262
INFO:WNN:Epoch 15: Training Loss 0.089758793823421 	 Validation Loss 0.4280504584312439
INFO:WNN:Epoch 16: Training Loss 0.08751732824991147 	 Validation Loss 0.39512398838996887
INFO:WNN:Epoch 17: Training Loss 0.08906094872703155 	 Validation Loss 0.4193669557571411
threshold tensor(2.8600, grad_fn=<MulBackward0>)
