INFO:WNN:Epoch 0: Training Loss 0.17981016547197387 	 Validation Loss 0.2689519776031375
INFO:WNN:Epoch 1: Training Loss 0.15960498475691393 	 Validation Loss 0.29610686749219894
INFO:WNN:Epoch 2: Training Loss 0.1193128434963347 	 Validation Loss 0.14047554996795952
INFO:WNN:Epoch 3: Training Loss 0.11416420241862181 	 Validation Loss 0.1746168276295066
INFO:WNN:Epoch 4: Training Loss 0.09519084609512772 	 Validation Loss 0.164429672062397
INFO:WNN:Epoch 5: Training Loss 0.14979657976488983 	 Validation Loss 0.2442195056937635
INFO:WNN:Epoch 6: Training Loss 0.12388844446589549 	 Validation Loss 0.21104579884558916
INFO:WNN:Epoch 7: Training Loss 0.20771093583399697 	 Validation Loss 0.23323574848473072
INFO:WNN:Epoch 8: Training Loss 0.1564718861066337 	 Validation Loss 0.6011940315365791
INFO:WNN:Epoch 9: Training Loss 0.15790683337088143 	 Validation Loss 0.2707535029621795
INFO:WNN:Epoch 10: Training Loss 0.2198845659870477 	 Validation Loss 0.49608026072382927
INFO:WNN:Epoch 11: Training Loss 0.23804175711813427 	 Validation Loss 0.6132906060665846
INFO:WNN:Epoch 12: Training Loss 0.25703153537497636 	 Validation Loss 0.44485659897327423
INFO:WNN:Epoch 13: Training Loss 0.2664862804647003 	 Validation Loss 0.58587158145383
threshold tensor(7.6698, grad_fn=<MulBackward0>)
