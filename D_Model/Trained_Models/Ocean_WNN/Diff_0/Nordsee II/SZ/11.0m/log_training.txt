INFO:WNN:Epoch 0: Training Loss 0.17981016289974963 	 Validation Loss 0.26895194547250867
INFO:WNN:Epoch 1: Training Loss 0.1596049846460422 	 Validation Loss 0.2961068404838443
INFO:WNN:Epoch 2: Training Loss 0.11931283113413624 	 Validation Loss 0.14047555066645145
INFO:WNN:Epoch 3: Training Loss 0.11416425755513566 	 Validation Loss 0.1746167754754424
INFO:WNN:Epoch 4: Training Loss 0.09519091756304815 	 Validation Loss 0.16442971490323544
INFO:WNN:Epoch 5: Training Loss 0.14979675523049774 	 Validation Loss 0.244219028390944
INFO:WNN:Epoch 6: Training Loss 0.12388740657340913 	 Validation Loss 0.2110474007204175
INFO:WNN:Epoch 7: Training Loss 0.20770963948840895 	 Validation Loss 0.23323407140560448
INFO:WNN:Epoch 8: Training Loss 0.15647354143272554 	 Validation Loss 0.6012449394911528
INFO:WNN:Epoch 9: Training Loss 0.15790416823611372 	 Validation Loss 0.27075258758850396
INFO:WNN:Epoch 10: Training Loss 0.21983993565663695 	 Validation Loss 0.4957357458770275
INFO:WNN:Epoch 11: Training Loss 0.23723705547551313 	 Validation Loss 0.6114433268085122
INFO:WNN:Epoch 12: Training Loss 0.2544542717791739 	 Validation Loss 0.4387361630797386
INFO:WNN:Epoch 13: Training Loss 0.2668458516044276 	 Validation Loss 0.587578295962885
threshold tensor(7.7030, grad_fn=<MulBackward0>)
