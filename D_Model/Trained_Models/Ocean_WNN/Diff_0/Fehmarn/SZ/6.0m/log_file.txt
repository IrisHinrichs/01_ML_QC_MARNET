INFO:WNN:Epoch 0: Training Loss 1.0348223745822906 	 Validation Loss 0.29405540227890015
INFO:WNN:Epoch 1: Training Loss 0.7252388546864191 	 Validation Loss 0.29024556279182434
INFO:WNN:Epoch 2: Training Loss 0.5502088367938995 	 Validation Loss 0.29139500856399536
INFO:WNN:Epoch 3: Training Loss 0.5670352478822073 	 Validation Loss 0.2897016704082489
INFO:WNN:Epoch 4: Training Loss 0.5461433033148447 	 Validation Loss 0.2777068018913269
INFO:WNN:Epoch 5: Training Loss 0.49584023157755536 	 Validation Loss 0.2346898466348648
INFO:WNN:Epoch 6: Training Loss 0.46847330530484516 	 Validation Loss 0.1631358414888382
INFO:WNN:Epoch 7: Training Loss 0.44242235521475476 	 Validation Loss 0.11737336218357086
INFO:WNN:Epoch 8: Training Loss 0.4323023209969203 	 Validation Loss 0.10878913104534149
INFO:WNN:Epoch 9: Training Loss 0.4159374584754308 	 Validation Loss 0.12158498167991638
INFO:WNN:Epoch 10: Training Loss 0.39697500069936115 	 Validation Loss 0.13630543649196625
INFO:WNN:Epoch 11: Training Loss 0.3851805180311203 	 Validation Loss 0.12805026769638062
INFO:WNN:Epoch 12: Training Loss 0.3724956214427948 	 Validation Loss 0.11706841737031937
INFO:WNN:Epoch 13: Training Loss 0.36582480867703754 	 Validation Loss 0.118509940803051
INFO:WNN:Epoch 14: Training Loss 0.3556147913138072 	 Validation Loss 0.12009038031101227
INFO:WNN:Epoch 15: Training Loss 0.34580783545970917 	 Validation Loss 0.11809322237968445
INFO:WNN:Epoch 16: Training Loss 0.33539407948652905 	 Validation Loss 0.1177075058221817
INFO:WNN:Epoch 17: Training Loss 0.32524629433949787 	 Validation Loss 0.12160102277994156
INFO:WNN:Epoch 18: Training Loss 0.31486466030279797 	 Validation Loss 0.12842684984207153
INFO:WNN:Epoch 19: Training Loss 0.30489154656728107 	 Validation Loss 0.13558396697044373
threshold tensor(1.0528, grad_fn=<MulBackward0>)
