INFO:WNN:Epoch 0: Training Loss 0.5595093841132309 	 Validation Loss 0.11441744118928909
INFO:WNN:Epoch 1: Training Loss 0.36620258992271765 	 Validation Loss 0.11600516736507416
INFO:WNN:Epoch 2: Training Loss 0.2069530401578439 	 Validation Loss 0.08509819209575653
INFO:WNN:Epoch 3: Training Loss 0.11436972148450357 	 Validation Loss 0.07240468449890614
INFO:WNN:Epoch 4: Training Loss 0.06641933172275978 	 Validation Loss 0.06813571974635124
INFO:WNN:Epoch 5: Training Loss 0.05645928917718785 	 Validation Loss 0.06526618637144566
INFO:WNN:Epoch 6: Training Loss 0.0784615684367184 	 Validation Loss 0.06263474747538567
INFO:WNN:Epoch 7: Training Loss 0.09154379341219153 	 Validation Loss 0.08206338621675968
INFO:WNN:Epoch 8: Training Loss 0.13758833207456128 	 Validation Loss 0.10545851290225983
INFO:WNN:Epoch 9: Training Loss 0.17981468826266273 	 Validation Loss 0.1568457931280136
INFO:WNN:Epoch 10: Training Loss 0.144695797602513 	 Validation Loss 0.07877619937062263
INFO:WNN:Epoch 11: Training Loss 0.12355925282463431 	 Validation Loss 0.09286734461784363
INFO:WNN:Epoch 12: Training Loss 0.06406541391541916 	 Validation Loss 0.14092675410211086
INFO:WNN:Epoch 13: Training Loss 0.06725613347121648 	 Validation Loss 0.1829434409737587
INFO:WNN:Epoch 14: Training Loss 0.08532673644367605 	 Validation Loss 0.1695132814347744
INFO:WNN:Epoch 15: Training Loss 0.10380118769327444 	 Validation Loss 0.09771315008401871
INFO:WNN:Epoch 16: Training Loss 0.07807646640243807 	 Validation Loss 0.06421447172760963
INFO:WNN:Epoch 17: Training Loss 0.06414628161084172 	 Validation Loss 0.0744868591427803
threshold tensor(0.9624, grad_fn=<MulBackward0>)
