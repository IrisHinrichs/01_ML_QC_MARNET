INFO:WNN:Epoch 0: Training Loss 0.6453920900821686 	 Validation Loss 0.0977146103978157
INFO:WNN:Epoch 1: Training Loss 0.45170122385025024 	 Validation Loss 0.07535789906978607
INFO:WNN:Epoch 2: Training Loss 0.35984691977500916 	 Validation Loss 0.10396207869052887
INFO:WNN:Epoch 3: Training Loss 0.3178119957447052 	 Validation Loss 0.13171635568141937
INFO:WNN:Epoch 4: Training Loss 0.30008815973997116 	 Validation Loss 0.12026958912611008
INFO:WNN:Epoch 5: Training Loss 0.26114974170923233 	 Validation Loss 0.10553113371133804
INFO:WNN:Epoch 6: Training Loss 0.22943465411663055 	 Validation Loss 0.11292939633131027
INFO:WNN:Epoch 7: Training Loss 0.2171507328748703 	 Validation Loss 0.12721747159957886
INFO:WNN:Epoch 8: Training Loss 0.20151454955339432 	 Validation Loss 0.13057509064674377
INFO:WNN:Epoch 9: Training Loss 0.18701373413205147 	 Validation Loss 0.1270933598279953
INFO:WNN:Epoch 10: Training Loss 0.1832376942038536 	 Validation Loss 0.12786521017551422
INFO:WNN:Epoch 11: Training Loss 0.17765233293175697 	 Validation Loss 0.1348692625761032
INFO:WNN:Epoch 12: Training Loss 0.1681385077536106 	 Validation Loss 0.14323653280735016
threshold tensor(0.8818, grad_fn=<MulBackward0>)
