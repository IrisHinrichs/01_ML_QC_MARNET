INFO:WNN:Epoch 0: Training Loss 0.4146536694696316 	 Validation Loss 2.4434779062867165
INFO:WNN:Epoch 1: Training Loss 0.38975238875271034 	 Validation Loss 1.3596318773925304
INFO:WNN:Epoch 2: Training Loss 0.36082019248547464 	 Validation Loss 0.7899210564792156
INFO:WNN:Epoch 3: Training Loss 0.2826174788463574 	 Validation Loss 1.0119465440511703
INFO:WNN:Epoch 4: Training Loss 0.20679133886901233 	 Validation Loss 0.36585009656846523
INFO:WNN:Epoch 5: Training Loss 0.10440419644538242 	 Validation Loss 0.2562128435820341
INFO:WNN:Epoch 6: Training Loss 0.08747836182681987 	 Validation Loss 0.25985971093177795
INFO:WNN:Epoch 7: Training Loss 0.08138404367491603 	 Validation Loss 0.25589960627257824
INFO:WNN:Epoch 8: Training Loss 0.07649312651931094 	 Validation Loss 0.23639837373048067
INFO:WNN:Epoch 9: Training Loss 0.07465813760287486 	 Validation Loss 0.21636716276407242
INFO:WNN:Epoch 10: Training Loss 0.07467601634562016 	 Validation Loss 0.18499937932938337
INFO:WNN:Epoch 11: Training Loss 0.06874904183384317 	 Validation Loss 0.15235639922320843
INFO:WNN:Epoch 12: Training Loss 0.05561745333342025 	 Validation Loss 0.13033520430326462
INFO:WNN:Epoch 13: Training Loss 0.04399242799711199 	 Validation Loss 0.11510804574936628
INFO:WNN:Epoch 14: Training Loss 0.03818782246358191 	 Validation Loss 0.11312277615070343
INFO:WNN:Epoch 15: Training Loss 0.03981501135813932 	 Validation Loss 0.11305758822709322
INFO:WNN:Epoch 16: Training Loss 0.03981107582176964 	 Validation Loss 0.09997092559933662
INFO:WNN:Epoch 17: Training Loss 0.03760682729905686 	 Validation Loss 0.11139788292348385
INFO:WNN:Epoch 18: Training Loss 0.04242604955708465 	 Validation Loss 0.11335521936416626
INFO:WNN:Epoch 19: Training Loss 0.04297283041076018 	 Validation Loss 0.06865817494690418
INFO:WNN:Epoch 20: Training Loss 0.05446455582904701 	 Validation Loss 0.35841836873441935
INFO:WNN:Epoch 21: Training Loss 0.20894880707447344 	 Validation Loss 0.9000805262476206
INFO:WNN:Epoch 22: Training Loss 0.17943124260860854 	 Validation Loss 1.914478735998273
INFO:WNN:Epoch 23: Training Loss 0.2582392885278051 	 Validation Loss 1.9867361634969711
INFO:WNN:Epoch 24: Training Loss 0.41689739186460006 	 Validation Loss 1.3397207111120224
INFO:WNN:Epoch 25: Training Loss 0.4546186956218802 	 Validation Loss 1.9577710554003716
INFO:WNN:Epoch 26: Training Loss 0.40715408224899036 	 Validation Loss 1.9443043768405914
INFO:WNN:Epoch 27: Training Loss 0.5161544540180609 	 Validation Loss 0.6939173117280006
INFO:WNN:Epoch 28: Training Loss 0.49572677795703596 	 Validation Loss 2.6041015833616257
INFO:WNN:Epoch 29: Training Loss 0.30137287419459496 	 Validation Loss 1.494158286601305
INFO:WNN:Epoch 30: Training Loss 0.35343469922932297 	 Validation Loss 1.3394971415400505
threshold tensor(7.5082, grad_fn=<MulBackward0>)
