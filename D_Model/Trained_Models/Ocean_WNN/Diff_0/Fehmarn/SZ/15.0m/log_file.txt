INFO:WNN:Epoch 0: Training Loss 0.8344330290953318 	 Validation Loss 0.6654918193817139
INFO:WNN:Epoch 1: Training Loss 0.411023885011673 	 Validation Loss 0.06581678241491318
INFO:WNN:Epoch 2: Training Loss 0.280543049176534 	 Validation Loss 0.061002932488918304
INFO:WNN:Epoch 3: Training Loss 0.32497865955034894 	 Validation Loss 0.09007841348648071
INFO:WNN:Epoch 4: Training Loss 0.2550791750351588 	 Validation Loss 0.07062670588493347
INFO:WNN:Epoch 5: Training Loss 0.1739752640326818 	 Validation Loss 0.03513532504439354
INFO:WNN:Epoch 6: Training Loss 0.1683804194132487 	 Validation Loss 0.03990773484110832
INFO:WNN:Epoch 7: Training Loss 0.15525340537230173 	 Validation Loss 0.07867678999900818
INFO:WNN:Epoch 8: Training Loss 0.13042153169711432 	 Validation Loss 0.07070942223072052
INFO:WNN:Epoch 9: Training Loss 0.11195651690165202 	 Validation Loss 0.03659648075699806
INFO:WNN:Epoch 10: Training Loss 0.11080985516309738 	 Validation Loss 0.03677066043019295
INFO:WNN:Epoch 11: Training Loss 0.1110355978210767 	 Validation Loss 0.03611406311392784
INFO:WNN:Epoch 12: Training Loss 0.10019710411628087 	 Validation Loss 0.029117612168192863
INFO:WNN:Epoch 13: Training Loss 0.09519873932003975 	 Validation Loss 0.028937656432390213
INFO:WNN:Epoch 14: Training Loss 0.08982113252083461 	 Validation Loss 0.028901612386107445
INFO:WNN:Epoch 15: Training Loss 0.0833313303689162 	 Validation Loss 0.02924865484237671
INFO:WNN:Epoch 16: Training Loss 0.07865200936794281 	 Validation Loss 0.03066227026283741
INFO:WNN:Epoch 17: Training Loss 0.07637665544946988 	 Validation Loss 0.029718656092882156
INFO:WNN:Epoch 18: Training Loss 0.0741258015235265 	 Validation Loss 0.027279295027256012
INFO:WNN:Epoch 19: Training Loss 0.0707655909160773 	 Validation Loss 0.027296194806694984
INFO:WNN:Epoch 20: Training Loss 0.06870569537083308 	 Validation Loss 0.026788271963596344
INFO:WNN:Epoch 21: Training Loss 0.06652052948872249 	 Validation Loss 0.026419198140501976
INFO:WNN:Epoch 22: Training Loss 0.06392987693349521 	 Validation Loss 0.027138864621520042
INFO:WNN:Epoch 23: Training Loss 0.06223683307568232 	 Validation Loss 0.027688387781381607
INFO:WNN:Epoch 24: Training Loss 0.06136768807967504 	 Validation Loss 0.026902979239821434
INFO:WNN:Epoch 25: Training Loss 0.060060578087965645 	 Validation Loss 0.026617392897605896
INFO:WNN:Epoch 26: Training Loss 0.05861410374442736 	 Validation Loss 0.02744569629430771
INFO:WNN:Epoch 27: Training Loss 0.057377045353253685 	 Validation Loss 0.027699947357177734
INFO:WNN:Epoch 28: Training Loss 0.056220373759667076 	 Validation Loss 0.027356715872883797
INFO:WNN:Epoch 29: Training Loss 0.05520060410102209 	 Validation Loss 0.027631565928459167
threshold tensor(0.1669, grad_fn=<MulBackward0>)
