INFO:WNN:Epoch 0: Training Loss 0.7031144723296165 	 Validation Loss 0.3460426926612854
INFO:WNN:Epoch 1: Training Loss 0.26677582412958145 	 Validation Loss 0.10904856026172638
INFO:WNN:Epoch 2: Training Loss 0.1726419236510992 	 Validation Loss 0.1368546038866043
INFO:WNN:Epoch 3: Training Loss 0.19180698320269585 	 Validation Loss 0.11955198645591736
INFO:WNN:Epoch 4: Training Loss 0.14723558165133 	 Validation Loss 0.1117546483874321
INFO:WNN:Epoch 5: Training Loss 0.1168598048388958 	 Validation Loss 0.1812119483947754
INFO:WNN:Epoch 6: Training Loss 0.10939216800034046 	 Validation Loss 0.27222704887390137
INFO:WNN:Epoch 7: Training Loss 0.09399271383881569 	 Validation Loss 0.19669440388679504
INFO:WNN:Epoch 8: Training Loss 0.08044529054313898 	 Validation Loss 0.09517429023981094
INFO:WNN:Epoch 9: Training Loss 0.0739084854722023 	 Validation Loss 0.09371031075716019
INFO:WNN:Epoch 10: Training Loss 0.07132560759782791 	 Validation Loss 0.0884094163775444
INFO:WNN:Epoch 11: Training Loss 0.06608856283128262 	 Validation Loss 0.10084456950426102
INFO:WNN:Epoch 12: Training Loss 0.06115424633026123 	 Validation Loss 0.1040053591132164
INFO:WNN:Epoch 13: Training Loss 0.057540228590369225 	 Validation Loss 0.11296550929546356
INFO:WNN:Epoch 14: Training Loss 0.05447855358943343 	 Validation Loss 0.10776681452989578
INFO:WNN:Epoch 15: Training Loss 0.05343192629516125 	 Validation Loss 0.09052148461341858
INFO:WNN:Epoch 16: Training Loss 0.051428865641355515 	 Validation Loss 0.09006142616271973
INFO:WNN:Epoch 17: Training Loss 0.04982703644782305 	 Validation Loss 0.08984740823507309
INFO:WNN:Epoch 18: Training Loss 0.048423000145703554 	 Validation Loss 0.08116485178470612
INFO:WNN:Epoch 19: Training Loss 0.0466541750356555 	 Validation Loss 0.08108624070882797
INFO:WNN:Epoch 20: Training Loss 0.04577063024044037 	 Validation Loss 0.07528810948133469
INFO:WNN:Epoch 21: Training Loss 0.044784463942050934 	 Validation Loss 0.07317802309989929
INFO:WNN:Epoch 22: Training Loss 0.04376534651964903 	 Validation Loss 0.07210220396518707
INFO:WNN:Epoch 23: Training Loss 0.042934708297252655 	 Validation Loss 0.06744294613599777
INFO:WNN:Epoch 24: Training Loss 0.04192798770964146 	 Validation Loss 0.06795177608728409
INFO:WNN:Epoch 25: Training Loss 0.041420751716941595 	 Validation Loss 0.06579898297786713
INFO:WNN:Epoch 26: Training Loss 0.040605593007057905 	 Validation Loss 0.0685129389166832
INFO:WNN:Epoch 27: Training Loss 0.04018542356789112 	 Validation Loss 0.0658414363861084
INFO:WNN:Epoch 28: Training Loss 0.039362932089716196 	 Validation Loss 0.06718897819519043
INFO:WNN:Epoch 29: Training Loss 0.039114289451390505 	 Validation Loss 0.06365948915481567
INFO:WNN:Epoch 30: Training Loss 0.038294507190585136 	 Validation Loss 0.06703111529350281
INFO:WNN:Epoch 31: Training Loss 0.03830616595223546 	 Validation Loss 0.06272543221712112
INFO:WNN:Epoch 32: Training Loss 0.037261595483869314 	 Validation Loss 0.06856098771095276
INFO:WNN:Epoch 33: Training Loss 0.03787562716752291 	 Validation Loss 0.060300055891275406
INFO:WNN:Epoch 34: Training Loss 0.03643970610573888 	 Validation Loss 0.07206369936466217
INFO:WNN:Epoch 35: Training Loss 0.03862600959837437 	 Validation Loss 0.05718309432268143
INFO:WNN:Epoch 36: Training Loss 0.036871292162686586 	 Validation Loss 0.08329662680625916
INFO:WNN:Epoch 37: Training Loss 0.04364441893994808 	 Validation Loss 0.05581776425242424
INFO:WNN:Epoch 38: Training Loss 0.04338370822370052 	 Validation Loss 0.1165783554315567
INFO:WNN:Epoch 39: Training Loss 0.06035998370498419 	 Validation Loss 0.07372830808162689
INFO:WNN:Epoch 40: Training Loss 0.06099134171381593 	 Validation Loss 0.1837702840566635
INFO:WNN:Epoch 41: Training Loss 0.07691508950665593 	 Validation Loss 0.08646997064352036
INFO:WNN:Epoch 42: Training Loss 0.06338100647553802 	 Validation Loss 0.11664977669715881
INFO:WNN:Epoch 43: Training Loss 0.05183257395401597 	 Validation Loss 0.07007396966218948
INFO:WNN:Epoch 44: Training Loss 0.04133120132610202 	 Validation Loss 0.06217345967888832
INFO:WNN:Epoch 45: Training Loss 0.039073048159480095 	 Validation Loss 0.09634330868721008
INFO:WNN:Epoch 46: Training Loss 0.04050460923463106 	 Validation Loss 0.06743403524160385
threshold tensor(0.6392, grad_fn=<MulBackward0>)
