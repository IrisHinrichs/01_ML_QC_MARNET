INFO:WNN:Epoch 0: Training Loss 0.354553404622353 	 Validation Loss 0.8779760003089905
INFO:WNN:Epoch 1: Training Loss 0.32103071361780167 	 Validation Loss 1.4718631505966187
INFO:WNN:Epoch 2: Training Loss 0.2309853403040996 	 Validation Loss 1.5024784803390503
INFO:WNN:Epoch 3: Training Loss 0.0944538340688898 	 Validation Loss 1.0656462907791138
INFO:WNN:Epoch 4: Training Loss 0.05636209142036163 	 Validation Loss 0.7856031060218811
INFO:WNN:Epoch 5: Training Loss 0.0584632705610532 	 Validation Loss 0.669133186340332
INFO:WNN:Epoch 6: Training Loss 0.041218499814231806 	 Validation Loss 0.6005380749702454
INFO:WNN:Epoch 7: Training Loss 0.03510528342583431 	 Validation Loss 0.537878692150116
INFO:WNN:Epoch 8: Training Loss 0.03634612792386459 	 Validation Loss 0.49719759821891785
INFO:WNN:Epoch 9: Training Loss 0.032730261831042856 	 Validation Loss 0.46069565415382385
INFO:WNN:Epoch 10: Training Loss 0.057062494210325755 	 Validation Loss 0.4535064995288849
INFO:WNN:Epoch 11: Training Loss 0.06493417578391157 	 Validation Loss 0.5592721700668335
INFO:WNN:Epoch 12: Training Loss 0.1716942426820214 	 Validation Loss 0.7283146977424622
INFO:WNN:Epoch 13: Training Loss 0.10410687442009266 	 Validation Loss 1.1059510707855225
INFO:WNN:Epoch 14: Training Loss 0.11111758477412738 	 Validation Loss 1.100026249885559
INFO:WNN:Epoch 15: Training Loss 0.04655072017787741 	 Validation Loss 0.7628101110458374
INFO:WNN:Epoch 16: Training Loss 0.03340273939717848 	 Validation Loss 0.6288197040557861
INFO:WNN:Epoch 17: Training Loss 0.03259014434969196 	 Validation Loss 0.5684977769851685
INFO:WNN:Epoch 18: Training Loss 0.028823313876413383 	 Validation Loss 0.5103470087051392
INFO:WNN:Epoch 19: Training Loss 0.044595365054332294 	 Validation Loss 0.49452412128448486
INFO:WNN:Epoch 20: Training Loss 0.04308324686896343 	 Validation Loss 0.505428671836853
threshold tensor(6.1740, grad_fn=<MulBackward0>)
