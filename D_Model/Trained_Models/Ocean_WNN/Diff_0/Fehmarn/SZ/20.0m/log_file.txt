INFO:WNN:Epoch 0: Training Loss 1.0311650484800339 	 Validation Loss 0.9161837100982666
INFO:WNN:Epoch 1: Training Loss 0.5983744189143181 	 Validation Loss 0.8470730781555176
INFO:WNN:Epoch 2: Training Loss 0.47497330605983734 	 Validation Loss 0.845903754234314
INFO:WNN:Epoch 3: Training Loss 0.38706664741039276 	 Validation Loss 0.8611552119255066
INFO:WNN:Epoch 4: Training Loss 0.39155831187963486 	 Validation Loss 0.872982382774353
INFO:WNN:Epoch 5: Training Loss 0.33683087676763535 	 Validation Loss 0.8967074751853943
INFO:WNN:Epoch 6: Training Loss 0.30151772126555443 	 Validation Loss 0.9205101132392883
INFO:WNN:Epoch 7: Training Loss 0.26471883803606033 	 Validation Loss 0.9437320232391357
INFO:WNN:Epoch 8: Training Loss 0.2507806122303009 	 Validation Loss 0.9668464064598083
INFO:WNN:Epoch 9: Training Loss 0.23844046890735626 	 Validation Loss 0.9917380809783936
INFO:WNN:Epoch 10: Training Loss 0.22564239986240864 	 Validation Loss 1.013131022453308
INFO:WNN:Epoch 11: Training Loss 0.21243666298687458 	 Validation Loss 1.0261067152023315
INFO:WNN:Epoch 12: Training Loss 0.2065992560237646 	 Validation Loss 1.035046935081482
threshold tensor(5.4020, grad_fn=<MulBackward0>)
