INFO:WNN:Epoch 0: Training Loss 0.6918439641594887 	 Validation Loss 0.6559837460517883
INFO:WNN:Epoch 1: Training Loss 0.28900428861379623 	 Validation Loss 0.31365081667900085
INFO:WNN:Epoch 2: Training Loss 0.3662722408771515 	 Validation Loss 0.2606598138809204
INFO:WNN:Epoch 3: Training Loss 0.2529556266963482 	 Validation Loss 0.20469430088996887
INFO:WNN:Epoch 4: Training Loss 0.2708749324083328 	 Validation Loss 0.17984522879123688
INFO:WNN:Epoch 5: Training Loss 0.22144225612282753 	 Validation Loss 0.1878959983587265
INFO:WNN:Epoch 6: Training Loss 0.19410685822367668 	 Validation Loss 0.18963736295700073
INFO:WNN:Epoch 7: Training Loss 0.20217538625001907 	 Validation Loss 0.17107167840003967
INFO:WNN:Epoch 8: Training Loss 0.1883528009057045 	 Validation Loss 0.14258338510990143
INFO:WNN:Epoch 9: Training Loss 0.1814800761640072 	 Validation Loss 0.09820646792650223
INFO:WNN:Epoch 10: Training Loss 0.16972538828849792 	 Validation Loss 0.06637318432331085
INFO:WNN:Epoch 11: Training Loss 0.1646052524447441 	 Validation Loss 0.07365414500236511
INFO:WNN:Epoch 12: Training Loss 0.15944872424006462 	 Validation Loss 0.11583082377910614
INFO:WNN:Epoch 13: Training Loss 0.15639319084584713 	 Validation Loss 0.12722258269786835
INFO:WNN:Epoch 14: Training Loss 0.15102889202535152 	 Validation Loss 0.0845988467335701
INFO:WNN:Epoch 15: Training Loss 0.14846364594995975 	 Validation Loss 0.06812827289104462
INFO:WNN:Epoch 16: Training Loss 0.14631258882582188 	 Validation Loss 0.08334555476903915
INFO:WNN:Epoch 17: Training Loss 0.1442226879298687 	 Validation Loss 0.08377847075462341
INFO:WNN:Epoch 18: Training Loss 0.14205988124012947 	 Validation Loss 0.07283788919448853
INFO:WNN:Epoch 19: Training Loss 0.14110516011714935 	 Validation Loss 0.0731525719165802
INFO:WNN:Epoch 20: Training Loss 0.13985280133783817 	 Validation Loss 0.06697291135787964
INFO:WNN:Epoch 21: Training Loss 0.13828765414655209 	 Validation Loss 0.06387373805046082
threshold tensor(0.2611, grad_fn=<MulBackward0>)
