INFO:WNN:Epoch 0: Training Loss 0.5390493653714656 	 Validation Loss 1.2927632331848145
INFO:WNN:Epoch 1: Training Loss 0.19226738349534572 	 Validation Loss 0.19075267761945724
INFO:WNN:Epoch 2: Training Loss 0.18695218772627414 	 Validation Loss 0.20477254688739777
INFO:WNN:Epoch 3: Training Loss 0.3859583709156141 	 Validation Loss 1.3243891596794128
INFO:WNN:Epoch 4: Training Loss 0.3200818480458111 	 Validation Loss 0.33751945197582245
INFO:WNN:Epoch 5: Training Loss 0.27056630570441487 	 Validation Loss 0.6924261525273323
INFO:WNN:Epoch 6: Training Loss 0.26687503987923267 	 Validation Loss 0.8777692019939423
INFO:WNN:Epoch 7: Training Loss 0.23719371701590716 	 Validation Loss 2.2146249264478683
INFO:WNN:Epoch 8: Training Loss 0.35948186898604034 	 Validation Loss 2.1055019944906235
INFO:WNN:Epoch 9: Training Loss 0.21688225877005607 	 Validation Loss 0.508790098130703
INFO:WNN:Epoch 10: Training Loss 0.27520551681518557 	 Validation Loss 1.0536933541297913
INFO:WNN:Epoch 11: Training Loss 0.1846824798034504 	 Validation Loss 1.9738809317350388
INFO:WNN:Epoch 12: Training Loss 0.23320311061106622 	 Validation Loss 0.804624430835247
threshold tensor(2.1626, grad_fn=<MulBackward0>)
