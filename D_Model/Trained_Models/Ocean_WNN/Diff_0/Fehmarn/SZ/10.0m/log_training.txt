INFO:WNN:Epoch 0: Training Loss 0.5390493521466851 	 Validation Loss 1.2927632331848145
INFO:WNN:Epoch 1: Training Loss 0.19226738344877958 	 Validation Loss 0.19075268134474754
INFO:WNN:Epoch 2: Training Loss 0.18695214823819697 	 Validation Loss 0.20477254688739777
INFO:WNN:Epoch 3: Training Loss 0.385958262742497 	 Validation Loss 1.3243888914585114
INFO:WNN:Epoch 4: Training Loss 0.3200815145857632 	 Validation Loss 0.33751949667930603
INFO:WNN:Epoch 5: Training Loss 0.2705678393132985 	 Validation Loss 0.6924298480153084
INFO:WNN:Epoch 6: Training Loss 0.26687039202079177 	 Validation Loss 0.8777443617582321
INFO:WNN:Epoch 7: Training Loss 0.23717371691018344 	 Validation Loss 2.2144749760627747
INFO:WNN:Epoch 8: Training Loss 0.3594918202608824 	 Validation Loss 2.104876384139061
INFO:WNN:Epoch 9: Training Loss 0.21682348060421647 	 Validation Loss 0.5087516978383064
INFO:WNN:Epoch 10: Training Loss 0.275237599061802 	 Validation Loss 1.0562202781438828
INFO:WNN:Epoch 11: Training Loss 0.1845112475566566 	 Validation Loss 1.9776068180799484
INFO:WNN:Epoch 12: Training Loss 0.23224773202091456 	 Validation Loss 0.8056775033473969
threshold tensor(2.1649, grad_fn=<MulBackward0>)
