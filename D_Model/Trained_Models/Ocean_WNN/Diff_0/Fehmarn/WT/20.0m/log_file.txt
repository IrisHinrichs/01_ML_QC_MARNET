INFO:WNN:Epoch 0: Training Loss 0.18200951317946115 	 Validation Loss 1.7199342250823975
INFO:WNN:Epoch 1: Training Loss 0.23021471003691354 	 Validation Loss 0.907312273979187
INFO:WNN:Epoch 2: Training Loss 0.2885086453623242 	 Validation Loss 2.5324766635894775
INFO:WNN:Epoch 3: Training Loss 0.33207345919476616 	 Validation Loss 1.1608468294143677
INFO:WNN:Epoch 4: Training Loss 0.3468625168833468 	 Validation Loss 2.165231466293335
INFO:WNN:Epoch 5: Training Loss 0.22558478307392862 	 Validation Loss 1.5100948810577393
INFO:WNN:Epoch 6: Training Loss 0.10491059472163518 	 Validation Loss 1.1293102502822876
INFO:WNN:Epoch 7: Training Loss 0.09739226309789552 	 Validation Loss 1.2301087379455566
INFO:WNN:Epoch 8: Training Loss 0.08615272492170334 	 Validation Loss 1.1282798051834106
INFO:WNN:Epoch 9: Training Loss 0.0826282733016544 	 Validation Loss 1.045343041419983
INFO:WNN:Epoch 10: Training Loss 0.07554619510968526 	 Validation Loss 1.0496901273727417
INFO:WNN:Epoch 11: Training Loss 0.07465666408340137 	 Validation Loss 1.0228434801101685
INFO:WNN:Epoch 12: Training Loss 0.07347242078847355 	 Validation Loss 0.9879958629608154
threshold tensor(5.7921, grad_fn=<MulBackward0>)
