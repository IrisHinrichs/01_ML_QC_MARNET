INFO:WNN:Epoch 0: Training Loss 0.17490221068308326 	 Validation Loss 0.0741284117102623
INFO:WNN:Epoch 1: Training Loss 0.3073511208114926 	 Validation Loss 0.3625837676227093
INFO:WNN:Epoch 2: Training Loss 0.4840390560283494 	 Validation Loss 0.1339104503664809
INFO:WNN:Epoch 3: Training Loss 0.2635409583615708 	 Validation Loss 0.021008007926866412
INFO:WNN:Epoch 4: Training Loss 0.37495647359173745 	 Validation Loss 0.3799334730332096
INFO:WNN:Epoch 5: Training Loss 0.6284388244174706 	 Validation Loss 0.03824593499302864
INFO:WNN:Epoch 6: Training Loss 0.416557147020487 	 Validation Loss 0.31134116742759943
INFO:WNN:Epoch 7: Training Loss 0.5045112466258515 	 Validation Loss 0.2032877535869678
INFO:WNN:Epoch 8: Training Loss 0.09109731697713465 	 Validation Loss 0.023255674401298165
INFO:WNN:Epoch 9: Training Loss 0.046807965121438935 	 Validation Loss 0.0011641918681561947
INFO:WNN:Epoch 10: Training Loss 0.041855790603828304 	 Validation Loss 0.08140170387923717
INFO:WNN:Epoch 11: Training Loss 0.07538210877909376 	 Validation Loss 0.004072641449359556
INFO:WNN:Epoch 12: Training Loss 0.039164305348499004 	 Validation Loss 0.0065651817712932825
INFO:WNN:Epoch 13: Training Loss 0.07457480810505028 	 Validation Loss 0.001230360590852797
INFO:WNN:Epoch 14: Training Loss 0.04001797552660315 	 Validation Loss 0.06758890797694524
INFO:WNN:Epoch 15: Training Loss 0.08067314031844337 	 Validation Loss 0.08359718602150679
INFO:WNN:Epoch 16: Training Loss 0.07986923788121203 	 Validation Loss 0.0203991054246823
INFO:WNN:Epoch 17: Training Loss 0.07991179047773282 	 Validation Loss 0.0035572077613323927
INFO:WNN:Epoch 18: Training Loss 0.03834524339375397 	 Validation Loss 0.01835033514847358
INFO:WNN:Epoch 19: Training Loss 0.03789896658013782 	 Validation Loss 0.020080922326693933
INFO:WNN:Epoch 20: Training Loss 0.07309700150249733 	 Validation Loss 0.12428303683797519
threshold tensor(0.3205, grad_fn=<MulBackward0>)
