INFO:WNN:Epoch 0: Training Loss 0.1749022217764933 	 Validation Loss 0.07412842164436977
INFO:WNN:Epoch 1: Training Loss 0.30735114882069564 	 Validation Loss 0.36258377383152646
INFO:WNN:Epoch 2: Training Loss 0.4840390501772668 	 Validation Loss 0.1339101837365888
INFO:WNN:Epoch 3: Training Loss 0.26354063332109945 	 Validation Loss 0.02100693015381694
INFO:WNN:Epoch 4: Training Loss 0.3749594648316916 	 Validation Loss 0.3799431213410571
INFO:WNN:Epoch 5: Training Loss 0.6284424152270529 	 Validation Loss 0.03823811529825131
INFO:WNN:Epoch 6: Training Loss 0.41654846581999055 	 Validation Loss 0.31126793605896336
INFO:WNN:Epoch 7: Training Loss 0.5046379402693775 	 Validation Loss 0.20342940092086792
INFO:WNN:Epoch 8: Training Loss 0.09105938858232952 	 Validation Loss 0.023270981619134545
INFO:WNN:Epoch 9: Training Loss 0.04688794391404372 	 Validation Loss 0.00115464012681817
INFO:WNN:Epoch 10: Training Loss 0.041649913243923545 	 Validation Loss 0.08023043721914291
INFO:WNN:Epoch 11: Training Loss 0.07507237437352564 	 Validation Loss 0.003910356162426372
INFO:WNN:Epoch 12: Training Loss 0.039543996175375976 	 Validation Loss 0.004989236088780065
INFO:WNN:Epoch 13: Training Loss 0.07474322840830104 	 Validation Loss 0.002016312132279078
INFO:WNN:Epoch 14: Training Loss 0.037865466502909034 	 Validation Loss 0.04761363503833612
INFO:WNN:Epoch 15: Training Loss 0.08267998834101793 	 Validation Loss 0.13502382766455412
INFO:WNN:Epoch 16: Training Loss 0.10025732835897037 	 Validation Loss 0.0095042052368323
INFO:WNN:Epoch 17: Training Loss 0.07357905744397107 	 Validation Loss 0.019188005477190018
INFO:WNN:Epoch 18: Training Loss 0.22980205352683292 	 Validation Loss 0.06582815945148468
INFO:WNN:Epoch 19: Training Loss 0.32707078095215064 	 Validation Loss 0.09061323602994283
INFO:WNN:Epoch 20: Training Loss 0.6952450809832145 	 Validation Loss 0.0774361677467823
threshold tensor(0.2086, grad_fn=<MulBackward0>)
