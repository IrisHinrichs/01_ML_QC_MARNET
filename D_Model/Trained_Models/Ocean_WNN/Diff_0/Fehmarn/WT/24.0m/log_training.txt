INFO:WNN:Epoch 0: Training Loss 0.1937752927378824 	 Validation Loss 0.016318597365170717
INFO:WNN:Epoch 1: Training Loss 0.03087366445793628 	 Validation Loss 0.03997530167301496
INFO:WNN:Epoch 2: Training Loss 0.08001601925126225 	 Validation Loss 0.013601669653629264
INFO:WNN:Epoch 3: Training Loss 0.19256930636604214 	 Validation Loss 0.11244122451171279
INFO:WNN:Epoch 4: Training Loss 0.2044943481644926 	 Validation Loss 0.01566923518354694
INFO:WNN:Epoch 5: Training Loss 0.2928879460442759 	 Validation Loss 0.07462112108866374
INFO:WNN:Epoch 6: Training Loss 0.38778220512904227 	 Validation Loss 0.02284400848050912
INFO:WNN:Epoch 7: Training Loss 0.15476261729013963 	 Validation Loss 0.003918062740315993
INFO:WNN:Epoch 8: Training Loss 0.19960847124012718 	 Validation Loss 0.06229454589386781
INFO:WNN:Epoch 9: Training Loss 0.2292588013778085 	 Validation Loss 0.08297520161916812
INFO:WNN:Epoch 10: Training Loss 0.16496016843524963 	 Validation Loss 0.010128605334709087
INFO:WNN:Epoch 11: Training Loss 0.16241490514948964 	 Validation Loss 0.4982176721096039
INFO:WNN:Epoch 12: Training Loss 0.25863617779042314 	 Validation Loss 0.02800158380220334
INFO:WNN:Epoch 13: Training Loss 0.44596608702704543 	 Validation Loss 0.167290431757768
INFO:WNN:Epoch 14: Training Loss 0.6864628878101939 	 Validation Loss 0.3612235834201177
INFO:WNN:Epoch 15: Training Loss 0.3856607732211867 	 Validation Loss 0.03666119463741779
INFO:WNN:Epoch 16: Training Loss 0.07209273161586477 	 Validation Loss 0.09242073508600394
INFO:WNN:Epoch 17: Training Loss 0.08266850751250684 	 Validation Loss 0.09055778632561366
INFO:WNN:Epoch 18: Training Loss 0.09105980860476848 	 Validation Loss 0.14944790552059808
threshold tensor(0.5355, grad_fn=<MulBackward0>)
