INFO:WNN:Epoch 0: Training Loss 0.1937752969541988 	 Validation Loss 0.01631859433837235
INFO:WNN:Epoch 1: Training Loss 0.03087366153178866 	 Validation Loss 0.039975302293896675
INFO:WNN:Epoch 2: Training Loss 0.08001600665577119 	 Validation Loss 0.01360166328959167
INFO:WNN:Epoch 3: Training Loss 0.1925692553502611 	 Validation Loss 0.11244144942611456
INFO:WNN:Epoch 4: Training Loss 0.2044943290335747 	 Validation Loss 0.01566922649120291
INFO:WNN:Epoch 5: Training Loss 0.29288763169299475 	 Validation Loss 0.07462158054113388
INFO:WNN:Epoch 6: Training Loss 0.38778209856536705 	 Validation Loss 0.022843402499953907
INFO:WNN:Epoch 7: Training Loss 0.15476333144205354 	 Validation Loss 0.003918020520359278
INFO:WNN:Epoch 8: Training Loss 0.19960878759674314 	 Validation Loss 0.06229510282476743
INFO:WNN:Epoch 9: Training Loss 0.22925539929545063 	 Validation Loss 0.08298387595762809
INFO:WNN:Epoch 10: Training Loss 0.1649511560844985 	 Validation Loss 0.010118373048802217
INFO:WNN:Epoch 11: Training Loss 0.162393733419271 	 Validation Loss 0.49830296635627747
INFO:WNN:Epoch 12: Training Loss 0.25861713067004327 	 Validation Loss 0.027984348436196644
INFO:WNN:Epoch 13: Training Loss 0.44593913481205366 	 Validation Loss 0.16724712029099464
INFO:WNN:Epoch 14: Training Loss 0.6862956545616422 	 Validation Loss 0.36116135617097217
INFO:WNN:Epoch 15: Training Loss 0.3853178636555741 	 Validation Loss 0.03575293843944868
INFO:WNN:Epoch 16: Training Loss 0.07217690040771332 	 Validation Loss 0.09294543601572514
INFO:WNN:Epoch 17: Training Loss 0.08145595604421235 	 Validation Loss 0.07356965852280457
INFO:WNN:Epoch 18: Training Loss 0.09532264568083014 	 Validation Loss 0.16860238586862883
threshold tensor(0.6603, grad_fn=<MulBackward0>)
