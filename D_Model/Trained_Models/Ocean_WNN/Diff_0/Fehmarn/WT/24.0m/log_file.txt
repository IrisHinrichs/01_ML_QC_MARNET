INFO:WNN:Epoch 0: Training Loss 0.36125316470861435 	 Validation Loss 2.800990581512451
INFO:WNN:Epoch 1: Training Loss 0.20366446922222772 	 Validation Loss 2.081789493560791
INFO:WNN:Epoch 2: Training Loss 0.1124288272112608 	 Validation Loss 1.6097233295440674
INFO:WNN:Epoch 3: Training Loss 0.12483477592468262 	 Validation Loss 1.5736476182937622
INFO:WNN:Epoch 4: Training Loss 0.08787236455827951 	 Validation Loss 1.906095027923584
INFO:WNN:Epoch 5: Training Loss 0.08490903116762638 	 Validation Loss 2.271785259246826
INFO:WNN:Epoch 6: Training Loss 0.09232839484078188 	 Validation Loss 2.4212403297424316
INFO:WNN:Epoch 7: Training Loss 0.08153990159432094 	 Validation Loss 2.314535617828369
INFO:WNN:Epoch 8: Training Loss 0.07930237303177516 	 Validation Loss 2.1097373962402344
INFO:WNN:Epoch 9: Training Loss 0.07239968205491702 	 Validation Loss 1.982704520225525
INFO:WNN:Epoch 10: Training Loss 0.0692788438561062 	 Validation Loss 1.96547532081604
INFO:WNN:Epoch 11: Training Loss 0.07085980909566085 	 Validation Loss 2.0031533241271973
INFO:WNN:Epoch 12: Training Loss 0.06754517446582516 	 Validation Loss 2.036870241165161
INFO:WNN:Epoch 13: Training Loss 0.06652265810407698 	 Validation Loss 2.007636547088623
threshold tensor(3.6843, grad_fn=<MulBackward0>)
