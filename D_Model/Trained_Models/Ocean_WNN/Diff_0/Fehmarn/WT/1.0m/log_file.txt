INFO:WNN:Epoch 0: Training Loss 0.7279447633773088 	 Validation Loss 0.32595258951187134
INFO:WNN:Epoch 1: Training Loss 0.4047529138624668 	 Validation Loss 0.26582083106040955
INFO:WNN:Epoch 2: Training Loss 0.28526904713362455 	 Validation Loss 0.20062613487243652
INFO:WNN:Epoch 3: Training Loss 0.2858637794852257 	 Validation Loss 0.16101562976837158
INFO:WNN:Epoch 4: Training Loss 0.2282467084005475 	 Validation Loss 0.15085777640342712
INFO:WNN:Epoch 5: Training Loss 0.19851491693407297 	 Validation Loss 0.1328374743461609
INFO:WNN:Epoch 6: Training Loss 0.15010319091379642 	 Validation Loss 0.10734537988901138
INFO:WNN:Epoch 7: Training Loss 0.1430988796055317 	 Validation Loss 0.10117064416408539
INFO:WNN:Epoch 8: Training Loss 0.1247232099995017 	 Validation Loss 0.10444912314414978
INFO:WNN:Epoch 9: Training Loss 0.1125092739239335 	 Validation Loss 0.1069960966706276
INFO:WNN:Epoch 10: Training Loss 0.10171616822481155 	 Validation Loss 0.11079337447881699
INFO:WNN:Epoch 11: Training Loss 0.09580872301012278 	 Validation Loss 0.11358343809843063
INFO:WNN:Epoch 12: Training Loss 0.08748986339196563 	 Validation Loss 0.11475156247615814
INFO:WNN:Epoch 13: Training Loss 0.08512861980125308 	 Validation Loss 0.11803856492042542
INFO:WNN:Epoch 14: Training Loss 0.08119173999875784 	 Validation Loss 0.119398333132267
INFO:WNN:Epoch 15: Training Loss 0.0771182393655181 	 Validation Loss 0.117469921708107
INFO:WNN:Epoch 16: Training Loss 0.07480014627799392 	 Validation Loss 0.11328175663948059
INFO:WNN:Epoch 17: Training Loss 0.07151606027036905 	 Validation Loss 0.11135678738355637
INFO:WNN:Epoch 18: Training Loss 0.0694535244256258 	 Validation Loss 0.11124406009912491
threshold tensor(1.0665, grad_fn=<MulBackward0>)
