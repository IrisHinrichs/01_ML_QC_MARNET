INFO:WNN:Epoch 0: Training Loss 0.1897619913215749 	 Validation Loss 0.022553854311505955
INFO:WNN:Epoch 1: Training Loss 0.05436541402539458 	 Validation Loss 0.01553721772506833
INFO:WNN:Epoch 2: Training Loss 0.08371475502564055 	 Validation Loss 0.026383978004256885
INFO:WNN:Epoch 3: Training Loss 0.22414785309229046 	 Validation Loss 0.08851601928472519
INFO:WNN:Epoch 4: Training Loss 0.25827466176835717 	 Validation Loss 0.0704591516405344
INFO:WNN:Epoch 5: Training Loss 0.6652750445743246 	 Validation Loss 0.14495093251268068
INFO:WNN:Epoch 6: Training Loss 0.2725988839908193 	 Validation Loss 0.17455133174856505
INFO:WNN:Epoch 7: Training Loss 0.11845844188549866 	 Validation Loss 0.112983042995135
INFO:WNN:Epoch 8: Training Loss 0.11598392863137026 	 Validation Loss 0.13997987533609071
INFO:WNN:Epoch 9: Training Loss 0.07174155856126971 	 Validation Loss 0.04573472092549006
INFO:WNN:Epoch 10: Training Loss 0.09447990250353339 	 Validation Loss 0.22916113336881003
INFO:WNN:Epoch 11: Training Loss 0.20163127064329778 	 Validation Loss 0.3457741936047872
INFO:WNN:Epoch 12: Training Loss 0.1907626486564469 	 Validation Loss 0.05723703280091286
threshold tensor(0.2755, grad_fn=<MulBackward0>)
