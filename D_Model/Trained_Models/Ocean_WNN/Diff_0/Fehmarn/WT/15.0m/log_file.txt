INFO:WNN:Epoch 0: Training Loss 0.4277516310253451 	 Validation Loss 0.04383382201194763
INFO:WNN:Epoch 1: Training Loss 0.1972324797703374 	 Validation Loss 0.02534482441842556
INFO:WNN:Epoch 2: Training Loss 0.11991358404198 	 Validation Loss 0.020722591318190098
INFO:WNN:Epoch 3: Training Loss 0.10519544798279962 	 Validation Loss 0.018221380189061165
INFO:WNN:Epoch 4: Training Loss 0.15974961263277837 	 Validation Loss 0.02185669564642012
INFO:WNN:Epoch 5: Training Loss 0.15873728620429192 	 Validation Loss 0.02785298600792885
INFO:WNN:Epoch 6: Training Loss 0.12585929486780398 	 Validation Loss 0.021113333059474826
INFO:WNN:Epoch 7: Training Loss 0.08656667154883185 	 Validation Loss 0.017871441785246134
INFO:WNN:Epoch 8: Training Loss 0.0846617071618957 	 Validation Loss 0.01769598643295467
INFO:WNN:Epoch 9: Training Loss 0.07857896844225545 	 Validation Loss 0.016515125171281397
INFO:WNN:Epoch 10: Training Loss 0.07863783665121563 	 Validation Loss 0.01655317028053105
INFO:WNN:Epoch 11: Training Loss 0.07831639120535504 	 Validation Loss 0.01674202224239707
INFO:WNN:Epoch 12: Training Loss 0.07857445849766655 	 Validation Loss 0.01739927940070629
INFO:WNN:Epoch 13: Training Loss 0.08319622975203299 	 Validation Loss 0.020828531123697758
INFO:WNN:Epoch 14: Training Loss 0.11332593786139641 	 Validation Loss 0.02208538679406047
INFO:WNN:Epoch 15: Training Loss 0.13115516058619944 	 Validation Loss 0.018891110783442855
INFO:WNN:Epoch 16: Training Loss 0.0913560826691889 	 Validation Loss 0.019224653486162424
INFO:WNN:Epoch 17: Training Loss 0.08982462087465871 	 Validation Loss 0.01846813317388296
INFO:WNN:Epoch 18: Training Loss 0.07960893111603876 	 Validation Loss 0.01742990594357252
INFO:WNN:Epoch 19: Training Loss 0.08922252401469215 	 Validation Loss 0.018827600870281458
INFO:WNN:Epoch 20: Training Loss 0.08134210524299453 	 Validation Loss 0.016079194960184395
threshold tensor(0.2981, grad_fn=<MulBackward0>)
