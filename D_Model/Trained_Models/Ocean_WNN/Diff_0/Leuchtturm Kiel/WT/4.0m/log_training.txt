INFO:WNN:Epoch 0: Training Loss 0.15575754980529874 	 Validation Loss 0.2649679072201252
INFO:WNN:Epoch 1: Training Loss 0.32044186148448806 	 Validation Loss 0.45527973771095276
INFO:WNN:Epoch 2: Training Loss 0.21192424955208683 	 Validation Loss 0.2923269644379616
INFO:WNN:Epoch 3: Training Loss 1.1577925295365739 	 Validation Loss 0.1526016816496849
INFO:WNN:Epoch 4: Training Loss 0.5155266065899807 	 Validation Loss 0.5734132006764412
INFO:WNN:Epoch 5: Training Loss 0.3159199854310986 	 Validation Loss 0.4584444221109152
INFO:WNN:Epoch 6: Training Loss 0.41229581466362264 	 Validation Loss 0.25670607201755047
INFO:WNN:Epoch 7: Training Loss 0.2304849115852636 	 Validation Loss 0.21039790101349354
INFO:WNN:Epoch 8: Training Loss 0.19755071403905897 	 Validation Loss 0.29563311487436295
INFO:WNN:Epoch 9: Training Loss 0.1285301331464859 	 Validation Loss 0.8988541439175606
INFO:WNN:Epoch 10: Training Loss 0.13486179252735353 	 Validation Loss 0.031699797604233027
INFO:WNN:Epoch 11: Training Loss 0.16954104115771654 	 Validation Loss 0.1781687936745584
INFO:WNN:Epoch 12: Training Loss 0.43165317572383505 	 Validation Loss 0.7962270304560661
INFO:WNN:Epoch 13: Training Loss 1.1972827625946911 	 Validation Loss 0.07577582495287061
INFO:WNN:Epoch 14: Training Loss 0.5159170601795527 	 Validation Loss 0.08362021553330123
INFO:WNN:Epoch 15: Training Loss 0.21710716292311968 	 Validation Loss 0.027235488407313824
INFO:WNN:Epoch 16: Training Loss 0.29223542466992053 	 Validation Loss 0.03377134806942195
INFO:WNN:Epoch 17: Training Loss 0.23021668793623418 	 Validation Loss 1.3969974964857101
INFO:WNN:Epoch 18: Training Loss 0.12781841521537568 	 Validation Loss 0.3669068068265915
INFO:WNN:Epoch 19: Training Loss 0.11116721874864269 	 Validation Loss 0.09993915632367134
INFO:WNN:Epoch 20: Training Loss 0.2620847593024669 	 Validation Loss 0.1478549875319004
INFO:WNN:Epoch 21: Training Loss 0.6104396328742113 	 Validation Loss 0.060399753390811384
INFO:WNN:Epoch 22: Training Loss 0.2702384817909213 	 Validation Loss 0.08375417906790972
INFO:WNN:Epoch 23: Training Loss 0.5384080752666618 	 Validation Loss 0.04934884875547141
INFO:WNN:Epoch 24: Training Loss 0.6192023155421743 	 Validation Loss 0.00791768275666982
INFO:WNN:Epoch 25: Training Loss 0.5820485024624282 	 Validation Loss 0.09818201884627342
INFO:WNN:Epoch 26: Training Loss 0.5449713267300959 	 Validation Loss 0.013011165778152645
INFO:WNN:Epoch 27: Training Loss 0.5378566779333004 	 Validation Loss 0.019859208492562175
INFO:WNN:Epoch 28: Training Loss 0.5927795131657538 	 Validation Loss 0.005284855666104704
INFO:WNN:Epoch 29: Training Loss 0.5230953512465699 	 Validation Loss 0.20538315549492836
INFO:WNN:Epoch 30: Training Loss 0.5572536210492549 	 Validation Loss 0.09224048722535372
INFO:WNN:Epoch 31: Training Loss 0.33083645169695264 	 Validation Loss 0.756158908829093
INFO:WNN:Epoch 32: Training Loss 0.26533530649448084 	 Validation Loss 0.07030712068080902
INFO:WNN:Epoch 33: Training Loss 0.20523748670506942 	 Validation Loss 0.09893524367362261
INFO:WNN:Epoch 34: Training Loss 0.2782664613526625 	 Validation Loss 1.225772462785244
INFO:WNN:Epoch 35: Training Loss 0.2688657403480084 	 Validation Loss 0.04796768515370786
INFO:WNN:Epoch 36: Training Loss 0.21561873974629664 	 Validation Loss 0.024405606323853135
INFO:WNN:Epoch 37: Training Loss 0.12410729196337689 	 Validation Loss 0.46165989339351654
INFO:WNN:Epoch 38: Training Loss 0.20377369551912008 	 Validation Loss 0.40739091858267784
INFO:WNN:Epoch 39: Training Loss 0.12466230348634001 	 Validation Loss 1.785780355334282
threshold tensor(3.1386, grad_fn=<MulBackward0>)
