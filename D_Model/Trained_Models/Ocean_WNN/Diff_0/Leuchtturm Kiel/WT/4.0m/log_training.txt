INFO:WNN:Epoch 0: Training Loss 0.15575755444528083 	 Validation Loss 0.2649678774178028
INFO:WNN:Epoch 1: Training Loss 0.3204418299941435 	 Validation Loss 0.45527931302785873
INFO:WNN:Epoch 2: Training Loss 0.21192422374946226 	 Validation Loss 0.29232694767415524
INFO:WNN:Epoch 3: Training Loss 1.1577894397796915 	 Validation Loss 0.152600334957242
INFO:WNN:Epoch 4: Training Loss 0.515524985471053 	 Validation Loss 0.5734229423105717
INFO:WNN:Epoch 5: Training Loss 0.31589858934083687 	 Validation Loss 0.45801636669784784
INFO:WNN:Epoch 6: Training Loss 0.41251504011563067 	 Validation Loss 0.2563506942242384
INFO:WNN:Epoch 7: Training Loss 0.23186132403290166 	 Validation Loss 0.20619921293109655
INFO:WNN:Epoch 8: Training Loss 0.20230244303312492 	 Validation Loss 0.3064340874552727
INFO:WNN:Epoch 9: Training Loss 0.13263394318508087 	 Validation Loss 1.433806911110878
INFO:WNN:Epoch 10: Training Loss 0.11665855623857443 	 Validation Loss 0.2090067584067583
INFO:WNN:Epoch 11: Training Loss 0.17681499496046899 	 Validation Loss 0.04688110062852502
INFO:WNN:Epoch 12: Training Loss 0.3986457189848085 	 Validation Loss 0.9023950397968292
INFO:WNN:Epoch 13: Training Loss 0.9934058977565395 	 Validation Loss 0.0622361374553293
INFO:WNN:Epoch 14: Training Loss 0.6740099385176961 	 Validation Loss 0.1423576893284917
INFO:WNN:Epoch 15: Training Loss 0.2401857318976591 	 Validation Loss 0.149625722784549
INFO:WNN:Epoch 16: Training Loss 0.43537721949230346 	 Validation Loss 0.23079607263207436
INFO:WNN:Epoch 17: Training Loss 0.6644741078600331 	 Validation Loss 0.13858777657151222
INFO:WNN:Epoch 18: Training Loss 0.39942896497871966 	 Validation Loss 0.09069369919598103
INFO:WNN:Epoch 19: Training Loss 0.3725737551576458 	 Validation Loss 0.07409784570336342
INFO:WNN:Epoch 20: Training Loss 0.16472548398832304 	 Validation Loss 0.03386065340600908
INFO:WNN:Epoch 21: Training Loss 0.12626436173579553 	 Validation Loss 0.40563974902033806
INFO:WNN:Epoch 22: Training Loss 0.18354835811150555 	 Validation Loss 0.33938030898571014
INFO:WNN:Epoch 23: Training Loss 0.45832212740141487 	 Validation Loss 0.013957398186903447
INFO:WNN:Epoch 24: Training Loss 0.35091070672183017 	 Validation Loss 0.24353413470089436
INFO:WNN:Epoch 25: Training Loss 0.17673803190793103 	 Validation Loss 0.28254674188792706
INFO:WNN:Epoch 26: Training Loss 0.21862178342601668 	 Validation Loss 0.041265574749559164
INFO:WNN:Epoch 27: Training Loss 0.27064962285785155 	 Validation Loss 0.08785986807197332
INFO:WNN:Epoch 28: Training Loss 0.23754111327423108 	 Validation Loss 0.009077964816242456
INFO:WNN:Epoch 29: Training Loss 0.17775788881385418 	 Validation Loss 0.10196693986654282
INFO:WNN:Epoch 30: Training Loss 0.2364782327841524 	 Validation Loss 0.07599527575075626
INFO:WNN:Epoch 31: Training Loss 0.3984927178521286 	 Validation Loss 0.03371313354000449
INFO:WNN:Epoch 32: Training Loss 0.49994239463870016 	 Validation Loss 0.9792952015995979
INFO:WNN:Epoch 33: Training Loss 0.41545102410646717 	 Validation Loss 0.027646723203361034
INFO:WNN:Epoch 34: Training Loss 0.18688682676477741 	 Validation Loss 0.015525072580203414
INFO:WNN:Epoch 35: Training Loss 0.357870547350363 	 Validation Loss 0.09055433608591557
INFO:WNN:Epoch 36: Training Loss 0.11778756444035689 	 Validation Loss 0.014562040800228715
INFO:WNN:Epoch 37: Training Loss 0.36305407286133795 	 Validation Loss 0.025183033081702888
INFO:WNN:Epoch 38: Training Loss 0.4137032160420887 	 Validation Loss 0.045211720280349255
INFO:WNN:Epoch 39: Training Loss 0.33759716952160473 	 Validation Loss 0.6862781941890717
threshold tensor(1.2102, grad_fn=<MulBackward0>)
