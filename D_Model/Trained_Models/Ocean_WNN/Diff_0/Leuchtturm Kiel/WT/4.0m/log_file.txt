INFO:WNN:Epoch 0: Training Loss 0.624584436416626 	 Validation Loss 0.3498360514640808
INFO:WNN:Epoch 1: Training Loss 0.46030321419239045 	 Validation Loss 0.21275514364242554
INFO:WNN:Epoch 2: Training Loss 0.3301440790295601 	 Validation Loss 0.25344234704971313
INFO:WNN:Epoch 3: Training Loss 0.27782506346702573 	 Validation Loss 0.18494822084903717
INFO:WNN:Epoch 4: Training Loss 0.2311459705233574 	 Validation Loss 0.14921437203884125
INFO:WNN:Epoch 5: Training Loss 0.20958280563354492 	 Validation Loss 0.14127257466316223
INFO:WNN:Epoch 6: Training Loss 0.17677459865808487 	 Validation Loss 0.13380572199821472
INFO:WNN:Epoch 7: Training Loss 0.16196265518665315 	 Validation Loss 0.12780989706516266
INFO:WNN:Epoch 8: Training Loss 0.15108327865600585 	 Validation Loss 0.11227582395076752
INFO:WNN:Epoch 9: Training Loss 0.13661276996135713 	 Validation Loss 0.10945707559585571
INFO:WNN:Epoch 10: Training Loss 0.1289776161313057 	 Validation Loss 0.10457134991884232
INFO:WNN:Epoch 11: Training Loss 0.12046913504600525 	 Validation Loss 0.10360075533390045
INFO:WNN:Epoch 12: Training Loss 0.11751001477241516 	 Validation Loss 0.0983700379729271
INFO:WNN:Epoch 13: Training Loss 0.10947439298033715 	 Validation Loss 0.11623554676771164
INFO:WNN:Epoch 14: Training Loss 0.11485700905323029 	 Validation Loss 0.10408766567707062
INFO:WNN:Epoch 15: Training Loss 0.10977784991264343 	 Validation Loss 0.1293327957391739
INFO:WNN:Epoch 16: Training Loss 0.11792908012866973 	 Validation Loss 0.10599789768457413
INFO:WNN:Epoch 17: Training Loss 0.11423301249742508 	 Validation Loss 0.12577557563781738
INFO:WNN:Epoch 18: Training Loss 0.12753898054361343 	 Validation Loss 0.09845191985368729
INFO:WNN:Epoch 19: Training Loss 0.12622860968112945 	 Validation Loss 0.1076367124915123
INFO:WNN:Epoch 20: Training Loss 0.1422440618276596 	 Validation Loss 0.09175671637058258
INFO:WNN:Epoch 21: Training Loss 0.11811045855283737 	 Validation Loss 0.09421570599079132
INFO:WNN:Epoch 22: Training Loss 0.11020702272653579 	 Validation Loss 0.1044836938381195
INFO:WNN:Epoch 23: Training Loss 0.08529571518301964 	 Validation Loss 0.09485181421041489
INFO:WNN:Epoch 24: Training Loss 0.0848424844443798 	 Validation Loss 0.10909830033779144
INFO:WNN:Epoch 25: Training Loss 0.08567415326833724 	 Validation Loss 0.09849361330270767
INFO:WNN:Epoch 26: Training Loss 0.07890535593032837 	 Validation Loss 0.10504040867090225
INFO:WNN:Epoch 27: Training Loss 0.07923793494701385 	 Validation Loss 0.10185763239860535
INFO:WNN:Epoch 28: Training Loss 0.07319134175777435 	 Validation Loss 0.10174186527729034
INFO:WNN:Epoch 29: Training Loss 0.07270674780011177 	 Validation Loss 0.10435742139816284
INFO:WNN:Epoch 30: Training Loss 0.06954078823328018 	 Validation Loss 0.10402054339647293
INFO:WNN:Epoch 31: Training Loss 0.06892402842640877 	 Validation Loss 0.10460571944713593
threshold tensor(0.8403, grad_fn=<MulBackward0>)
