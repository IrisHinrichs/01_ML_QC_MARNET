INFO:WNN:Epoch 0: Training Loss 0.4233321522224287 	 Validation Loss 0.4881649762392044
INFO:WNN:Epoch 1: Training Loss 0.794050381759007 	 Validation Loss 0.022076777182519436
INFO:WNN:Epoch 2: Training Loss 0.7545747180047329 	 Validation Loss 2.0268412828445435
INFO:WNN:Epoch 3: Training Loss 0.5960297363926657 	 Validation Loss 0.19574023876339197
INFO:WNN:Epoch 4: Training Loss 0.39508255463442765 	 Validation Loss 0.6500721722841263
INFO:WNN:Epoch 5: Training Loss 0.6044780590964365 	 Validation Loss 1.477450042963028
INFO:WNN:Epoch 6: Training Loss 0.8155883268336765 	 Validation Loss 1.7879467010498047
INFO:WNN:Epoch 7: Training Loss 0.8089866576483473 	 Validation Loss 1.2717164158821106
INFO:WNN:Epoch 8: Training Loss 0.39010472299560206 	 Validation Loss 0.8600547909736633
INFO:WNN:Epoch 9: Training Loss 0.338007309299428 	 Validation Loss 0.24718423187732697
INFO:WNN:Epoch 10: Training Loss 0.1621361609795713 	 Validation Loss 0.5025020837783813
INFO:WNN:Epoch 11: Training Loss 0.26555134802038083 	 Validation Loss 0.10486806184053421
INFO:WNN:Epoch 12: Training Loss 0.2744254576682579 	 Validation Loss 0.5041555315256119
threshold tensor(1.8316, grad_fn=<MulBackward0>)
