INFO:WNN:Epoch 0: Training Loss 0.15208126378016576 	 Validation Loss 0.06460480857640505
INFO:WNN:Epoch 1: Training Loss 0.32802169335134806 	 Validation Loss 0.12993581593036652
INFO:WNN:Epoch 2: Training Loss 0.15293915542368328 	 Validation Loss 0.2225242992863059
INFO:WNN:Epoch 3: Training Loss 1.0640975125922612 	 Validation Loss 0.07005188544280827
INFO:WNN:Epoch 4: Training Loss 0.6321483900209123 	 Validation Loss 0.0838099243119359
INFO:WNN:Epoch 5: Training Loss 0.2586938181353147 	 Validation Loss 0.08765449048951268
INFO:WNN:Epoch 6: Training Loss 0.15082908142170298 	 Validation Loss 0.11739349365234375
INFO:WNN:Epoch 7: Training Loss 0.18242174766172894 	 Validation Loss 0.1490323469042778
INFO:WNN:Epoch 8: Training Loss 0.39696141877474506 	 Validation Loss 0.1373441074974835
INFO:WNN:Epoch 9: Training Loss 0.575649130289563 	 Validation Loss 0.11735744494944811
INFO:WNN:Epoch 10: Training Loss 0.4967755203589707 	 Validation Loss 0.17591651156544685
INFO:WNN:Epoch 11: Training Loss 1.2470848768782397 	 Validation Loss 0.08723850641399622
threshold tensor(0.2804, grad_fn=<MulBackward0>)
