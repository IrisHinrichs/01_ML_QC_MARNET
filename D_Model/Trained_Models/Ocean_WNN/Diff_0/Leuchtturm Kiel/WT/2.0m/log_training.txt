INFO:WNN:Epoch 0: Training Loss 0.15208126646522882 	 Validation Loss 0.06460481137037277
INFO:WNN:Epoch 1: Training Loss 0.32802169107373863 	 Validation Loss 0.1299358494579792
INFO:WNN:Epoch 2: Training Loss 0.15293910940301664 	 Validation Loss 0.22252405155450106
INFO:WNN:Epoch 3: Training Loss 1.0640971500993586 	 Validation Loss 0.07005180686246604
INFO:WNN:Epoch 4: Training Loss 0.6321481529340681 	 Validation Loss 0.08381023071706295
INFO:WNN:Epoch 5: Training Loss 0.2587037983917511 	 Validation Loss 0.08766104909591377
INFO:WNN:Epoch 6: Training Loss 0.15080466443642734 	 Validation Loss 0.11743105947971344
INFO:WNN:Epoch 7: Training Loss 0.18251535781065845 	 Validation Loss 0.14954876713454723
INFO:WNN:Epoch 8: Training Loss 0.3962310130356796 	 Validation Loss 0.13750193687155843
INFO:WNN:Epoch 9: Training Loss 0.5807443782912507 	 Validation Loss 0.12123660836368799
INFO:WNN:Epoch 10: Training Loss 0.5035564314288598 	 Validation Loss 0.17258286848664284
INFO:WNN:Epoch 11: Training Loss 1.2579713334111617 	 Validation Loss 0.06581310834735632
threshold tensor(0.2657, grad_fn=<MulBackward0>)
