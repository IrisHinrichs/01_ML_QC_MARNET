INFO:WNN:Epoch 0: Training Loss 0.15701679763520907 	 Validation Loss 0.30976665019989014
INFO:WNN:Epoch 1: Training Loss 0.3421284299367385 	 Validation Loss 0.5340959578752518
INFO:WNN:Epoch 2: Training Loss 0.23908808076151808 	 Validation Loss 0.5393389314413071
INFO:WNN:Epoch 3: Training Loss 1.4376746711121606 	 Validation Loss 0.05080005154013634
INFO:WNN:Epoch 4: Training Loss 0.675245674297912 	 Validation Loss 0.34727586433291435
INFO:WNN:Epoch 5: Training Loss 0.20596798262663973 	 Validation Loss 0.09524249192327261
INFO:WNN:Epoch 6: Training Loss 0.23169614620634266 	 Validation Loss 0.1507148090749979
INFO:WNN:Epoch 7: Training Loss 0.2119479575416162 	 Validation Loss 0.29518723115324974
INFO:WNN:Epoch 8: Training Loss 0.19165691328170295 	 Validation Loss 0.2790913376957178
INFO:WNN:Epoch 9: Training Loss 0.19506960980259694 	 Validation Loss 0.04389207158237696
INFO:WNN:Epoch 10: Training Loss 0.07473850614688773 	 Validation Loss 0.48309021443128586
INFO:WNN:Epoch 11: Training Loss 0.18370656616891556 	 Validation Loss 0.32689570635557175
INFO:WNN:Epoch 12: Training Loss 0.2190055321495045 	 Validation Loss 0.7652612775564194
INFO:WNN:Epoch 13: Training Loss 0.37315908669113435 	 Validation Loss 1.271579384803772
INFO:WNN:Epoch 14: Training Loss 0.8029832886716736 	 Validation Loss 0.6006554737687111
INFO:WNN:Epoch 15: Training Loss 0.6900792938383621 	 Validation Loss 0.647792711853981
INFO:WNN:Epoch 16: Training Loss 0.295042060879207 	 Validation Loss 0.3918616287410259
INFO:WNN:Epoch 17: Training Loss 0.2839243907309581 	 Validation Loss 0.6092980839312077
INFO:WNN:Epoch 18: Training Loss 0.3373094412215453 	 Validation Loss 0.1873763846233487
INFO:WNN:Epoch 19: Training Loss 0.6343318570455138 	 Validation Loss 0.10367765091359615
INFO:WNN:Epoch 20: Training Loss 0.6653089434447115 	 Validation Loss 0.7752304151654243
threshold tensor(1.3228, grad_fn=<MulBackward0>)
