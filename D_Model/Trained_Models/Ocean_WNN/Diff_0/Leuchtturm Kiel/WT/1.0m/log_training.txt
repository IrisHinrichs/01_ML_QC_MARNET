INFO:WNN:Epoch 0: Training Loss 0.15603527597646924 	 Validation Loss 0.3214950729161501
INFO:WNN:Epoch 1: Training Loss 0.3415658727264224 	 Validation Loss 0.5927490442991257
INFO:WNN:Epoch 2: Training Loss 0.2446211144653341 	 Validation Loss 0.5083222836256027
INFO:WNN:Epoch 3: Training Loss 1.4679771762457676 	 Validation Loss 0.03058607899583876
INFO:WNN:Epoch 4: Training Loss 0.6676953915739432 	 Validation Loss 0.29359949473291636
INFO:WNN:Epoch 5: Training Loss 0.20467019474802775 	 Validation Loss 0.14377142256125808
INFO:WNN:Epoch 6: Training Loss 0.22576050071109507 	 Validation Loss 0.1005014693364501
INFO:WNN:Epoch 7: Training Loss 0.13514135959086984 	 Validation Loss 0.19892998412251472
INFO:WNN:Epoch 8: Training Loss 0.11939720961215373 	 Validation Loss 0.30126986652612686
INFO:WNN:Epoch 9: Training Loss 0.19085024937429274 	 Validation Loss 0.22008882090449333
INFO:WNN:Epoch 10: Training Loss 0.24658799826330136 	 Validation Loss 0.07763804099522531
INFO:WNN:Epoch 11: Training Loss 0.2941328999688036 	 Validation Loss 0.11808417551219463
INFO:WNN:Epoch 12: Training Loss 0.46479626711631666 	 Validation Loss 1.299595132470131
INFO:WNN:Epoch 13: Training Loss 1.6316708655924432 	 Validation Loss 0.12069832533597946
INFO:WNN:Epoch 14: Training Loss 0.8418421136762296 	 Validation Loss 0.39373547956347466
threshold tensor(0.6407, grad_fn=<MulBackward0>)
