INFO:WNN:Epoch 0: Training Loss 0.15603528586022244 	 Validation Loss 0.3214949443936348
INFO:WNN:Epoch 1: Training Loss 0.34156589920952224 	 Validation Loss 0.5927491262555122
INFO:WNN:Epoch 2: Training Loss 0.24462115662153958 	 Validation Loss 0.5083221793174744
INFO:WNN:Epoch 3: Training Loss 1.4679778068185976 	 Validation Loss 0.03058701241388917
INFO:WNN:Epoch 4: Training Loss 0.667692803755118 	 Validation Loss 0.29360977839678526
INFO:WNN:Epoch 5: Training Loss 0.20468520092415726 	 Validation Loss 0.14383177179843187
INFO:WNN:Epoch 6: Training Loss 0.22577524421545345 	 Validation Loss 0.1005359124392271
INFO:WNN:Epoch 7: Training Loss 0.13506987834874068 	 Validation Loss 0.1984112374484539
INFO:WNN:Epoch 8: Training Loss 0.11977351654324651 	 Validation Loss 0.2945897150784731
INFO:WNN:Epoch 9: Training Loss 0.18411967737899562 	 Validation Loss 0.21882317773997784
INFO:WNN:Epoch 10: Training Loss 0.24015610834809079 	 Validation Loss 0.09201175207272172
INFO:WNN:Epoch 11: Training Loss 0.2958729560801109 	 Validation Loss 0.1958542838692665
INFO:WNN:Epoch 12: Training Loss 0.5180251156756034 	 Validation Loss 0.004848273703828454
INFO:WNN:Epoch 13: Training Loss 1.1671934090028073 	 Validation Loss 0.11104713939130306
INFO:WNN:Epoch 14: Training Loss 0.7382886682845844 	 Validation Loss 0.4003252238035202
INFO:WNN:Epoch 15: Training Loss 0.20790749165693312 	 Validation Loss 0.7439604476094246
INFO:WNN:Epoch 16: Training Loss 0.24653299383464314 	 Validation Loss 0.43030817806720734
INFO:WNN:Epoch 17: Training Loss 0.31986584638001486 	 Validation Loss 0.07278276793658733
INFO:WNN:Epoch 18: Training Loss 0.3565543658463404 	 Validation Loss 0.07996882870793343
INFO:WNN:Epoch 19: Training Loss 0.40420491414445836 	 Validation Loss 0.12351856753230095
INFO:WNN:Epoch 20: Training Loss 0.30898749454700875 	 Validation Loss 0.004046877671498805
INFO:WNN:Epoch 21: Training Loss 0.2168964735400449 	 Validation Loss 0.26796203199774027
INFO:WNN:Epoch 22: Training Loss 0.2149349007993892 	 Validation Loss 0.003992467449279502
INFO:WNN:Epoch 23: Training Loss 0.5451350168487619 	 Validation Loss 0.0452943854033947
INFO:WNN:Epoch 24: Training Loss 0.8250936387820051 	 Validation Loss 0.09388026222586632
INFO:WNN:Epoch 25: Training Loss 0.7637490458631268 	 Validation Loss 0.10053756227716804
INFO:WNN:Epoch 26: Training Loss 0.6588009191586429 	 Validation Loss 0.010132132389117032
INFO:WNN:Epoch 27: Training Loss 0.3723922324476469 	 Validation Loss 0.11091619543731213
INFO:WNN:Epoch 28: Training Loss 0.4206971675009718 	 Validation Loss 0.10040571540594101
INFO:WNN:Epoch 29: Training Loss 0.4021547526834414 	 Validation Loss 0.03775386279448867
INFO:WNN:Epoch 30: Training Loss 0.3296362498132068 	 Validation Loss 0.2344361450523138
INFO:WNN:Epoch 31: Training Loss 0.38157322403738303 	 Validation Loss 0.05068398918956518
threshold tensor(0.1171, grad_fn=<MulBackward0>)
