INFO:WNN:Epoch 0: Training Loss 0.5111749176681042 	 Validation Loss 0.3578944653272629
INFO:WNN:Epoch 1: Training Loss 0.5413146407157182 	 Validation Loss 0.08196979761123657
INFO:WNN:Epoch 2: Training Loss 0.32527524274773895 	 Validation Loss 0.06853508949279785
INFO:WNN:Epoch 3: Training Loss 0.14720062308944762 	 Validation Loss 0.0299103744328022
INFO:WNN:Epoch 4: Training Loss 0.12079530467279255 	 Validation Loss 0.0336660067550838
INFO:WNN:Epoch 5: Training Loss 0.09344903221353888 	 Validation Loss 0.0335117825306952
INFO:WNN:Epoch 6: Training Loss 0.05878997611813247 	 Validation Loss 0.021226797718554735
INFO:WNN:Epoch 7: Training Loss 0.05352795032784343 	 Validation Loss 0.040337907150387764
INFO:WNN:Epoch 8: Training Loss 0.06615412693470717 	 Validation Loss 0.024103387258946896
INFO:WNN:Epoch 9: Training Loss 0.07423345612827688 	 Validation Loss 0.05424838978797197
INFO:WNN:Epoch 10: Training Loss 0.13947699047625065 	 Validation Loss 0.09233836643397808
INFO:WNN:Epoch 11: Training Loss 0.08341968666762113 	 Validation Loss 0.019435306079685688
INFO:WNN:Epoch 12: Training Loss 0.16367220051586628 	 Validation Loss 0.030307927168905735
INFO:WNN:Epoch 13: Training Loss 0.1005667916033417 	 Validation Loss 0.01855246163904667
INFO:WNN:Epoch 14: Training Loss 0.08879402916878462 	 Validation Loss 0.022495579905807972
INFO:WNN:Epoch 15: Training Loss 0.10749608907848597 	 Validation Loss 0.024959491565823555
INFO:WNN:Epoch 16: Training Loss 0.10328962682746351 	 Validation Loss 0.023356997407972813
INFO:WNN:Epoch 17: Training Loss 0.0686996230110526 	 Validation Loss 0.03388283494859934
INFO:WNN:Epoch 18: Training Loss 0.04140011820010841 	 Validation Loss 0.024002423509955406
INFO:WNN:Epoch 19: Training Loss 0.058164002173580226 	 Validation Loss 0.06458787433803082
INFO:WNN:Epoch 20: Training Loss 0.09193128626793623 	 Validation Loss 0.026194177567958832
INFO:WNN:Epoch 21: Training Loss 0.0685846757516265 	 Validation Loss 0.020330501720309258
INFO:WNN:Epoch 22: Training Loss 0.030270320507697762 	 Validation Loss 0.008750997949391603
INFO:WNN:Epoch 23: Training Loss 0.019212519628927113 	 Validation Loss 0.007167454343289137
INFO:WNN:Epoch 24: Training Loss 0.014739456987008452 	 Validation Loss 0.005015025264583528
INFO:WNN:Epoch 25: Training Loss 0.014389188871718942 	 Validation Loss 0.005424898641649634
INFO:WNN:Epoch 26: Training Loss 0.014015667813364416 	 Validation Loss 0.005237954435870051
INFO:WNN:Epoch 27: Training Loss 0.017454378581605853 	 Validation Loss 0.006357417267281562
INFO:WNN:Epoch 28: Training Loss 0.021601864784024656 	 Validation Loss 0.007263433071784675
INFO:WNN:Epoch 29: Training Loss 0.033909775312058625 	 Validation Loss 0.012186014791950583
INFO:WNN:Epoch 30: Training Loss 0.055244514173828065 	 Validation Loss 0.025490236468613148
INFO:WNN:Epoch 31: Training Loss 0.0856609617266804 	 Validation Loss 0.0539619792252779
INFO:WNN:Epoch 32: Training Loss 0.12473081836476922 	 Validation Loss 0.03443743474781513
INFO:WNN:Epoch 33: Training Loss 0.0865297720208764 	 Validation Loss 0.01590024447068572
INFO:WNN:Epoch 34: Training Loss 0.049065287741832435 	 Validation Loss 0.009332005400210619
INFO:WNN:Epoch 35: Training Loss 0.03008599791675806 	 Validation Loss 0.00823924201540649
threshold tensor(0.1084, grad_fn=<MulBackward0>)
