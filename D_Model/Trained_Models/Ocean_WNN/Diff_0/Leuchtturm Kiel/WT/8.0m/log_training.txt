INFO:WNN:Epoch 0: Training Loss 0.15498100728764835 	 Validation Loss 0.10281592002138495
INFO:WNN:Epoch 1: Training Loss 0.23039788796403815 	 Validation Loss 0.2340698540210724
INFO:WNN:Epoch 2: Training Loss 0.12594336429001055 	 Validation Loss 0.20338360592722893
INFO:WNN:Epoch 3: Training Loss 0.4374412804923301 	 Validation Loss 1.4708762168884277
INFO:WNN:Epoch 4: Training Loss 0.7742751581864136 	 Validation Loss 0.40465988777577877
INFO:WNN:Epoch 5: Training Loss 0.5997848175022573 	 Validation Loss 0.111248844768852
INFO:WNN:Epoch 6: Training Loss 0.5858391367752726 	 Validation Loss 0.03920023189857602
INFO:WNN:Epoch 7: Training Loss 0.18244941889988406 	 Validation Loss 0.24392074346542358
INFO:WNN:Epoch 8: Training Loss 0.12879826235843617 	 Validation Loss 0.1939812060445547
INFO:WNN:Epoch 9: Training Loss 0.1915202832181147 	 Validation Loss 0.04358435235917568
INFO:WNN:Epoch 10: Training Loss 0.3609173434402143 	 Validation Loss 0.40199852362275124
INFO:WNN:Epoch 11: Training Loss 0.5478437925815501 	 Validation Loss 0.11713259993121028
INFO:WNN:Epoch 12: Training Loss 0.4793676387385598 	 Validation Loss 0.8867396339774132
INFO:WNN:Epoch 13: Training Loss 0.6660724008115866 	 Validation Loss 0.029339576023630798
INFO:WNN:Epoch 14: Training Loss 0.5091218678428541 	 Validation Loss 0.061554834712296724
INFO:WNN:Epoch 15: Training Loss 0.21645398497963064 	 Validation Loss 0.19846279919147491
INFO:WNN:Epoch 16: Training Loss 0.08863931685586326 	 Validation Loss 0.13002243265509605
INFO:WNN:Epoch 17: Training Loss 0.12141048369096732 	 Validation Loss 0.041808973997831345
INFO:WNN:Epoch 18: Training Loss 0.14376538235505687 	 Validation Loss 0.3704930478706956
INFO:WNN:Epoch 19: Training Loss 0.22584250676704365 	 Validation Loss 0.6652318835258484
INFO:WNN:Epoch 20: Training Loss 0.47830241230235154 	 Validation Loss 0.3817219566553831
INFO:WNN:Epoch 21: Training Loss 0.720787532808673 	 Validation Loss 0.005594460584688932
INFO:WNN:Epoch 22: Training Loss 0.33816546739064274 	 Validation Loss 0.29711691895499825
INFO:WNN:Epoch 23: Training Loss 0.31453223275168546 	 Validation Loss 0.006245110133022536
INFO:WNN:Epoch 24: Training Loss 0.30211217176180244 	 Validation Loss 0.06386978831142187
INFO:WNN:Epoch 25: Training Loss 0.4653085889867581 	 Validation Loss 0.23068356374278665
INFO:WNN:Epoch 26: Training Loss 0.4023877629296048 	 Validation Loss 0.15056617930531502
INFO:WNN:Epoch 27: Training Loss 0.20389934551591674 	 Validation Loss 0.37270578369498253
INFO:WNN:Epoch 28: Training Loss 0.16858367669434907 	 Validation Loss 0.013109089573845267
INFO:WNN:Epoch 29: Training Loss 0.31530852752390304 	 Validation Loss 0.021873506193514913
INFO:WNN:Epoch 30: Training Loss 0.13349177211473165 	 Validation Loss 0.01684228517115116
INFO:WNN:Epoch 31: Training Loss 0.09765924421824618 	 Validation Loss 0.015345884254202247
INFO:WNN:Epoch 32: Training Loss 0.1367843883511211 	 Validation Loss 0.05431894585490227
threshold tensor(0.2001, grad_fn=<MulBackward0>)
