INFO:WNN:Epoch 0: Training Loss 0.22987363978551464 	 Validation Loss 0.028630468645133078
INFO:WNN:Epoch 1: Training Loss 0.22778457306539787 	 Validation Loss 0.05733070941641927
INFO:WNN:Epoch 2: Training Loss 0.5105260243151515 	 Validation Loss 0.10077729821205139
INFO:WNN:Epoch 3: Training Loss 0.2402485840037347 	 Validation Loss 0.032267284113913774
INFO:WNN:Epoch 4: Training Loss 0.14073116504143746 	 Validation Loss 0.05233753100037575
INFO:WNN:Epoch 5: Training Loss 0.17864099668527378 	 Validation Loss 0.15070683229714632
INFO:WNN:Epoch 6: Training Loss 0.1684529764233813 	 Validation Loss 0.10950921848416328
INFO:WNN:Epoch 7: Training Loss 0.1445874198107049 	 Validation Loss 0.008011609796085395
INFO:WNN:Epoch 8: Training Loss 0.16100017810961054 	 Validation Loss 0.3278946317732334
INFO:WNN:Epoch 9: Training Loss 0.3728053147566416 	 Validation Loss 0.11094138212502003
INFO:WNN:Epoch 10: Training Loss 0.24264689574077253 	 Validation Loss 0.07474011951126158
INFO:WNN:Epoch 11: Training Loss 0.2767052712539832 	 Validation Loss 0.045644836500287056
INFO:WNN:Epoch 12: Training Loss 0.13261657455078665 	 Validation Loss 0.04891148488968611
INFO:WNN:Epoch 13: Training Loss 0.09100320176609482 	 Validation Loss 0.03594331711065024
INFO:WNN:Epoch 14: Training Loss 0.22640289264058489 	 Validation Loss 0.03736142814159393
INFO:WNN:Epoch 15: Training Loss 0.1513758509804214 	 Validation Loss 0.06534113362431526
INFO:WNN:Epoch 16: Training Loss 0.1201590117517977 	 Validation Loss 0.054623063653707504
INFO:WNN:Epoch 17: Training Loss 0.06972082074507997 	 Validation Loss 0.050195034593343735
INFO:WNN:Epoch 18: Training Loss 0.1024004492321096 	 Validation Loss 0.02430005365749821
threshold tensor(0.4556, grad_fn=<MulBackward0>)
