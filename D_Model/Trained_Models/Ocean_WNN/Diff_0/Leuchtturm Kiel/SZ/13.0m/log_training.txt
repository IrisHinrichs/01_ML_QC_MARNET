INFO:WNN:Epoch 0: Training Loss 0.22987363811504716 	 Validation Loss 0.02863046620041132
INFO:WNN:Epoch 1: Training Loss 0.22778454760555178 	 Validation Loss 0.057330633979290724
INFO:WNN:Epoch 2: Training Loss 0.5105256162702091 	 Validation Loss 0.10077714454382658
INFO:WNN:Epoch 3: Training Loss 0.24025417052556775 	 Validation Loss 0.03226216230541468
INFO:WNN:Epoch 4: Training Loss 0.14074241159860754 	 Validation Loss 0.05229050572961569
INFO:WNN:Epoch 5: Training Loss 0.17982092568381053 	 Validation Loss 0.14798861928284168
INFO:WNN:Epoch 6: Training Loss 0.16384928961910883 	 Validation Loss 0.13454885222017765
INFO:WNN:Epoch 7: Training Loss 0.22929449130444685 	 Validation Loss 0.03937978879548609
INFO:WNN:Epoch 8: Training Loss 0.25329231522563433 	 Validation Loss 0.15852040704339743
INFO:WNN:Epoch 9: Training Loss 0.4148763231267886 	 Validation Loss 0.16598381474614143
INFO:WNN:Epoch 10: Training Loss 0.26951335832875756 	 Validation Loss 0.06864868570119143
INFO:WNN:Epoch 11: Training Loss 0.33881671095104327 	 Validation Loss 0.12012347532436252
threshold tensor(1.3796, grad_fn=<MulBackward0>)
