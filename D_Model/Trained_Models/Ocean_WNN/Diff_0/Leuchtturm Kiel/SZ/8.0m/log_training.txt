INFO:WNN:Epoch 0: Training Loss 0.36193493065925747 	 Validation Loss 0.04446916934102774
INFO:WNN:Epoch 1: Training Loss 0.08660442830855922 	 Validation Loss 0.025166550651192665
INFO:WNN:Epoch 2: Training Loss 0.09663599056120102 	 Validation Loss 0.023831447586417198
INFO:WNN:Epoch 3: Training Loss 0.18563917766396815 	 Validation Loss 0.04185276385396719
INFO:WNN:Epoch 4: Training Loss 0.26943422911258846 	 Validation Loss 0.07691070064902306
INFO:WNN:Epoch 5: Training Loss 0.27401388572672236 	 Validation Loss 0.05036337673664093
INFO:WNN:Epoch 6: Training Loss 0.15944421893128982 	 Validation Loss 0.02722601592540741
INFO:WNN:Epoch 7: Training Loss 0.10555487487894985 	 Validation Loss 0.03299267031252384
INFO:WNN:Epoch 8: Training Loss 0.11817927728407085 	 Validation Loss 0.028211146593093872
INFO:WNN:Epoch 9: Training Loss 0.06567087799059944 	 Validation Loss 0.014282281743362546
INFO:WNN:Epoch 10: Training Loss 0.09364332335714537 	 Validation Loss 0.019449974410235882
INFO:WNN:Epoch 11: Training Loss 0.0899253671702284 	 Validation Loss 0.031649110838770866
INFO:WNN:Epoch 12: Training Loss 0.08906638590045847 	 Validation Loss 0.03232676349580288
INFO:WNN:Epoch 13: Training Loss 0.08543740836187051 	 Validation Loss 0.020389670506119728
INFO:WNN:Epoch 14: Training Loss 0.06673007222035757 	 Validation Loss 0.02632447611540556
INFO:WNN:Epoch 15: Training Loss 0.08468407213401336 	 Validation Loss 0.03022134117782116
INFO:WNN:Epoch 16: Training Loss 0.07501075957686855 	 Validation Loss 0.020547322928905487
INFO:WNN:Epoch 17: Training Loss 0.05220961114928986 	 Validation Loss 0.012223907513543963
INFO:WNN:Epoch 18: Training Loss 0.09815589348391558 	 Validation Loss 0.03781045973300934
INFO:WNN:Epoch 19: Training Loss 0.08495774180986561 	 Validation Loss 0.04011818580329418
INFO:WNN:Epoch 20: Training Loss 0.04901652424954451 	 Validation Loss 0.012914355844259262
INFO:WNN:Epoch 21: Training Loss 0.09850867098877923 	 Validation Loss 0.03382360376417637
INFO:WNN:Epoch 22: Training Loss 0.07301782719934216 	 Validation Loss 0.04177694395184517
INFO:WNN:Epoch 23: Training Loss 0.04134818817524669 	 Validation Loss 0.01065170532092452
INFO:WNN:Epoch 24: Training Loss 0.05426344330995702 	 Validation Loss 0.010074848309159279
INFO:WNN:Epoch 25: Training Loss 0.06515396003109905 	 Validation Loss 0.020038658287376165
INFO:WNN:Epoch 26: Training Loss 0.08362353523261845 	 Validation Loss 0.03191152773797512
INFO:WNN:Epoch 27: Training Loss 0.1329175078202612 	 Validation Loss 0.0449935644865036
INFO:WNN:Epoch 28: Training Loss 0.10724892916802603 	 Validation Loss 0.028210804797708988
INFO:WNN:Epoch 29: Training Loss 0.15841654498273364 	 Validation Loss 0.02457475382834673
INFO:WNN:Epoch 30: Training Loss 0.21711361474500826 	 Validation Loss 0.028300637379288673
INFO:WNN:Epoch 31: Training Loss 0.2260986456575875 	 Validation Loss 0.03255033399909735
INFO:WNN:Epoch 32: Training Loss 0.15620382986246392 	 Validation Loss 0.03311544377356768
INFO:WNN:Epoch 33: Training Loss 0.1543541840958194 	 Validation Loss 0.025085742585361004
INFO:WNN:Epoch 34: Training Loss 0.11385907821554261 	 Validation Loss 0.018061325419694185
INFO:WNN:Epoch 35: Training Loss 0.2432393625450249 	 Validation Loss 0.028189036063849926
threshold tensor(0.1912, grad_fn=<MulBackward0>)
