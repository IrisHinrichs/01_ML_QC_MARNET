INFO:WNN:Epoch 0: Training Loss 0.4854240894317627 	 Validation Loss 0.05212440714240074
INFO:WNN:Epoch 1: Training Loss 0.3297413945198059 	 Validation Loss 0.06964068859815598
INFO:WNN:Epoch 2: Training Loss 0.2674476832151413 	 Validation Loss 0.22557081282138824
INFO:WNN:Epoch 3: Training Loss 0.19044265076518058 	 Validation Loss 0.03563850000500679
INFO:WNN:Epoch 4: Training Loss 0.19413310885429383 	 Validation Loss 0.036783378571271896
INFO:WNN:Epoch 5: Training Loss 0.1757781594991684 	 Validation Loss 0.07666004449129105
INFO:WNN:Epoch 6: Training Loss 0.15684375017881394 	 Validation Loss 0.033746711909770966
INFO:WNN:Epoch 7: Training Loss 0.15282521843910218 	 Validation Loss 0.03397737815976143
INFO:WNN:Epoch 8: Training Loss 0.14761887937784196 	 Validation Loss 0.04169520363211632
INFO:WNN:Epoch 9: Training Loss 0.13706130310893058 	 Validation Loss 0.03668724000453949
INFO:WNN:Epoch 10: Training Loss 0.13724754601716996 	 Validation Loss 0.03598906099796295
INFO:WNN:Epoch 11: Training Loss 0.13405043333768846 	 Validation Loss 0.0366990827023983
INFO:WNN:Epoch 12: Training Loss 0.13364115357398987 	 Validation Loss 0.0347445048391819
INFO:WNN:Epoch 13: Training Loss 0.13314911127090454 	 Validation Loss 0.04472667723894119
INFO:WNN:Epoch 14: Training Loss 0.13786844089627265 	 Validation Loss 0.03821689635515213
INFO:WNN:Epoch 15: Training Loss 0.14129985347390175 	 Validation Loss 0.07419916242361069
INFO:WNN:Epoch 16: Training Loss 0.15706670582294463 	 Validation Loss 0.04437980428338051
INFO:WNN:Epoch 17: Training Loss 0.1557788707315922 	 Validation Loss 0.0734495297074318
threshold tensor(0.3413, grad_fn=<MulBackward0>)
