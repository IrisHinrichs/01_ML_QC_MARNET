INFO:WNN:Epoch 0: Training Loss 0.3507706884161702 	 Validation Loss 0.22450129128992558
INFO:WNN:Epoch 1: Training Loss 0.2771870142942856 	 Validation Loss 0.20086130127310753
INFO:WNN:Epoch 2: Training Loss 0.12840648789313577 	 Validation Loss 0.16096478886902332
INFO:WNN:Epoch 3: Training Loss 0.17114276117238675 	 Validation Loss 0.1725622182711959
INFO:WNN:Epoch 4: Training Loss 0.31385466450176736 	 Validation Loss 0.5914069153368473
INFO:WNN:Epoch 5: Training Loss 0.29113228596693336 	 Validation Loss 0.13841559807769954
INFO:WNN:Epoch 6: Training Loss 0.36763441295567195 	 Validation Loss 0.23059008968994021
INFO:WNN:Epoch 7: Training Loss 0.46793826210445594 	 Validation Loss 0.26033591851592064
INFO:WNN:Epoch 8: Training Loss 0.37172840773645377 	 Validation Loss 0.3898969180881977
INFO:WNN:Epoch 9: Training Loss 0.5402582566002532 	 Validation Loss 0.20430848561227322
INFO:WNN:Epoch 10: Training Loss 0.3950215268285117 	 Validation Loss 0.43718830682337284
INFO:WNN:Epoch 11: Training Loss 0.4934113021526072 	 Validation Loss 0.2848394177854061
INFO:WNN:Epoch 12: Training Loss 0.422656371301162 	 Validation Loss 0.13784558698534966
INFO:WNN:Epoch 13: Training Loss 0.23632915217534728 	 Validation Loss 0.1293689776211977
INFO:WNN:Epoch 14: Training Loss 0.19180027251723147 	 Validation Loss 0.12200250290334225
INFO:WNN:Epoch 15: Training Loss 0.14368372073300953 	 Validation Loss 0.07218778971582651
INFO:WNN:Epoch 16: Training Loss 0.2732925113846755 	 Validation Loss 0.16728936322033405
INFO:WNN:Epoch 17: Training Loss 0.29340586565769394 	 Validation Loss 0.07784631755203009
INFO:WNN:Epoch 18: Training Loss 0.1461423593388486 	 Validation Loss 0.06795609556138515
INFO:WNN:Epoch 19: Training Loss 0.09923915336618111 	 Validation Loss 0.0860252920538187
INFO:WNN:Epoch 20: Training Loss 0.09041659076262029 	 Validation Loss 0.0413827751763165
INFO:WNN:Epoch 21: Training Loss 0.07332705064225824 	 Validation Loss 0.03118618531152606
INFO:WNN:Epoch 22: Training Loss 0.06480023231346249 	 Validation Loss 0.02394182041462045
INFO:WNN:Epoch 23: Training Loss 0.05551477727047833 	 Validation Loss 0.03423680714331567
INFO:WNN:Epoch 24: Training Loss 0.0504756810666535 	 Validation Loss 0.03872360708191991
INFO:WNN:Epoch 25: Training Loss 0.05304567395831414 	 Validation Loss 0.04981506476178765
INFO:WNN:Epoch 26: Training Loss 0.045274280015349624 	 Validation Loss 0.03757234290242195
INFO:WNN:Epoch 27: Training Loss 0.03790344787384605 	 Validation Loss 0.027246094774454832
INFO:WNN:Epoch 28: Training Loss 0.042609300364607146 	 Validation Loss 0.052026049233973026
INFO:WNN:Epoch 29: Training Loss 0.033436378335676316 	 Validation Loss 0.021641461178660393
INFO:WNN:Epoch 30: Training Loss 0.043577233487407545 	 Validation Loss 0.08493385277688503
INFO:WNN:Epoch 31: Training Loss 0.03113089975487951 	 Validation Loss 0.016199398785829544
INFO:WNN:Epoch 32: Training Loss 0.05802932898592507 	 Validation Loss 0.16670279204845428
INFO:WNN:Epoch 33: Training Loss 0.03901544425752945 	 Validation Loss 0.05592296295799315
INFO:WNN:Epoch 34: Training Loss 0.18579405347543163 	 Validation Loss 0.1514585241675377
INFO:WNN:Epoch 35: Training Loss 0.10608177907147726 	 Validation Loss 0.03593964409083128
INFO:WNN:Epoch 36: Training Loss 0.08869416952791018 	 Validation Loss 0.08259758725762367
INFO:WNN:Epoch 37: Training Loss 0.05980642019662016 	 Validation Loss 0.14144206256605685
INFO:WNN:Epoch 38: Training Loss 1.782102335850054 	 Validation Loss 0.9292274340987206
INFO:WNN:Epoch 39: Training Loss 1.2254878407166827 	 Validation Loss 0.43616118654608727
INFO:WNN:Epoch 40: Training Loss 0.9071122449970553 	 Validation Loss 0.45891910046339035
INFO:WNN:Epoch 41: Training Loss 1.1427821915537593 	 Validation Loss 0.46756976936012506
INFO:WNN:Epoch 42: Training Loss 1.3540731962208474 	 Validation Loss 0.593836173415184
threshold tensor(2.8475, grad_fn=<MulBackward0>)
