INFO:WNN:Epoch 0: Training Loss 0.2506327869902764 	 Validation Loss 0.39067449420690536
INFO:WNN:Epoch 1: Training Loss 0.09295485255175404 	 Validation Loss 0.1548960736642281
INFO:WNN:Epoch 2: Training Loss 0.04414044719056359 	 Validation Loss 0.13640361092984676
INFO:WNN:Epoch 3: Training Loss 0.04002302660540279 	 Validation Loss 0.2341509871184826
INFO:WNN:Epoch 4: Training Loss 0.060015360239361014 	 Validation Loss 0.12400386606653531
INFO:WNN:Epoch 5: Training Loss 0.07289832688402384 	 Validation Loss 0.08583109204967816
INFO:WNN:Epoch 6: Training Loss 0.04658997874108276 	 Validation Loss 0.44695181399583817
INFO:WNN:Epoch 7: Training Loss 0.047867610601575246 	 Validation Loss 0.6382105797529221
INFO:WNN:Epoch 8: Training Loss 0.07796345207441066 	 Validation Loss 0.41168127954006195
INFO:WNN:Epoch 9: Training Loss 0.07748984553452049 	 Validation Loss 0.12875048195322356
INFO:WNN:Epoch 10: Training Loss 0.03892173068930528 	 Validation Loss 0.19652457690487304
INFO:WNN:Epoch 11: Training Loss 0.018626266604821598 	 Validation Loss 0.140811942362537
INFO:WNN:Epoch 12: Training Loss 0.015307865815702825 	 Validation Loss 0.1258177695175012
INFO:WNN:Epoch 13: Training Loss 0.01716103121289052 	 Validation Loss 0.1004864051938057
INFO:WNN:Epoch 14: Training Loss 0.01916873526393569 	 Validation Loss 0.13166042665640512
INFO:WNN:Epoch 15: Training Loss 0.021938170698870506 	 Validation Loss 0.12311393519242604
INFO:WNN:Epoch 16: Training Loss 0.022776287611174797 	 Validation Loss 0.17619463056325912
threshold tensor(0.5192, grad_fn=<MulBackward0>)
