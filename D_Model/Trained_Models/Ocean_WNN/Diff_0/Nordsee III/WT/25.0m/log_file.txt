INFO:WNN:Epoch 0: Training Loss 0.8046716749668121 	 Validation Loss 1.0281633138656616
INFO:WNN:Epoch 1: Training Loss 0.5186903029680252 	 Validation Loss 0.5708131194114685
INFO:WNN:Epoch 2: Training Loss 0.43823881447315216 	 Validation Loss 0.3269447684288025
INFO:WNN:Epoch 3: Training Loss 0.33830246329307556 	 Validation Loss 0.18443666398525238
INFO:WNN:Epoch 4: Training Loss 0.3262901231646538 	 Validation Loss 0.10015580803155899
INFO:WNN:Epoch 5: Training Loss 0.3457770049571991 	 Validation Loss 0.057835571467876434
INFO:WNN:Epoch 6: Training Loss 0.32640260457992554 	 Validation Loss 0.04433043673634529
INFO:WNN:Epoch 7: Training Loss 0.2991199865937233 	 Validation Loss 0.04118358716368675
INFO:WNN:Epoch 8: Training Loss 0.29577120393514633 	 Validation Loss 0.04002528265118599
INFO:WNN:Epoch 9: Training Loss 0.29448311030864716 	 Validation Loss 0.052394505590200424
INFO:WNN:Epoch 10: Training Loss 0.2768508195877075 	 Validation Loss 0.09209807962179184
INFO:WNN:Epoch 11: Training Loss 0.2592194601893425 	 Validation Loss 0.15031659603118896
INFO:WNN:Epoch 12: Training Loss 0.2556385397911072 	 Validation Loss 0.19608116149902344
INFO:WNN:Epoch 13: Training Loss 0.25562674552202225 	 Validation Loss 0.20701317489147186
INFO:WNN:Epoch 14: Training Loss 0.24934282898902893 	 Validation Loss 0.1876460760831833
INFO:WNN:Epoch 15: Training Loss 0.24294083565473557 	 Validation Loss 0.15735279023647308
INFO:WNN:Epoch 16: Training Loss 0.24085379391908646 	 Validation Loss 0.13243219256401062
INFO:WNN:Epoch 17: Training Loss 0.2380075752735138 	 Validation Loss 0.11828126013278961
INFO:WNN:Epoch 18: Training Loss 0.23235727101564407 	 Validation Loss 0.11205273866653442
threshold tensor(0.5601, grad_fn=<MulBackward0>)
