INFO:WNN:Epoch 0: Training Loss 0.05815843102588717 	 Validation Loss 0.7420804599920908
INFO:WNN:Epoch 1: Training Loss 0.050834002851375515 	 Validation Loss 0.6997862681746483
INFO:WNN:Epoch 2: Training Loss 0.0321811429457739 	 Validation Loss 1.3386011918385823
INFO:WNN:Epoch 3: Training Loss 0.010190851863340608 	 Validation Loss 0.6450200875600179
INFO:WNN:Epoch 4: Training Loss 0.013872058511645134 	 Validation Loss 0.4829967990517616
INFO:WNN:Epoch 5: Training Loss 0.017686986688724055 	 Validation Loss 0.6358424226442972
INFO:WNN:Epoch 6: Training Loss 0.013969217264093458 	 Validation Loss 0.8257502565781275
INFO:WNN:Epoch 7: Training Loss 0.008816110941448381 	 Validation Loss 0.857096791267395
INFO:WNN:Epoch 8: Training Loss 0.00854472635214084 	 Validation Loss 0.8020479579766592
INFO:WNN:Epoch 9: Training Loss 0.011558081674489325 	 Validation Loss 0.8143301606178284
INFO:WNN:Epoch 10: Training Loss 0.013953817022099559 	 Validation Loss 0.9267058670520782
INFO:WNN:Epoch 11: Training Loss 0.011752258893933946 	 Validation Loss 1.0852692425251007
INFO:WNN:Epoch 12: Training Loss 0.008946023771672376 	 Validation Loss 1.1385635336240132
INFO:WNN:Epoch 13: Training Loss 0.012699117644556931 	 Validation Loss 1.1890310148398082
INFO:WNN:Epoch 14: Training Loss 0.013217677235037887 	 Validation Loss 1.0308890740076702
INFO:WNN:Epoch 15: Training Loss 0.014103249972686171 	 Validation Loss 0.39970557888348895
INFO:WNN:Epoch 16: Training Loss 0.01378215178847313 	 Validation Loss 0.4165138651927312
INFO:WNN:Epoch 17: Training Loss 0.010591033132680292 	 Validation Loss 0.6935081134239832
INFO:WNN:Epoch 18: Training Loss 0.0075701947407131745 	 Validation Loss 0.8732666869958242
INFO:WNN:Epoch 19: Training Loss 0.012902588521995183 	 Validation Loss 0.46042654663324356
INFO:WNN:Epoch 20: Training Loss 0.008109473646618426 	 Validation Loss 0.7824592789014181
INFO:WNN:Epoch 21: Training Loss 0.008927455291684185 	 Validation Loss 0.5331740031639735
INFO:WNN:Epoch 22: Training Loss 0.006970962312438392 	 Validation Loss 0.7429251670837402
INFO:WNN:Epoch 23: Training Loss 0.006690123043621757 	 Validation Loss 0.6194819758335749
INFO:WNN:Epoch 24: Training Loss 0.007409395177715591 	 Validation Loss 0.6326917310555776
INFO:WNN:Epoch 25: Training Loss 0.006198442760588867 	 Validation Loss 0.7435328662395477
INFO:WNN:Epoch 26: Training Loss 0.006357731438973653 	 Validation Loss 0.6008670181035995
threshold tensor(6.5205, grad_fn=<MulBackward0>)
