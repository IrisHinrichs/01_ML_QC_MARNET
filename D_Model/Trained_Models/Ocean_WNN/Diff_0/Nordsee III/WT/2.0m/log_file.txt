INFO:WNN:Epoch 0: Training Loss 0.500217285938561 	 Validation Loss 0.12069964408874512
INFO:WNN:Epoch 1: Training Loss 0.49188650120049715 	 Validation Loss 0.04183457791805267
INFO:WNN:Epoch 2: Training Loss 0.27856706106103957 	 Validation Loss 0.033646345138549805
INFO:WNN:Epoch 3: Training Loss 0.11006415728479624 	 Validation Loss 0.03802867233753204
INFO:WNN:Epoch 4: Training Loss 0.0715151506010443 	 Validation Loss 0.0681295320391655
INFO:WNN:Epoch 5: Training Loss 0.05591948190703988 	 Validation Loss 0.03756216540932655
INFO:WNN:Epoch 6: Training Loss 0.049044958082959056 	 Validation Loss 0.04669886454939842
INFO:WNN:Epoch 7: Training Loss 0.04723542765714228 	 Validation Loss 0.03977454826235771
INFO:WNN:Epoch 8: Training Loss 0.04166432865895331 	 Validation Loss 0.03675074130296707
INFO:WNN:Epoch 9: Training Loss 0.04109443863853812 	 Validation Loss 0.030486425384879112
INFO:WNN:Epoch 10: Training Loss 0.03800789313390851 	 Validation Loss 0.02627989836037159
INFO:WNN:Epoch 11: Training Loss 0.03496511047706008 	 Validation Loss 0.029385702684521675
INFO:WNN:Epoch 12: Training Loss 0.036515319254249334 	 Validation Loss 0.02725839801132679
INFO:WNN:Epoch 13: Training Loss 0.03497322555631399 	 Validation Loss 0.028789332136511803
INFO:WNN:Epoch 14: Training Loss 0.06145666365046054 	 Validation Loss 0.03417377173900604
INFO:WNN:Epoch 15: Training Loss 0.11407840019091964 	 Validation Loss 0.02899242751300335
INFO:WNN:Epoch 16: Training Loss 0.12184210820123553 	 Validation Loss 0.05104060843586922
INFO:WNN:Epoch 17: Training Loss 0.16298054798971862 	 Validation Loss 0.037044283002614975
INFO:WNN:Epoch 18: Training Loss 0.1841578111052513 	 Validation Loss 0.01952975057065487
INFO:WNN:Epoch 19: Training Loss 0.14458421972813085 	 Validation Loss 0.05296264588832855
INFO:WNN:Epoch 20: Training Loss 0.059477772330865264 	 Validation Loss 0.027469931170344353
INFO:WNN:Epoch 21: Training Loss 0.03749792999587953 	 Validation Loss 0.02255576103925705
INFO:WNN:Epoch 22: Training Loss 0.04377837001811713 	 Validation Loss 0.02273119054734707
INFO:WNN:Epoch 23: Training Loss 0.032224380993284285 	 Validation Loss 0.02279127761721611
INFO:WNN:Epoch 24: Training Loss 0.028677967726252973 	 Validation Loss 0.018062569200992584
INFO:WNN:Epoch 25: Training Loss 0.026228939299471676 	 Validation Loss 0.017727080732584
INFO:WNN:Epoch 26: Training Loss 0.026160630048252642 	 Validation Loss 0.018199846148490906
INFO:WNN:Epoch 27: Training Loss 0.024767735856585205 	 Validation Loss 0.016179800033569336
INFO:WNN:Epoch 28: Training Loss 0.026029209315311164 	 Validation Loss 0.018022431060671806
INFO:WNN:Epoch 29: Training Loss 0.026918593735899776 	 Validation Loss 0.014584335498511791
INFO:WNN:Epoch 30: Training Loss 0.027202928788028657 	 Validation Loss 0.017116162925958633
INFO:WNN:Epoch 31: Training Loss 0.028944309276994318 	 Validation Loss 0.02153937518596649
INFO:WNN:Epoch 32: Training Loss 0.030417039175517857 	 Validation Loss 0.022131409496068954
INFO:WNN:Epoch 33: Training Loss 0.05405365000478923 	 Validation Loss 0.023548176512122154
INFO:WNN:Epoch 34: Training Loss 0.08258625818416476 	 Validation Loss 0.014080929569900036
INFO:WNN:Epoch 35: Training Loss 0.059086484368890524 	 Validation Loss 0.015694323927164078
INFO:WNN:Epoch 36: Training Loss 0.04499317071167752 	 Validation Loss 0.01883653923869133
INFO:WNN:Epoch 37: Training Loss 0.04332679032813758 	 Validation Loss 0.02171676605939865
INFO:WNN:Epoch 38: Training Loss 0.049602286191657186 	 Validation Loss 0.0231842752546072
INFO:WNN:Epoch 39: Training Loss 0.046982080792076886 	 Validation Loss 0.023193201050162315
INFO:WNN:Epoch 40: Training Loss 0.04637650342192501 	 Validation Loss 0.020705239847302437
threshold tensor(0.1223, grad_fn=<MulBackward0>)
