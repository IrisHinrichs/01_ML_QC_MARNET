INFO:WNN:Epoch 0: Training Loss 0.10316607922847781 	 Validation Loss 2.489662061134974
INFO:WNN:Epoch 1: Training Loss 0.029380024344261204 	 Validation Loss 1.1872376104195912
INFO:WNN:Epoch 2: Training Loss 0.024441260558419994 	 Validation Loss 0.7387785216172537
INFO:WNN:Epoch 3: Training Loss 0.024446462766666496 	 Validation Loss 0.6805405418078104
INFO:WNN:Epoch 4: Training Loss 0.02031684174934136 	 Validation Loss 0.7603216469287872
INFO:WNN:Epoch 5: Training Loss 0.017095916704939946 	 Validation Loss 0.997086783250173
INFO:WNN:Epoch 6: Training Loss 0.015373993580163057 	 Validation Loss 1.3968851069609325
INFO:WNN:Epoch 7: Training Loss 0.017154023564320855 	 Validation Loss 1.6075645685195923
INFO:WNN:Epoch 8: Training Loss 0.021906921428827834 	 Validation Loss 1.6697009205818176
INFO:WNN:Epoch 9: Training Loss 0.020095731021969446 	 Validation Loss 1.265119155248006
INFO:WNN:Epoch 10: Training Loss 0.017827753656144654 	 Validation Loss 0.6812306344509125
INFO:WNN:Epoch 11: Training Loss 0.021841443203655737 	 Validation Loss 0.7623854180177053
INFO:WNN:Epoch 12: Training Loss 0.02060350499980684 	 Validation Loss 1.3237839738527934
INFO:WNN:Epoch 13: Training Loss 0.018943656383947072 	 Validation Loss 1.702762891848882
INFO:WNN:Epoch 14: Training Loss 0.027287223251603012 	 Validation Loss 3.4460307558377585
threshold tensor(8.9716, grad_fn=<MulBackward0>)
