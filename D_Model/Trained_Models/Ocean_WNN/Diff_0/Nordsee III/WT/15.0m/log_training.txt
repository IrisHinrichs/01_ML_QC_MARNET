INFO:WNN:Epoch 0: Training Loss 0.10316607293539813 	 Validation Loss 2.4896620710690818
INFO:WNN:Epoch 1: Training Loss 0.0293800247400733 	 Validation Loss 1.187237451473872
INFO:WNN:Epoch 2: Training Loss 0.024441259532302084 	 Validation Loss 0.7387784322102865
INFO:WNN:Epoch 3: Training Loss 0.02444645596634863 	 Validation Loss 0.6805402934551239
INFO:WNN:Epoch 4: Training Loss 0.02031684645750959 	 Validation Loss 0.7603216469287872
INFO:WNN:Epoch 5: Training Loss 0.01709591643552163 	 Validation Loss 0.9970874190330505
INFO:WNN:Epoch 6: Training Loss 0.015373991086380556 	 Validation Loss 1.3968857924143474
INFO:WNN:Epoch 7: Training Loss 0.017154030031191984 	 Validation Loss 1.6075648566087086
INFO:WNN:Epoch 8: Training Loss 0.021906901051157286 	 Validation Loss 1.6696989337603252
INFO:WNN:Epoch 9: Training Loss 0.0200956895415272 	 Validation Loss 1.265117476383845
INFO:WNN:Epoch 10: Training Loss 0.017827747991707707 	 Validation Loss 0.6812314291795095
INFO:WNN:Epoch 11: Training Loss 0.021841440135280468 	 Validation Loss 0.7623861531416575
INFO:WNN:Epoch 12: Training Loss 0.020603519137616138 	 Validation Loss 1.3237870434919994
INFO:WNN:Epoch 13: Training Loss 0.018943694684587953 	 Validation Loss 1.7027575969696045
INFO:WNN:Epoch 14: Training Loss 0.027287229338461266 	 Validation Loss 3.4460285902023315
threshold tensor(8.9716, grad_fn=<MulBackward0>)
