INFO:WNN:Epoch 0: Training Loss 0.9983231425285339 	 Validation Loss 0.2559046745300293
INFO:WNN:Epoch 1: Training Loss 0.7685630818208059 	 Validation Loss 0.014743653126060963
INFO:WNN:Epoch 2: Training Loss 0.6683515707651774 	 Validation Loss 0.0422196127474308
INFO:WNN:Epoch 3: Training Loss 0.6560896535714468 	 Validation Loss 0.05999438837170601
INFO:WNN:Epoch 4: Training Loss 0.6204199194908142 	 Validation Loss 0.019736584275960922
INFO:WNN:Epoch 5: Training Loss 0.5934539635976156 	 Validation Loss 0.013744968920946121
INFO:WNN:Epoch 6: Training Loss 0.5739840666453043 	 Validation Loss 0.020068464800715446
INFO:WNN:Epoch 7: Training Loss 0.5453233520189921 	 Validation Loss 0.014049854129552841
INFO:WNN:Epoch 8: Training Loss 0.5314625302950541 	 Validation Loss 0.008647332899272442
INFO:WNN:Epoch 9: Training Loss 0.5183360477288564 	 Validation Loss 0.006788922473788261
INFO:WNN:Epoch 10: Training Loss 0.5011206070582072 	 Validation Loss 0.006128386128693819
INFO:WNN:Epoch 11: Training Loss 0.48569755752881366 	 Validation Loss 0.0066932737827301025
INFO:WNN:Epoch 12: Training Loss 0.4676012694835663 	 Validation Loss 0.00765023659914732
INFO:WNN:Epoch 13: Training Loss 0.4505997598171234 	 Validation Loss 0.006859627552330494
INFO:WNN:Epoch 14: Training Loss 0.4334753255049388 	 Validation Loss 0.006840739864856005
INFO:WNN:Epoch 15: Training Loss 0.4143403271834056 	 Validation Loss 0.008060434833168983
INFO:WNN:Epoch 16: Training Loss 0.39396678407986957 	 Validation Loss 0.007603371050208807
INFO:WNN:Epoch 17: Training Loss 0.3725780248641968 	 Validation Loss 0.007036666851490736
INFO:WNN:Epoch 18: Training Loss 0.3518894712130229 	 Validation Loss 0.007183310110121965
INFO:WNN:Epoch 19: Training Loss 0.3307219098011653 	 Validation Loss 0.007454863749444485
INFO:WNN:Epoch 20: Training Loss 0.30917302270730335 	 Validation Loss 0.008386950008571148
INFO:WNN:Epoch 21: Training Loss 0.28779687484105426 	 Validation Loss 0.009883934631943703
threshold tensor(0.0551, grad_fn=<MulBackward0>)
