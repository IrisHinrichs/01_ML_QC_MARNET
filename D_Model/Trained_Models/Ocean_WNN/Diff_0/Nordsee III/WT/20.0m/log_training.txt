INFO:WNN:Epoch 0: Training Loss 0.1861200288004641 	 Validation Loss 2.7333166003227234
INFO:WNN:Epoch 1: Training Loss 0.1045859250373074 	 Validation Loss 3.3243824938933053
INFO:WNN:Epoch 2: Training Loss 0.050052831361868555 	 Validation Loss 3.4899507562319436
INFO:WNN:Epoch 3: Training Loss 0.10756796943023801 	 Validation Loss 3.5436248977979026
INFO:WNN:Epoch 4: Training Loss 0.06754093196110002 	 Validation Loss 3.2585567037264505
INFO:WNN:Epoch 5: Training Loss 0.11633665014856628 	 Validation Loss 4.004716495672862
INFO:WNN:Epoch 6: Training Loss 0.04743740943792675 	 Validation Loss 3.020974040031433
INFO:WNN:Epoch 7: Training Loss 0.03842906524992681 	 Validation Loss 3.057979812224706
INFO:WNN:Epoch 8: Training Loss 0.03988903009365978 	 Validation Loss 2.6704479853312173
INFO:WNN:Epoch 9: Training Loss 0.03674863946424531 	 Validation Loss 3.020501365264257
INFO:WNN:Epoch 10: Training Loss 0.025220541193682167 	 Validation Loss 2.798255870739619
INFO:WNN:Epoch 11: Training Loss 0.02413072813900986 	 Validation Loss 2.7444240053494773
threshold tensor(15.5654, grad_fn=<MulBackward0>)
