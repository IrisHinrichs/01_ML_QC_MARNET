INFO:WNN:Epoch 0: Training Loss 1.0534939567248027 	 Validation Loss 0.28172409534454346
INFO:WNN:Epoch 1: Training Loss 0.7545393109321594 	 Validation Loss 0.2572937607765198
INFO:WNN:Epoch 2: Training Loss 0.6580876161654791 	 Validation Loss 0.2776091992855072
INFO:WNN:Epoch 3: Training Loss 0.6491593917210897 	 Validation Loss 0.26705077290534973
INFO:WNN:Epoch 4: Training Loss 0.6142076353232065 	 Validation Loss 0.2692074775695801
INFO:WNN:Epoch 5: Training Loss 0.5999436577161154 	 Validation Loss 0.2694498300552368
INFO:WNN:Epoch 6: Training Loss 0.5909300446510315 	 Validation Loss 0.28049394488334656
INFO:WNN:Epoch 7: Training Loss 0.579726462562879 	 Validation Loss 0.28871405124664307
INFO:WNN:Epoch 8: Training Loss 0.5649896115064621 	 Validation Loss 0.28746867179870605
INFO:WNN:Epoch 9: Training Loss 0.5519172102212906 	 Validation Loss 0.28747260570526123
INFO:WNN:Epoch 10: Training Loss 0.5395669043064117 	 Validation Loss 0.2958923280239105
INFO:WNN:Epoch 11: Training Loss 0.5214663048585256 	 Validation Loss 0.30564913153648376
INFO:WNN:Epoch 12: Training Loss 0.5010207742452621 	 Validation Loss 0.3137534260749817
threshold tensor(4.6610, grad_fn=<MulBackward0>)
