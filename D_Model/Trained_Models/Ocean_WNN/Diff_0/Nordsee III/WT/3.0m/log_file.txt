INFO:WNN:Epoch 0: Training Loss 0.4314722263121179 	 Validation Loss 0.5324703454971313
INFO:WNN:Epoch 1: Training Loss 0.1738787019359214 	 Validation Loss 0.16950945556163788
INFO:WNN:Epoch 2: Training Loss 0.1726960763335228 	 Validation Loss 0.3333618640899658
INFO:WNN:Epoch 3: Training Loss 0.04332896276277357 	 Validation Loss 0.7657380700111389
INFO:WNN:Epoch 4: Training Loss 0.04982979489224298 	 Validation Loss 0.6040693521499634
INFO:WNN:Epoch 5: Training Loss 0.025908388729606355 	 Validation Loss 0.31685271859169006
INFO:WNN:Epoch 6: Training Loss 0.028449312717254673 	 Validation Loss 0.32773375511169434
INFO:WNN:Epoch 7: Training Loss 0.023186528639468764 	 Validation Loss 0.3662779629230499
INFO:WNN:Epoch 8: Training Loss 0.020396541438198516 	 Validation Loss 0.2641051709651947
INFO:WNN:Epoch 9: Training Loss 0.018674201564863324 	 Validation Loss 0.21435196697711945
INFO:WNN:Epoch 10: Training Loss 0.018448872308778976 	 Validation Loss 0.20917284488677979
INFO:WNN:Epoch 11: Training Loss 0.017037453678702668 	 Validation Loss 0.1849137544631958
INFO:WNN:Epoch 12: Training Loss 0.016201162910354987 	 Validation Loss 0.15596453845500946
INFO:WNN:Epoch 13: Training Loss 0.015670370959144617 	 Validation Loss 0.14896723628044128
INFO:WNN:Epoch 14: Training Loss 0.014861090225167572 	 Validation Loss 0.13402439653873444
INFO:WNN:Epoch 15: Training Loss 0.014454523292702757 	 Validation Loss 0.12081259489059448
INFO:WNN:Epoch 16: Training Loss 0.013862837679750686 	 Validation Loss 0.11587304621934891
INFO:WNN:Epoch 17: Training Loss 0.013492426693639053 	 Validation Loss 0.10333118587732315
INFO:WNN:Epoch 18: Training Loss 0.013143202780546355 	 Validation Loss 0.10090149194002151
INFO:WNN:Epoch 19: Training Loss 0.012609293035763715 	 Validation Loss 0.09188496321439743
INFO:WNN:Epoch 20: Training Loss 0.012778766553050705 	 Validation Loss 0.08821336925029755
INFO:WNN:Epoch 21: Training Loss 0.012106757211898054 	 Validation Loss 0.086490698158741
INFO:WNN:Epoch 22: Training Loss 0.015111127469156469 	 Validation Loss 0.07631757110357285
INFO:WNN:Epoch 23: Training Loss 0.021175803333920027 	 Validation Loss 0.08655853569507599
INFO:WNN:Epoch 24: Training Loss 0.034548418795956035 	 Validation Loss 0.06887711584568024
INFO:WNN:Epoch 25: Training Loss 0.05618777842859605 	 Validation Loss 0.13421794772148132
INFO:WNN:Epoch 26: Training Loss 0.06793513428419828 	 Validation Loss 0.10999137908220291
INFO:WNN:Epoch 27: Training Loss 0.1314025249864374 	 Validation Loss 0.41611364483833313
INFO:WNN:Epoch 28: Training Loss 0.269571271858045 	 Validation Loss 1.304703712463379
INFO:WNN:Epoch 29: Training Loss 0.26115996004747494 	 Validation Loss 0.2847927212715149
INFO:WNN:Epoch 30: Training Loss 0.0807192474603653 	 Validation Loss 0.9242260456085205
INFO:WNN:Epoch 31: Training Loss 0.07290543003806046 	 Validation Loss 0.8187083601951599
INFO:WNN:Epoch 32: Training Loss 0.01854807512635099 	 Validation Loss 0.4306221902370453
INFO:WNN:Epoch 33: Training Loss 0.03550172267880823 	 Validation Loss 0.2775856852531433
INFO:WNN:Epoch 34: Training Loss 0.014800197145502483 	 Validation Loss 0.3252907991409302
INFO:WNN:Epoch 35: Training Loss 0.016609420833577002 	 Validation Loss 0.2758522629737854
threshold tensor(1.6740, grad_fn=<MulBackward0>)
