INFO:WNN:Epoch 0: Training Loss 0.09012965502386744 	 Validation Loss 2.032607063651085
INFO:WNN:Epoch 1: Training Loss 0.013718666872150745 	 Validation Loss 1.6860714852809906
INFO:WNN:Epoch 2: Training Loss 0.018066566827297775 	 Validation Loss 1.3346390575170517
INFO:WNN:Epoch 3: Training Loss 0.010282286234679774 	 Validation Loss 1.0434850603342056
INFO:WNN:Epoch 4: Training Loss 0.014563768022609029 	 Validation Loss 1.2276849523186684
INFO:WNN:Epoch 5: Training Loss 0.021953305839843146 	 Validation Loss 1.7946533858776093
INFO:WNN:Epoch 6: Training Loss 0.025171253225187575 	 Validation Loss 2.245478942990303
INFO:WNN:Epoch 7: Training Loss 0.018110790473380774 	 Validation Loss 2.38289612531662
INFO:WNN:Epoch 8: Training Loss 0.01065225920385935 	 Validation Loss 2.3252779245376587
INFO:WNN:Epoch 9: Training Loss 0.008666159989044183 	 Validation Loss 2.3643500357866287
INFO:WNN:Epoch 10: Training Loss 0.008609532043478932 	 Validation Loss 2.3925225287675858
INFO:WNN:Epoch 11: Training Loss 0.009351345879787748 	 Validation Loss 2.387184515595436
INFO:WNN:Epoch 12: Training Loss 0.010145777922871552 	 Validation Loss 2.351873755455017
INFO:WNN:Epoch 13: Training Loss 0.010518419565139056 	 Validation Loss 2.2822127491235733
INFO:WNN:Epoch 14: Training Loss 0.010742977293292906 	 Validation Loss 2.2247971147298813
threshold tensor(12.6096, grad_fn=<MulBackward0>)
