INFO:WNN:Epoch 0: Training Loss 0.2373475106433034 	 Validation Loss 0.9081529080867767
INFO:WNN:Epoch 1: Training Loss 0.24610900559595653 	 Validation Loss 0.3989710062742233
INFO:WNN:Epoch 2: Training Loss 0.09752675831051809 	 Validation Loss 1.0571117003758748
INFO:WNN:Epoch 3: Training Loss 0.09783409704520767 	 Validation Loss 0.045602818640569844
INFO:WNN:Epoch 4: Training Loss 0.04692184784715729 	 Validation Loss 0.0502904187887907
INFO:WNN:Epoch 5: Training Loss 0.02013895098186497 	 Validation Loss 0.23102909388641515
INFO:WNN:Epoch 6: Training Loss 0.019535231294243463 	 Validation Loss 0.18771984179814658
INFO:WNN:Epoch 7: Training Loss 0.022259910434617527 	 Validation Loss 0.11029442834357421
INFO:WNN:Epoch 8: Training Loss 0.013782168409254935 	 Validation Loss 0.0246924568588535
INFO:WNN:Epoch 9: Training Loss 0.012182943130444204 	 Validation Loss 0.03054343567540248
INFO:WNN:Epoch 10: Training Loss 0.010769744915887714 	 Validation Loss 0.06853155558928847
INFO:WNN:Epoch 11: Training Loss 0.008969680407816278 	 Validation Loss 0.09877310320734978
INFO:WNN:Epoch 12: Training Loss 0.012759744427499494 	 Validation Loss 0.12811150401830673
INFO:WNN:Epoch 13: Training Loss 0.01793777743337809 	 Validation Loss 0.3492496907711029
INFO:WNN:Epoch 14: Training Loss 0.03869815642579592 	 Validation Loss 0.6001834770043691
INFO:WNN:Epoch 15: Training Loss 0.03776783140575779 	 Validation Loss 0.19492916141947111
INFO:WNN:Epoch 16: Training Loss 0.01867118990048766 	 Validation Loss 0.024916381264726322
INFO:WNN:Epoch 17: Training Loss 0.0370937914121896 	 Validation Loss 0.45792774856090546
INFO:WNN:Epoch 18: Training Loss 0.0826904226743084 	 Validation Loss 0.13396588216225305
INFO:WNN:Epoch 19: Training Loss 0.05882924847787113 	 Validation Loss 0.347412367661794
threshold tensor(1.4864, grad_fn=<MulBackward0>)
