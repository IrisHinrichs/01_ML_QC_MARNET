INFO:WNN:Epoch 0: Training Loss 0.23734751181410893 	 Validation Loss 0.9081530074278513
INFO:WNN:Epoch 1: Training Loss 0.2461090154413666 	 Validation Loss 0.3989710273842017
INFO:WNN:Epoch 2: Training Loss 0.09752673923836223 	 Validation Loss 1.0571119785308838
INFO:WNN:Epoch 3: Training Loss 0.09783408651128411 	 Validation Loss 0.04560287669301033
INFO:WNN:Epoch 4: Training Loss 0.046921843674499544 	 Validation Loss 0.05029043493171533
INFO:WNN:Epoch 5: Training Loss 0.020138939652991083 	 Validation Loss 0.23102925655742487
INFO:WNN:Epoch 6: Training Loss 0.019535248992698533 	 Validation Loss 0.18771998211741447
INFO:WNN:Epoch 7: Training Loss 0.022259944479446857 	 Validation Loss 0.11029460467398167
INFO:WNN:Epoch 8: Training Loss 0.013782167115381785 	 Validation Loss 0.024692362484832604
INFO:WNN:Epoch 9: Training Loss 0.012182970268518797 	 Validation Loss 0.030543573821584385
INFO:WNN:Epoch 10: Training Loss 0.010769754172568875 	 Validation Loss 0.06853195233270526
INFO:WNN:Epoch 11: Training Loss 0.008969687771916922 	 Validation Loss 0.09877414380510648
INFO:WNN:Epoch 12: Training Loss 0.012759862710455698 	 Validation Loss 0.12811273088057837
INFO:WNN:Epoch 13: Training Loss 0.017937953565602325 	 Validation Loss 0.34925567110379535
INFO:WNN:Epoch 14: Training Loss 0.038698427091419164 	 Validation Loss 0.6001721272865931
INFO:WNN:Epoch 15: Training Loss 0.03776750717910805 	 Validation Loss 0.19494975016762814
INFO:WNN:Epoch 16: Training Loss 0.018672171807182687 	 Validation Loss 0.02492148180802663
INFO:WNN:Epoch 17: Training Loss 0.03709773278928229 	 Validation Loss 0.4579562246799469
INFO:WNN:Epoch 18: Training Loss 0.08270024948121447 	 Validation Loss 0.13399182756741843
INFO:WNN:Epoch 19: Training Loss 0.05882598878649462 	 Validation Loss 0.3472371498743693
threshold tensor(1.4857, grad_fn=<MulBackward0>)
