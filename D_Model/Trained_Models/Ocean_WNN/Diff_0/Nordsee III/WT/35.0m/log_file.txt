INFO:WNN:Epoch 0: Training Loss 0.437289253808558 	 Validation Loss 0.6545981168746948
INFO:WNN:Epoch 1: Training Loss 0.08630087226629257 	 Validation Loss 0.31646928191185
INFO:WNN:Epoch 2: Training Loss 0.09905785042792559 	 Validation Loss 0.29257863759994507
INFO:WNN:Epoch 3: Training Loss 0.07057995954528451 	 Validation Loss 0.41108718514442444
INFO:WNN:Epoch 4: Training Loss 0.04289564350619912 	 Validation Loss 0.6016157269477844
INFO:WNN:Epoch 5: Training Loss 0.04196891561150551 	 Validation Loss 0.5926787853240967
INFO:WNN:Epoch 6: Training Loss 0.03151816944591701 	 Validation Loss 0.36609336733818054
INFO:WNN:Epoch 7: Training Loss 0.027271818369627 	 Validation Loss 0.22530078887939453
INFO:WNN:Epoch 8: Training Loss 0.02556070452556014 	 Validation Loss 0.24423055350780487
INFO:WNN:Epoch 9: Training Loss 0.02141294558532536 	 Validation Loss 0.3480239510536194
INFO:WNN:Epoch 10: Training Loss 0.01787282689474523 	 Validation Loss 0.33095911145210266
INFO:WNN:Epoch 11: Training Loss 0.015057575656101108 	 Validation Loss 0.22583384811878204
INFO:WNN:Epoch 12: Training Loss 0.013386801118031144 	 Validation Loss 0.19199590384960175
INFO:WNN:Epoch 13: Training Loss 0.012612494174391031 	 Validation Loss 0.18009020388126373
INFO:WNN:Epoch 14: Training Loss 0.011356019880622625 	 Validation Loss 0.18127106130123138
INFO:WNN:Epoch 15: Training Loss 0.010367704555392265 	 Validation Loss 0.15619666874408722
INFO:WNN:Epoch 16: Training Loss 0.009835917444434017 	 Validation Loss 0.12219849973917007
INFO:WNN:Epoch 17: Training Loss 0.009316210867837071 	 Validation Loss 0.1415964514017105
INFO:WNN:Epoch 18: Training Loss 0.010095814475789666 	 Validation Loss 0.10146325826644897
INFO:WNN:Epoch 19: Training Loss 0.010339156026020646 	 Validation Loss 0.21226340532302856
INFO:WNN:Epoch 20: Training Loss 0.023091405746527016 	 Validation Loss 0.06411898881196976
INFO:WNN:Epoch 21: Training Loss 0.03659102169331163 	 Validation Loss 0.16360460221767426
INFO:WNN:Epoch 22: Training Loss 0.017755179200321436 	 Validation Loss 0.18097807466983795
INFO:WNN:Epoch 23: Training Loss 0.010208396590314806 	 Validation Loss 0.1628580540418625
INFO:WNN:Epoch 24: Training Loss 0.009809689654503018 	 Validation Loss 0.16919700801372528
INFO:WNN:Epoch 25: Training Loss 0.010835727793164551 	 Validation Loss 0.1527138352394104
INFO:WNN:Epoch 26: Training Loss 0.008314811042509973 	 Validation Loss 0.1624503880739212
INFO:WNN:Epoch 27: Training Loss 0.007660223578568548 	 Validation Loss 0.17266905307769775
INFO:WNN:Epoch 28: Training Loss 0.008611648547230288 	 Validation Loss 0.13175369799137115
INFO:WNN:Epoch 29: Training Loss 0.007377107831416652 	 Validation Loss 0.13263696432113647
INFO:WNN:Epoch 30: Training Loss 0.00683200394269079 	 Validation Loss 0.14199556410312653
INFO:WNN:Epoch 31: Training Loss 0.007259375881403685 	 Validation Loss 0.11489498615264893
threshold tensor(0.5716, grad_fn=<MulBackward0>)
