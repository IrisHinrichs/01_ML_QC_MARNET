INFO:WNN:Epoch 0: Training Loss 0.10653783553844375 	 Validation Loss 2.1572426855564117
INFO:WNN:Epoch 1: Training Loss 0.04465773215545624 	 Validation Loss 2.8508040606975555
INFO:WNN:Epoch 2: Training Loss 0.10674016139554707 	 Validation Loss 3.7923264503479004
INFO:WNN:Epoch 3: Training Loss 0.14578202512171684 	 Validation Loss 3.5412210524082184
INFO:WNN:Epoch 4: Training Loss 0.08102218591551663 	 Validation Loss 4.703065514564514
INFO:WNN:Epoch 5: Training Loss 0.08231298703432197 	 Validation Loss 1.8008646070957184
INFO:WNN:Epoch 6: Training Loss 0.07493670903160378 	 Validation Loss 3.599966883659363
INFO:WNN:Epoch 7: Training Loss 0.028741202867505224 	 Validation Loss 3.3397443294525146
INFO:WNN:Epoch 8: Training Loss 0.009594739524111377 	 Validation Loss 3.102384388446808
INFO:WNN:Epoch 9: Training Loss 0.00725218928842382 	 Validation Loss 2.924300789833069
INFO:WNN:Epoch 10: Training Loss 0.006354180099372046 	 Validation Loss 2.804822325706482
INFO:WNN:Epoch 11: Training Loss 0.0061190397766150645 	 Validation Loss 2.702701151371002
INFO:WNN:Epoch 12: Training Loss 0.0054983539333933905 	 Validation Loss 2.631873279809952
INFO:WNN:Epoch 13: Training Loss 0.004925899814362779 	 Validation Loss 2.582529902458191
INFO:WNN:Epoch 14: Training Loss 0.0045910727895909186 	 Validation Loss 2.5399120151996613
INFO:WNN:Epoch 15: Training Loss 0.0042910906327465045 	 Validation Loss 2.50127512216568
INFO:WNN:Epoch 16: Training Loss 0.0041516248858181025 	 Validation Loss 2.4612922370433807
threshold tensor(12.2232, grad_fn=<MulBackward0>)
