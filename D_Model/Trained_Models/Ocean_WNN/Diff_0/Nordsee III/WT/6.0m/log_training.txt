INFO:WNN:Epoch 0: Training Loss 0.10653784233286526 	 Validation Loss 2.1572426855564117
INFO:WNN:Epoch 1: Training Loss 0.04465774222008997 	 Validation Loss 2.8508040010929108
INFO:WNN:Epoch 2: Training Loss 0.10674019461977437 	 Validation Loss 3.7923277020454407
INFO:WNN:Epoch 3: Training Loss 0.14578204141280643 	 Validation Loss 3.541219800710678
INFO:WNN:Epoch 4: Training Loss 0.08102209677665749 	 Validation Loss 4.703061580657959
INFO:WNN:Epoch 5: Training Loss 0.08231294017186332 	 Validation Loss 1.8008664399385452
INFO:WNN:Epoch 6: Training Loss 0.07493688244104499 	 Validation Loss 3.5999664068222046
INFO:WNN:Epoch 7: Training Loss 0.02874122496524995 	 Validation Loss 3.339745283126831
INFO:WNN:Epoch 8: Training Loss 0.009594755247235298 	 Validation Loss 3.1023858189582825
INFO:WNN:Epoch 9: Training Loss 0.007252199076130196 	 Validation Loss 2.9243019223213196
INFO:WNN:Epoch 10: Training Loss 0.006354182444435234 	 Validation Loss 2.8048229217529297
INFO:WNN:Epoch 11: Training Loss 0.006119037929844732 	 Validation Loss 2.7027015388011932
INFO:WNN:Epoch 12: Training Loss 0.005498355293336014 	 Validation Loss 2.631873279809952
INFO:WNN:Epoch 13: Training Loss 0.0049259008603368066 	 Validation Loss 2.5825297236442566
INFO:WNN:Epoch 14: Training Loss 0.004591080450071869 	 Validation Loss 2.539911150932312
INFO:WNN:Epoch 15: Training Loss 0.004291099239542911 	 Validation Loss 2.5012737810611725
INFO:WNN:Epoch 16: Training Loss 0.0041516347282044026 	 Validation Loss 2.4612908363342285
threshold tensor(12.2232, grad_fn=<MulBackward0>)
