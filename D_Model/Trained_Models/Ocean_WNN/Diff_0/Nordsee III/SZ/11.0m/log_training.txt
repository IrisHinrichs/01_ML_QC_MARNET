INFO:WNN:Epoch 0: Training Loss 0.33073121842795183 	 Validation Loss 0.3995890070994695
INFO:WNN:Epoch 1: Training Loss 0.09360318391450814 	 Validation Loss 0.1445174583544334
INFO:WNN:Epoch 2: Training Loss 0.0600409039628825 	 Validation Loss 0.08809179533272982
INFO:WNN:Epoch 3: Training Loss 0.05576561968108373 	 Validation Loss 0.2435008535782496
INFO:WNN:Epoch 4: Training Loss 0.06661958214494267 	 Validation Loss 0.10955027242501576
INFO:WNN:Epoch 5: Training Loss 0.07329558630340866 	 Validation Loss 0.20575804015000662
INFO:WNN:Epoch 6: Training Loss 0.04274839873957847 	 Validation Loss 0.08444969200839599
INFO:WNN:Epoch 7: Training Loss 0.03416717330193413 	 Validation Loss 0.07709958031773567
INFO:WNN:Epoch 8: Training Loss 0.0284636390603347 	 Validation Loss 0.08148074429482222
INFO:WNN:Epoch 9: Training Loss 0.03193704052828252 	 Validation Loss 0.0717402206112941
INFO:WNN:Epoch 10: Training Loss 0.030939110042527317 	 Validation Loss 0.07160795355836551
INFO:WNN:Epoch 11: Training Loss 0.0335895708362971 	 Validation Loss 0.06845877754191558
INFO:WNN:Epoch 12: Training Loss 0.04089556491401579 	 Validation Loss 0.06773228570818901
INFO:WNN:Epoch 13: Training Loss 0.05605703750625253 	 Validation Loss 0.07445752217123906
INFO:WNN:Epoch 14: Training Loss 0.04029783200073455 	 Validation Loss 0.08616017798582713
INFO:WNN:Epoch 15: Training Loss 0.02794773083047143 	 Validation Loss 0.07510011736303568
INFO:WNN:Epoch 16: Training Loss 0.026073058864234815 	 Validation Loss 0.09132973725597064
INFO:WNN:Epoch 17: Training Loss 0.023588365364620195 	 Validation Loss 0.07356639951467514
INFO:WNN:Epoch 18: Training Loss 0.029093479890642423 	 Validation Loss 0.08938698408504327
INFO:WNN:Epoch 19: Training Loss 0.026073354954964347 	 Validation Loss 0.08056432039787371
INFO:WNN:Epoch 20: Training Loss 0.027076335118285246 	 Validation Loss 0.07597926693658034
INFO:WNN:Epoch 21: Training Loss 0.030134361520010446 	 Validation Loss 0.10116995126008987
INFO:WNN:Epoch 22: Training Loss 0.02771001918507474 	 Validation Loss 0.08255588139096896
INFO:WNN:Epoch 23: Training Loss 0.028686984106233077 	 Validation Loss 0.09748270362615585
threshold tensor(1.2285, grad_fn=<MulBackward0>)
