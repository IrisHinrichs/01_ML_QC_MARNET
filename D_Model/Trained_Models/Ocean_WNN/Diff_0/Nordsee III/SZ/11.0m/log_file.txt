INFO:WNN:Epoch 0: Training Loss 0.4491533326605956 	 Validation Loss 1.2131937742233276
INFO:WNN:Epoch 1: Training Loss 0.37221814369161926 	 Validation Loss 1.186278223991394
INFO:WNN:Epoch 2: Training Loss 0.24458702579140662 	 Validation Loss 1.097853183746338
INFO:WNN:Epoch 3: Training Loss 0.2364466181024909 	 Validation Loss 1.0353713035583496
INFO:WNN:Epoch 4: Training Loss 0.19020239748060702 	 Validation Loss 1.0244046449661255
INFO:WNN:Epoch 5: Training Loss 0.18375889969368775 	 Validation Loss 0.9849897623062134
INFO:WNN:Epoch 6: Training Loss 0.16938288677483798 	 Validation Loss 0.9645715951919556
INFO:WNN:Epoch 7: Training Loss 0.17044433491925398 	 Validation Loss 0.9826837182044983
INFO:WNN:Epoch 8: Training Loss 0.16257194789747398 	 Validation Loss 0.9560760855674744
INFO:WNN:Epoch 9: Training Loss 0.16199770715708534 	 Validation Loss 0.9791275858879089
INFO:WNN:Epoch 10: Training Loss 0.15839088029849033 	 Validation Loss 0.9685797691345215
INFO:WNN:Epoch 11: Training Loss 0.15590392237451547 	 Validation Loss 0.9674848914146423
INFO:WNN:Epoch 12: Training Loss 0.15438323891721667 	 Validation Loss 0.9762595295906067
INFO:WNN:Epoch 13: Training Loss 0.15262883744047334 	 Validation Loss 0.9805340766906738
INFO:WNN:Epoch 14: Training Loss 0.15052252220145115 	 Validation Loss 0.9740064144134521
INFO:WNN:Epoch 15: Training Loss 0.148653778526932 	 Validation Loss 0.9817256927490234
INFO:WNN:Epoch 16: Training Loss 0.15010424290473262 	 Validation Loss 1.018852949142456
INFO:WNN:Epoch 17: Training Loss 0.15226832876602808 	 Validation Loss 1.0218017101287842
threshold tensor(5.8296, grad_fn=<MulBackward0>)
