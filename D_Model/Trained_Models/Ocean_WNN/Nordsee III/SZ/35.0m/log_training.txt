INFO:WNN:Epoch 0: Training Loss 0.5969524816876012 	 Validation Loss 0.0128078560034434
INFO:WNN:Epoch 1: Training Loss 0.206906788939211 	 Validation Loss 0.017439975403249264
INFO:WNN:Epoch 2: Training Loss 0.16070709611189418 	 Validation Loss 0.02164251667757829
INFO:WNN:Epoch 3: Training Loss 0.18704875458497555 	 Validation Loss 0.014408524303386608
INFO:WNN:Epoch 4: Training Loss 0.12353789589168238 	 Validation Loss 0.0066758870768050356
INFO:WNN:Epoch 5: Training Loss 0.11128885225792017 	 Validation Loss 0.003908240546782811
INFO:WNN:Epoch 6: Training Loss 0.09370004937518388 	 Validation Loss 0.003332354089555641
INFO:WNN:Epoch 7: Training Loss 0.09147628063136445 	 Validation Loss 0.005910883502413829
INFO:WNN:Epoch 8: Training Loss 0.1115894318192399 	 Validation Loss 0.014430303126573563
INFO:WNN:Epoch 9: Training Loss 0.21730524029449694 	 Validation Loss 0.044541917741298676
INFO:WNN:Epoch 10: Training Loss 0.39467100437198366 	 Validation Loss 0.037805940955877304
INFO:WNN:Epoch 11: Training Loss 0.22911178013309835 	 Validation Loss 0.011817526227484146
INFO:WNN:Epoch 12: Training Loss 0.19992127941056553 	 Validation Loss 0.04384985193610191
INFO:WNN:Epoch 13: Training Loss 0.1794499873649329 	 Validation Loss 0.048708392928044
INFO:WNN:Epoch 14: Training Loss 0.16566227853763849 	 Validation Loss 0.006090118239323298
INFO:WNN:Epoch 15: Training Loss 0.1622581701825506 	 Validation Loss 0.043144515405098595
INFO:WNN:Epoch 16: Training Loss 0.21429419414406375 	 Validation Loss 0.003992182241442303
INFO:WNN:Epoch 17: Training Loss 0.16705957001873425 	 Validation Loss 0.03764557962616285
threshold tensor(0.1006, grad_fn=<MulBackward0>)
