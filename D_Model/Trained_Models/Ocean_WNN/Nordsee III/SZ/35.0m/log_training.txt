INFO:WNN:Epoch 0: Training Loss 0.01728595294052998 	 Validation Loss 9.76787991172993e-06
INFO:WNN:Epoch 1: Training Loss 9.185568068029885e-05 	 Validation Loss 2.484335678016376e-06
INFO:WNN:Epoch 2: Training Loss 5.7238827505098505e-05 	 Validation Loss 1.2137096796828297e-05
INFO:WNN:Epoch 3: Training Loss 0.00011193019288384676 	 Validation Loss 2.576022284807146e-05
INFO:WNN:Epoch 4: Training Loss 0.00012031115477181434 	 Validation Loss 2.6331501329776882e-05
INFO:WNN:Epoch 5: Training Loss 9.657688513341003e-05 	 Validation Loss 1.2605625821985692e-05
INFO:WNN:Epoch 6: Training Loss 8.792672735619281e-05 	 Validation Loss 7.3191435237479e-06
INFO:WNN:Epoch 7: Training Loss 8.744844495142599e-05 	 Validation Loss 5.567193707318236e-06
INFO:WNN:Epoch 8: Training Loss 8.834896893919872e-05 	 Validation Loss 5.170378655192407e-06
INFO:WNN:Epoch 9: Training Loss 9.160989506723029e-05 	 Validation Loss 6.335854259810327e-06
INFO:WNN:Epoch 10: Training Loss 9.504834067765192e-05 	 Validation Loss 6.6338196802462335e-06
INFO:WNN:Epoch 11: Training Loss 9.6733859728561e-05 	 Validation Loss 5.375472110497665e-06
INFO:WNN:Epoch 12: Training Loss 9.678119031499526e-05 	 Validation Loss 4.54039208206167e-06
threshold tensor(3.5423e-05, grad_fn=<MulBackward0>)
