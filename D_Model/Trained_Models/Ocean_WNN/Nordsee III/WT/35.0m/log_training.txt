INFO:WNN:Epoch 0: Training Loss 0.017659393075809198 	 Validation Loss 0.0003875975859652196
INFO:WNN:Epoch 1: Training Loss 3.316075497658793e-05 	 Validation Loss 0.00027698393124511413
INFO:WNN:Epoch 2: Training Loss 4.198433328527683e-05 	 Validation Loss 0.0005218961628593712
INFO:WNN:Epoch 3: Training Loss 8.217167927690688e-05 	 Validation Loss 0.00035052826125239435
INFO:WNN:Epoch 4: Training Loss 5.441415480171534e-05 	 Validation Loss 0.00022226925820076658
INFO:WNN:Epoch 5: Training Loss 6.261681322854429e-05 	 Validation Loss 0.00023848670636855078
INFO:WNN:Epoch 6: Training Loss 6.481111922767014e-05 	 Validation Loss 0.0003099956204298198
INFO:WNN:Epoch 7: Training Loss 6.92440867804781e-05 	 Validation Loss 0.0003371420927780693
INFO:WNN:Epoch 8: Training Loss 6.763118569291951e-05 	 Validation Loss 0.00034899046618698374
INFO:WNN:Epoch 9: Training Loss 6.903140904504263e-05 	 Validation Loss 0.00035567078106800583
INFO:WNN:Epoch 10: Training Loss 6.674368537663408e-05 	 Validation Loss 0.0003471470720089403
INFO:WNN:Epoch 11: Training Loss 6.516110031376293e-05 	 Validation Loss 0.00032975467305125977
INFO:WNN:Epoch 12: Training Loss 6.588907620133405e-05 	 Validation Loss 0.0003207052444243648
INFO:WNN:Epoch 13: Training Loss 6.913310838569941e-05 	 Validation Loss 0.00031201896813905076
INFO:WNN:Epoch 14: Training Loss 6.965649866158076e-05 	 Validation Loss 0.00029688723639588314
INFO:WNN:Epoch 15: Training Loss 6.825466942643743e-05 	 Validation Loss 0.0002840890836321503
threshold tensor(0.0013, grad_fn=<MulBackward0>)
