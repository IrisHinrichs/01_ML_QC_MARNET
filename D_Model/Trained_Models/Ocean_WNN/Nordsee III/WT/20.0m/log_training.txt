INFO:WNN:Epoch 0: Training Loss 0.01775812950974601 	 Validation Loss 0.0008667286068278676
INFO:WNN:Epoch 1: Training Loss 0.00011508723007815595 	 Validation Loss 0.000888412190154971
INFO:WNN:Epoch 2: Training Loss 9.042111359747196e-05 	 Validation Loss 0.0006297976815403672
INFO:WNN:Epoch 3: Training Loss 0.00013176135756631473 	 Validation Loss 0.000602226953156383
INFO:WNN:Epoch 4: Training Loss 0.00013126893493335955 	 Validation Loss 0.0006056807069398928
INFO:WNN:Epoch 5: Training Loss 0.00013173182938349523 	 Validation Loss 0.0006155158359130534
INFO:WNN:Epoch 6: Training Loss 0.0001275443992093577 	 Validation Loss 0.0006349968924850044
INFO:WNN:Epoch 7: Training Loss 0.00012356071513376524 	 Validation Loss 0.0006420801689980888
INFO:WNN:Epoch 8: Training Loss 0.00012026928414538166 	 Validation Loss 0.0006585137982458238
INFO:WNN:Epoch 9: Training Loss 0.00011709700517680436 	 Validation Loss 0.0006617847078208191
INFO:WNN:Epoch 10: Training Loss 0.0001137874543311617 	 Validation Loss 0.0006446531543689263
INFO:WNN:Epoch 11: Training Loss 0.00011151945058713863 	 Validation Loss 0.000628327511448232
INFO:WNN:Epoch 12: Training Loss 0.00011066802435948375 	 Validation Loss 0.0006183068787019389
INFO:WNN:Epoch 13: Training Loss 0.0001099765934376202 	 Validation Loss 0.0006100753627025471
threshold tensor(0.0098, grad_fn=<MulBackward0>)
