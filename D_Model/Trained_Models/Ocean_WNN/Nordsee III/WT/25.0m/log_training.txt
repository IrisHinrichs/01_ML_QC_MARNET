INFO:WNN:Epoch 0: Training Loss 0.2506327969687326 	 Validation Loss 0.39067451904217404
INFO:WNN:Epoch 1: Training Loss 0.09295485438778997 	 Validation Loss 0.15489605348557234
INFO:WNN:Epoch 2: Training Loss 0.044140447140671314 	 Validation Loss 0.13640361403425535
INFO:WNN:Epoch 3: Training Loss 0.04002302124364568 	 Validation Loss 0.23415118331710497
INFO:WNN:Epoch 4: Training Loss 0.060015366093388624 	 Validation Loss 0.12400397037466367
INFO:WNN:Epoch 5: Training Loss 0.07289833739799048 	 Validation Loss 0.08583108770350616
INFO:WNN:Epoch 6: Training Loss 0.0465899840729045 	 Validation Loss 0.44695213561256725
INFO:WNN:Epoch 7: Training Loss 0.04786759856423097 	 Validation Loss 0.6382104655106863
INFO:WNN:Epoch 8: Training Loss 0.07796345742452623 	 Validation Loss 0.4116811503966649
INFO:WNN:Epoch 9: Training Loss 0.07748996016702482 	 Validation Loss 0.12874967977404594
INFO:WNN:Epoch 10: Training Loss 0.038921804489967016 	 Validation Loss 0.19652257456133762
INFO:WNN:Epoch 11: Training Loss 0.018626419900517378 	 Validation Loss 0.14080085364791253
INFO:WNN:Epoch 12: Training Loss 0.015307730105372943 	 Validation Loss 0.12581434535483518
INFO:WNN:Epoch 13: Training Loss 0.01716069998302763 	 Validation Loss 0.10048229619860649
INFO:WNN:Epoch 14: Training Loss 0.019168232251623913 	 Validation Loss 0.13165323436260223
INFO:WNN:Epoch 15: Training Loss 0.021937513346451203 	 Validation Loss 0.12310910224914551
INFO:WNN:Epoch 16: Training Loss 0.022775724852856782 	 Validation Loss 0.17618643989165625
threshold tensor(0.5192, grad_fn=<MulBackward0>)
