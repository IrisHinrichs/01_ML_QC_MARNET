INFO:WNN:Epoch 0: Training Loss 0.01996096374087546 	 Validation Loss 0.037761606049672186
INFO:WNN:Epoch 1: Training Loss 0.002025243948698447 	 Validation Loss 0.02942065650778305
INFO:WNN:Epoch 2: Training Loss 0.0014005751157058581 	 Validation Loss 0.024466211600358494
INFO:WNN:Epoch 3: Training Loss 0.0010913073485146294 	 Validation Loss 0.024561835764971975
INFO:WNN:Epoch 4: Training Loss 0.0009410165610671147 	 Validation Loss 0.026024056769933343
INFO:WNN:Epoch 5: Training Loss 0.0009038066131604584 	 Validation Loss 0.027748501969553117
INFO:WNN:Epoch 6: Training Loss 0.0009442377975854189 	 Validation Loss 0.030196458340570744
INFO:WNN:Epoch 7: Training Loss 0.0010153826313538817 	 Validation Loss 0.03284222794334508
INFO:WNN:Epoch 8: Training Loss 0.0008636410794329444 	 Validation Loss 0.03333460975490096
INFO:WNN:Epoch 9: Training Loss 0.0008172458113431976 	 Validation Loss 0.03553606477928244
INFO:WNN:Epoch 10: Training Loss 0.0007955801208411755 	 Validation Loss 0.03814628394320607
INFO:WNN:Epoch 11: Training Loss 0.0007751293079938758 	 Validation Loss 0.04063547120636536
INFO:WNN:Epoch 12: Training Loss 0.0007762710846761295 	 Validation Loss 0.042900787097298436
INFO:WNN:Epoch 13: Training Loss 0.0008162933536368655 	 Validation Loss 0.04535012394707236
threshold tensor(0.4924, grad_fn=<MulBackward0>)
