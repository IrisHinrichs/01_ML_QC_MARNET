INFO:WNN:Epoch 0: Training Loss 0.017654150779856284 	 Validation Loss 0.0004665858400080146
INFO:WNN:Epoch 1: Training Loss 5.098784102496471e-05 	 Validation Loss 0.00043445950036079413
INFO:WNN:Epoch 2: Training Loss 5.644080650353902e-05 	 Validation Loss 0.0006402735040561917
INFO:WNN:Epoch 3: Training Loss 0.0001251934035622071 	 Validation Loss 0.00048376701306551695
INFO:WNN:Epoch 4: Training Loss 0.000105732746646936 	 Validation Loss 0.0003677989174219773
INFO:WNN:Epoch 5: Training Loss 7.59125896084559e-05 	 Validation Loss 0.0002927452078438364
INFO:WNN:Epoch 6: Training Loss 7.561904541424675e-05 	 Validation Loss 0.0002797684150108479
INFO:WNN:Epoch 7: Training Loss 7.634750100383566e-05 	 Validation Loss 0.00034386635666629043
INFO:WNN:Epoch 8: Training Loss 8.178272718168955e-05 	 Validation Loss 0.00037736851966959267
INFO:WNN:Epoch 9: Training Loss 8.162678197436435e-05 	 Validation Loss 0.0004045160496591254
INFO:WNN:Epoch 10: Training Loss 8.465873465866026e-05 	 Validation Loss 0.0003937447997183578
INFO:WNN:Epoch 11: Training Loss 8.624163687451464e-05 	 Validation Loss 0.0003914849198230917
INFO:WNN:Epoch 12: Training Loss 8.760101741245307e-05 	 Validation Loss 0.0003920414114367708
INFO:WNN:Epoch 13: Training Loss 9.00686564640247e-05 	 Validation Loss 0.00039086332233435113
INFO:WNN:Epoch 14: Training Loss 9.185768221706375e-05 	 Validation Loss 0.000384725214644277
INFO:WNN:Epoch 15: Training Loss 9.05845699922533e-05 	 Validation Loss 0.00037401298110732267
INFO:WNN:Epoch 16: Training Loss 8.653869533320955e-05 	 Validation Loss 0.0003633256750011545
threshold tensor(0.0016, grad_fn=<MulBackward0>)
