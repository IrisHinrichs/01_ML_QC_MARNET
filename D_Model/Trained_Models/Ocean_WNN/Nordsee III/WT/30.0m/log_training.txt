INFO:WNN:Epoch 0: Training Loss 0.2469842671815838 	 Validation Loss 0.7059503793716431
INFO:WNN:Epoch 1: Training Loss 0.1955278021416494 	 Validation Loss 0.15111382553974786
INFO:WNN:Epoch 2: Training Loss 0.08747844169182437 	 Validation Loss 1.76919953028361
INFO:WNN:Epoch 3: Training Loss 0.13309597461151756 	 Validation Loss 0.023378806188702583
INFO:WNN:Epoch 4: Training Loss 0.056034568790346385 	 Validation Loss 0.04943329282104969
INFO:WNN:Epoch 5: Training Loss 0.029273470933549105 	 Validation Loss 0.2725423313677311
INFO:WNN:Epoch 6: Training Loss 0.027284405270724423 	 Validation Loss 0.2637430727481842
INFO:WNN:Epoch 7: Training Loss 0.02920659713314048 	 Validation Loss 0.09284121729433537
INFO:WNN:Epoch 8: Training Loss 0.014553303642398013 	 Validation Loss 0.020655444512764614
INFO:WNN:Epoch 9: Training Loss 0.0183280985735889 	 Validation Loss 0.03219999341915051
INFO:WNN:Epoch 10: Training Loss 0.017185057965772493 	 Validation Loss 0.17568675925334296
INFO:WNN:Epoch 11: Training Loss 0.01860377022364576 	 Validation Loss 0.057203794519106545
INFO:WNN:Epoch 12: Training Loss 0.01486084669262969 	 Validation Loss 0.154428002734979
INFO:WNN:Epoch 13: Training Loss 0.02617780917789787 	 Validation Loss 0.028912488992015522
INFO:WNN:Epoch 14: Training Loss 0.029256617231294513 	 Validation Loss 0.32446110000212985
INFO:WNN:Epoch 15: Training Loss 0.03754429053182581 	 Validation Loss 0.11925547942519188
INFO:WNN:Epoch 16: Training Loss 0.022529272329328314 	 Validation Loss 0.16907029350598654
INFO:WNN:Epoch 17: Training Loss 0.024532991740852595 	 Validation Loss 0.09504322210947673
INFO:WNN:Epoch 18: Training Loss 0.020088774285146167 	 Validation Loss 0.11344826718171437
INFO:WNN:Epoch 19: Training Loss 0.02007333228497633 	 Validation Loss 0.07202968870600064
threshold tensor(0.2818, grad_fn=<MulBackward0>)
