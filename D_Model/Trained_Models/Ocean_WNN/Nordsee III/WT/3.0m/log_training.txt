INFO:WNN:Epoch 0: Training Loss 0.032991362629093045 	 Validation Loss 0.013245922679613744
INFO:WNN:Epoch 1: Training Loss 0.0231172437639927 	 Validation Loss 0.007857537597634032
INFO:WNN:Epoch 2: Training Loss 0.012371908548177355 	 Validation Loss 0.008004218973967778
INFO:WNN:Epoch 3: Training Loss 0.011837399546101376 	 Validation Loss 0.008408132360533014
INFO:WNN:Epoch 4: Training Loss 0.010194288973133795 	 Validation Loss 0.021021594817284495
INFO:WNN:Epoch 5: Training Loss 0.01491202504733279 	 Validation Loss 0.021605295802666142
INFO:WNN:Epoch 6: Training Loss 0.01093374981450191 	 Validation Loss 0.005997200147248805
INFO:WNN:Epoch 7: Training Loss 0.014385310807742283 	 Validation Loss 0.013109084293578885
INFO:WNN:Epoch 8: Training Loss 0.012147945992258036 	 Validation Loss 0.015033727245671409
INFO:WNN:Epoch 9: Training Loss 0.008824168619207947 	 Validation Loss 0.010198814802736576
INFO:WNN:Epoch 10: Training Loss 0.008185158511986871 	 Validation Loss 0.009144987725968739
INFO:WNN:Epoch 11: Training Loss 0.009006519380376414 	 Validation Loss 0.032899930798781236
INFO:WNN:Epoch 12: Training Loss 0.010227657437324258 	 Validation Loss 0.021121592011435757
INFO:WNN:Epoch 13: Training Loss 0.009968926070967327 	 Validation Loss 0.0358449610149754
INFO:WNN:Epoch 14: Training Loss 0.015359354235084088 	 Validation Loss 0.021194943971100395
INFO:WNN:Epoch 15: Training Loss 0.010612321062625881 	 Validation Loss 0.023264559725898186
INFO:WNN:Epoch 16: Training Loss 0.005637124537649445 	 Validation Loss 0.02727081929749277
INFO:WNN:Epoch 17: Training Loss 0.006545940648829188 	 Validation Loss 0.027844002911089256
threshold tensor(0.1684, grad_fn=<MulBackward0>)
