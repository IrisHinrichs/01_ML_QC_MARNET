INFO:WNN:Epoch 0: Training Loss 0.21648569345577723 	 Validation Loss 0.2210090309381485
INFO:WNN:Epoch 1: Training Loss 0.9187071352477048 	 Validation Loss 0.35640619695186615
INFO:WNN:Epoch 2: Training Loss 0.27850587133111226 	 Validation Loss 0.36987652629613876
INFO:WNN:Epoch 3: Training Loss 0.9295098679528261 	 Validation Loss 0.8900086283683777
INFO:WNN:Epoch 4: Training Loss 0.9043145606690949 	 Validation Loss 0.9621084481477737
INFO:WNN:Epoch 5: Training Loss 0.6248295732118465 	 Validation Loss 1.413370668888092
INFO:WNN:Epoch 6: Training Loss 0.35015298358026753 	 Validation Loss 0.961618185043335
INFO:WNN:Epoch 7: Training Loss 0.307800659030262 	 Validation Loss 1.0679457187652588
INFO:WNN:Epoch 8: Training Loss 0.250868402240384 	 Validation Loss 0.6282727420330048
INFO:WNN:Epoch 9: Training Loss 0.20742112184719494 	 Validation Loss 0.728349506855011
INFO:WNN:Epoch 10: Training Loss 0.4339745457594593 	 Validation Loss 0.9993449300527573
INFO:WNN:Epoch 11: Training Loss 0.40297747991496213 	 Validation Loss 0.7434022724628448
threshold tensor(1.5928, grad_fn=<MulBackward0>)
