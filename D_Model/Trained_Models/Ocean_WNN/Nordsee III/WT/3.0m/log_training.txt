INFO:WNN:Epoch 0: Training Loss 0.21648569760361203 	 Validation Loss 0.2210090458393097
INFO:WNN:Epoch 1: Training Loss 0.91870711902717 	 Validation Loss 0.35640624910593033
INFO:WNN:Epoch 2: Training Loss 0.2785058576458444 	 Validation Loss 0.3698766715824604
INFO:WNN:Epoch 3: Training Loss 0.9295099495750576 	 Validation Loss 0.8900087773799896
INFO:WNN:Epoch 4: Training Loss 0.9043149802902782 	 Validation Loss 0.9621064066886902
INFO:WNN:Epoch 5: Training Loss 0.6248285683492819 	 Validation Loss 1.413370132446289
INFO:WNN:Epoch 6: Training Loss 0.3501512915999801 	 Validation Loss 0.961576372385025
INFO:WNN:Epoch 7: Training Loss 0.30779736089796106 	 Validation Loss 1.068033754825592
INFO:WNN:Epoch 8: Training Loss 0.2508995026755319 	 Validation Loss 0.6284219324588776
INFO:WNN:Epoch 9: Training Loss 0.20746054201973257 	 Validation Loss 0.7287102788686752
INFO:WNN:Epoch 10: Training Loss 0.43399207277602897 	 Validation Loss 0.9983894228935242
INFO:WNN:Epoch 11: Training Loss 0.4029173419500391 	 Validation Loss 0.7431996464729309
threshold tensor(1.5931, grad_fn=<MulBackward0>)
