INFO:WNN:Epoch 0: Training Loss 0.047053124569945884 	 Validation Loss 0.055343921110033986
INFO:WNN:Epoch 1: Training Loss 0.020603767218203815 	 Validation Loss 0.030960613489151002
INFO:WNN:Epoch 2: Training Loss 0.023551878543670843 	 Validation Loss 0.03844389505684376
INFO:WNN:Epoch 3: Training Loss 0.02283255471641646 	 Validation Loss 0.036663345992565155
INFO:WNN:Epoch 4: Training Loss 0.020548272289223735 	 Validation Loss 0.04282421693205833
INFO:WNN:Epoch 5: Training Loss 0.022525945060910022 	 Validation Loss 0.045246805995702744
INFO:WNN:Epoch 6: Training Loss 0.01950638522312953 	 Validation Loss 0.032393550127744676
INFO:WNN:Epoch 7: Training Loss 0.019351088932621045 	 Validation Loss 0.022337467409670353
INFO:WNN:Epoch 8: Training Loss 0.01598698916532618 	 Validation Loss 0.037821239605545995
INFO:WNN:Epoch 9: Training Loss 0.015764356805217934 	 Validation Loss 0.034089570119977
INFO:WNN:Epoch 10: Training Loss 0.014527383468576554 	 Validation Loss 0.03914541378617287
INFO:WNN:Epoch 11: Training Loss 0.01568347094816309 	 Validation Loss 0.0640526320785284
INFO:WNN:Epoch 12: Training Loss 0.01600934531689987 	 Validation Loss 0.04227558821439743
INFO:WNN:Epoch 13: Training Loss 0.020351710039650715 	 Validation Loss 0.0744491271674633
INFO:WNN:Epoch 14: Training Loss 0.016674593742715807 	 Validation Loss 0.057979410886764525
INFO:WNN:Epoch 15: Training Loss 0.01574980720650711 	 Validation Loss 0.05278115831315518
INFO:WNN:Epoch 16: Training Loss 0.015712594289238317 	 Validation Loss 0.06599897965788841
INFO:WNN:Epoch 17: Training Loss 0.018243785030238 	 Validation Loss 0.07260831221938133
INFO:WNN:Epoch 18: Training Loss 0.0220837020963619 	 Validation Loss 0.14076778516173363
threshold tensor(0.6836, grad_fn=<MulBackward0>)
