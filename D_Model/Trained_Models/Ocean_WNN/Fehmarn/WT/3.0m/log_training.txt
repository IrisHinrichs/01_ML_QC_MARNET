INFO:WNN:Epoch 0: Training Loss 0.2777875855482549 	 Validation Loss 0.14945497252047063
INFO:WNN:Epoch 1: Training Loss 0.1718808044944713 	 Validation Loss 0.21115460693836213
INFO:WNN:Epoch 2: Training Loss 0.0915128878049576 	 Validation Loss 0.20739025250077248
INFO:WNN:Epoch 3: Training Loss 0.08080452106616023 	 Validation Loss 0.25574546232819556
INFO:WNN:Epoch 4: Training Loss 0.1853653977056258 	 Validation Loss 1.619784903526306
INFO:WNN:Epoch 5: Training Loss 0.2774518359381753 	 Validation Loss 0.5841690547764301
INFO:WNN:Epoch 6: Training Loss 0.19974961115896137 	 Validation Loss 1.3835934817790985
INFO:WNN:Epoch 7: Training Loss 0.27147288010470405 	 Validation Loss 0.27247912958264353
INFO:WNN:Epoch 8: Training Loss 0.1789901773946336 	 Validation Loss 0.15550491213798523
INFO:WNN:Epoch 9: Training Loss 0.3506938676066885 	 Validation Loss 0.17264699637889863
INFO:WNN:Epoch 10: Training Loss 0.5180702608880363 	 Validation Loss 1.0767637275159359
INFO:WNN:Epoch 11: Training Loss 0.9264513008308278 	 Validation Loss 3.21005045324564
threshold tensor(17.4575, grad_fn=<MulBackward0>)
