INFO:WNN:Epoch 0: Training Loss 0.035197645345201284 	 Validation Loss 0.00785207183798775
INFO:WNN:Epoch 1: Training Loss 0.05023004818513136 	 Validation Loss 0.0247640453485979
INFO:WNN:Epoch 2: Training Loss 0.04337779119841989 	 Validation Loss 0.06142642079956002
INFO:WNN:Epoch 3: Training Loss 0.04495109995469692 	 Validation Loss 0.048521123826503754
INFO:WNN:Epoch 4: Training Loss 0.046634089690348185 	 Validation Loss 0.019332523354225688
INFO:WNN:Epoch 5: Training Loss 0.03159366777218419 	 Validation Loss 0.044552757715185486
INFO:WNN:Epoch 6: Training Loss 0.04266137269948743 	 Validation Loss 0.025854459705038205
INFO:WNN:Epoch 7: Training Loss 0.010093167879076518 	 Validation Loss 0.023499527170012396
INFO:WNN:Epoch 8: Training Loss 0.01781589972889995 	 Validation Loss 0.019353008932537503
INFO:WNN:Epoch 9: Training Loss 0.013443469274031988 	 Validation Loss 0.01566901868985345
INFO:WNN:Epoch 10: Training Loss 0.022770380118529644 	 Validation Loss 0.010241903416398499
INFO:WNN:Epoch 11: Training Loss 0.009604211805886557 	 Validation Loss 0.018253375465671223
threshold tensor(0.1486, grad_fn=<MulBackward0>)
