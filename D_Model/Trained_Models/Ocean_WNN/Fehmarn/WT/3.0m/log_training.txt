INFO:WNN:Epoch 0: Training Loss 0.2777875789973142 	 Validation Loss 0.14945496413856746
INFO:WNN:Epoch 1: Training Loss 0.17188080435889902 	 Validation Loss 0.21115464270114898
INFO:WNN:Epoch 2: Training Loss 0.09151258020031065 	 Validation Loss 0.20739063248038292
INFO:WNN:Epoch 3: Training Loss 0.08080566234008374 	 Validation Loss 0.25573447421193124
INFO:WNN:Epoch 4: Training Loss 0.1853639215298728 	 Validation Loss 1.6198094248771668
INFO:WNN:Epoch 5: Training Loss 0.27745893745700817 	 Validation Loss 0.5842629987746477
INFO:WNN:Epoch 6: Training Loss 0.19978662054172328 	 Validation Loss 1.384308922290802
INFO:WNN:Epoch 7: Training Loss 0.2701737112218302 	 Validation Loss 0.2695154145359993
INFO:WNN:Epoch 8: Training Loss 0.17778988354073105 	 Validation Loss 0.15456420248374342
INFO:WNN:Epoch 9: Training Loss 0.33659739892257823 	 Validation Loss 0.1810052514076233
INFO:WNN:Epoch 10: Training Loss 0.6000441071618632 	 Validation Loss 1.3215369697660209
INFO:WNN:Epoch 11: Training Loss 0.9500398520635194 	 Validation Loss 6.0085931196808815
threshold tensor(28.8244, grad_fn=<MulBackward0>)
