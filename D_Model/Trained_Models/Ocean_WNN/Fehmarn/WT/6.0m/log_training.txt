INFO:WNN:Epoch 0: Training Loss 0.033163805471157645 	 Validation Loss 0.002962875684412817
INFO:WNN:Epoch 1: Training Loss 0.026013394985616636 	 Validation Loss 0.00921994809889131
INFO:WNN:Epoch 2: Training Loss 0.025642221459754175 	 Validation Loss 0.007198343441511194
INFO:WNN:Epoch 3: Training Loss 0.011212474426658217 	 Validation Loss 0.0050117217987361885
INFO:WNN:Epoch 4: Training Loss 0.02106663357394005 	 Validation Loss 0.01051956508308649
INFO:WNN:Epoch 5: Training Loss 0.01218571307269288 	 Validation Loss 0.0018985772169091636
INFO:WNN:Epoch 6: Training Loss 0.011401477224747911 	 Validation Loss 0.004643297469657328
INFO:WNN:Epoch 7: Training Loss 0.013154651315954443 	 Validation Loss 0.004398491725118624
INFO:WNN:Epoch 8: Training Loss 0.015907523373536313 	 Validation Loss 0.010102701683839163
INFO:WNN:Epoch 9: Training Loss 0.008201791802952408 	 Validation Loss 0.004755859056280719
INFO:WNN:Epoch 10: Training Loss 0.007496574862098559 	 Validation Loss 0.0010180933750234544
INFO:WNN:Epoch 11: Training Loss 0.007182950992895318 	 Validation Loss 0.0008448142778231866
INFO:WNN:Epoch 12: Training Loss 0.0035358442827047483 	 Validation Loss 0.0020929582339401045
INFO:WNN:Epoch 13: Training Loss 0.0015125801283747105 	 Validation Loss 0.0019762429486339292
INFO:WNN:Epoch 14: Training Loss 0.0012738242598811826 	 Validation Loss 0.001848444562508828
INFO:WNN:Epoch 15: Training Loss 0.0015268773695424898 	 Validation Loss 0.002002775378059596
INFO:WNN:Epoch 16: Training Loss 0.0018417420662025018 	 Validation Loss 0.0026313915538291135
INFO:WNN:Epoch 17: Training Loss 0.0020695635860399557 	 Validation Loss 0.0020828148764040736
INFO:WNN:Epoch 18: Training Loss 0.001524902105607602 	 Validation Loss 0.0003509971534691027
INFO:WNN:Epoch 19: Training Loss 0.0012285218371054052 	 Validation Loss 0.0003812259803655454
INFO:WNN:Epoch 20: Training Loss 0.001216476646007138 	 Validation Loss 0.0003941332995762221
INFO:WNN:Epoch 21: Training Loss 0.0008406474309238904 	 Validation Loss 0.0005996866336014742
INFO:WNN:Epoch 22: Training Loss 0.0010159938935296983 	 Validation Loss 0.0010895240508640807
INFO:WNN:Epoch 23: Training Loss 0.0012379992828621786 	 Validation Loss 0.0017622266022954136
INFO:WNN:Epoch 24: Training Loss 0.0013184719735846982 	 Validation Loss 0.0022353907115757465
INFO:WNN:Epoch 25: Training Loss 0.00130668008821542 	 Validation Loss 0.0010226077122044647
INFO:WNN:Epoch 26: Training Loss 0.0012748881594412346 	 Validation Loss 0.0005391757877077907
INFO:WNN:Epoch 27: Training Loss 0.0013467072352592571 	 Validation Loss 0.0007302586099184635
INFO:WNN:Epoch 28: Training Loss 0.0014351420127654405 	 Validation Loss 0.0007861117709479812
INFO:WNN:Epoch 29: Training Loss 0.0015682800726449545 	 Validation Loss 0.00014609214364706227
INFO:WNN:Epoch 30: Training Loss 0.0012215143200833823 	 Validation Loss 0.0005744696552735857
INFO:WNN:Epoch 31: Training Loss 0.0021543809382126495 	 Validation Loss 0.0006760234229861655
INFO:WNN:Epoch 32: Training Loss 0.006286850469480866 	 Validation Loss 0.010828789892709918
INFO:WNN:Epoch 33: Training Loss 0.009913606707261505 	 Validation Loss 0.006379003740019268
INFO:WNN:Epoch 34: Training Loss 0.017643544087449 	 Validation Loss 0.012516539440386824
INFO:WNN:Epoch 35: Training Loss 0.006353680437009039 	 Validation Loss 0.009978584052684406
INFO:WNN:Epoch 36: Training Loss 0.01018832084349657 	 Validation Loss 0.0057444815886103446
INFO:WNN:Epoch 37: Training Loss 0.012252925187249594 	 Validation Loss 0.01021380507801142
INFO:WNN:Epoch 38: Training Loss 0.009360299212985283 	 Validation Loss 0.006627361238416698
INFO:WNN:Epoch 39: Training Loss 0.013567187312918786 	 Validation Loss 0.004704719383476509
INFO:WNN:Epoch 40: Training Loss 0.017602203729661373 	 Validation Loss 0.007355860848393705
threshold tensor(0.0254, grad_fn=<MulBackward0>)
