INFO:WNN:Epoch 0: Training Loss 0.2688685938217854 	 Validation Loss 0.15734377005137504
INFO:WNN:Epoch 1: Training Loss 0.1680612887220481 	 Validation Loss 0.19252239316701888
INFO:WNN:Epoch 2: Training Loss 0.06794312980639029 	 Validation Loss 0.2993330530822277
INFO:WNN:Epoch 3: Training Loss 0.10242546576036941 	 Validation Loss 0.6675062537193298
INFO:WNN:Epoch 4: Training Loss 0.34940971030936213 	 Validation Loss 1.0446470975875854
INFO:WNN:Epoch 5: Training Loss 0.4352301951627471 	 Validation Loss 0.3996028952300549
INFO:WNN:Epoch 6: Training Loss 0.15332999371605205 	 Validation Loss 0.06401867866516113
INFO:WNN:Epoch 7: Training Loss 0.15164213135685253 	 Validation Loss 0.02958398787304759
INFO:WNN:Epoch 8: Training Loss 0.08177095500581391 	 Validation Loss 0.20490526780486107
INFO:WNN:Epoch 9: Training Loss 0.13843560583529924 	 Validation Loss 0.07495461776852608
INFO:WNN:Epoch 10: Training Loss 0.10937609657633436 	 Validation Loss 0.2897817075252533
INFO:WNN:Epoch 11: Training Loss 0.22634917761116655 	 Validation Loss 0.13619817644357682
INFO:WNN:Epoch 12: Training Loss 0.18049347962995496 	 Validation Loss 0.07820644117891788
INFO:WNN:Epoch 13: Training Loss 0.10415968221105353 	 Validation Loss 0.27288170605897905
INFO:WNN:Epoch 14: Training Loss 0.32828237487097517 	 Validation Loss 1.4529173165559768
INFO:WNN:Epoch 15: Training Loss 0.3589595041261349 	 Validation Loss 1.349722945690155
INFO:WNN:Epoch 16: Training Loss 0.33459351481199323 	 Validation Loss 0.8120795905590057
INFO:WNN:Epoch 17: Training Loss 0.4694359240245923 	 Validation Loss 0.28036233959719536
INFO:WNN:Epoch 18: Training Loss 0.4705256450261119 	 Validation Loss 1.2630488865077496
threshold tensor(7.4686, grad_fn=<MulBackward0>)
