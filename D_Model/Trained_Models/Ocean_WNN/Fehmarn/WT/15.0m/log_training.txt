INFO:WNN:Epoch 0: Training Loss 0.18976199039671984 	 Validation Loss 0.02255385306974252
INFO:WNN:Epoch 1: Training Loss 0.05436540704249637 	 Validation Loss 0.015537216871355971
INFO:WNN:Epoch 2: Training Loss 0.08371474319655034 	 Validation Loss 0.026383966207504272
INFO:WNN:Epoch 3: Training Loss 0.22414788836613297 	 Validation Loss 0.0885162428021431
INFO:WNN:Epoch 4: Training Loss 0.2582745416245113 	 Validation Loss 0.07045897903541724
INFO:WNN:Epoch 5: Training Loss 0.6652738750368977 	 Validation Loss 0.14495660985509554
INFO:WNN:Epoch 6: Training Loss 0.27260352528861 	 Validation Loss 0.17455070776244005
INFO:WNN:Epoch 7: Training Loss 0.11846145026437524 	 Validation Loss 0.11299276227752368
INFO:WNN:Epoch 8: Training Loss 0.11599285293616252 	 Validation Loss 0.1400207169353962
INFO:WNN:Epoch 9: Training Loss 0.07175699243089184 	 Validation Loss 0.04574865816781918
INFO:WNN:Epoch 10: Training Loss 0.09452952293455989 	 Validation Loss 0.22896546125411987
INFO:WNN:Epoch 11: Training Loss 0.20173775053828852 	 Validation Loss 0.34626715381940204
INFO:WNN:Epoch 12: Training Loss 0.19104423464806233 	 Validation Loss 0.05769781954586506
threshold tensor(0.2785, grad_fn=<MulBackward0>)
