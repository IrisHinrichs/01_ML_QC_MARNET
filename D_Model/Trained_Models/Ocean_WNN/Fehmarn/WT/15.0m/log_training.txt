INFO:WNN:Epoch 0: Training Loss 0.21728693013878161 	 Validation Loss 0.9893642246723175
INFO:WNN:Epoch 1: Training Loss 0.15170585247245913 	 Validation Loss 0.05267927036620677
INFO:WNN:Epoch 2: Training Loss 0.04880026128154861 	 Validation Loss 0.06264282241463662
INFO:WNN:Epoch 3: Training Loss 0.09827418584830445 	 Validation Loss 0.3117681618779898
INFO:WNN:Epoch 4: Training Loss 0.15619430273971696 	 Validation Loss 0.04139804318547249
INFO:WNN:Epoch 5: Training Loss 0.15804261163236644 	 Validation Loss 0.21274261251091958
INFO:WNN:Epoch 6: Training Loss 0.1786579098604042 	 Validation Loss 0.022927647829055785
INFO:WNN:Epoch 7: Training Loss 0.14321819608854247 	 Validation Loss 0.41523979119956494
INFO:WNN:Epoch 8: Training Loss 0.11776826218362968 	 Validation Loss 0.986579068005085
INFO:WNN:Epoch 9: Training Loss 0.19624937387607708 	 Validation Loss 1.7904264599084854
INFO:WNN:Epoch 10: Training Loss 0.22491841148761915 	 Validation Loss 4.575450909882784
INFO:WNN:Epoch 11: Training Loss 0.5240457802156245 	 Validation Loss 3.553846604377031
INFO:WNN:Epoch 12: Training Loss 0.40960332416395856 	 Validation Loss 5.318837708234787
INFO:WNN:Epoch 13: Training Loss 0.5169635815310138 	 Validation Loss 1.4474157214164733
INFO:WNN:Epoch 14: Training Loss 0.27211125471181224 	 Validation Loss 0.6383672781288624
INFO:WNN:Epoch 15: Training Loss 0.08893306606119097 	 Validation Loss 0.3817289799451828
INFO:WNN:Epoch 16: Training Loss 0.12142989751875483 	 Validation Loss 0.09679604470729827
INFO:WNN:Epoch 17: Training Loss 0.041254979838275266 	 Validation Loss 0.05948889553546906
threshold tensor(0.2162, grad_fn=<MulBackward0>)
