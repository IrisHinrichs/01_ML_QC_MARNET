INFO:WNN:Epoch 0: Training Loss 0.2513586595135776 	 Validation Loss 0.009723302838392556
INFO:WNN:Epoch 1: Training Loss 0.10870373190183169 	 Validation Loss 0.10571004971861839
INFO:WNN:Epoch 2: Training Loss 0.03676719637145583 	 Validation Loss 0.02031072797253728
INFO:WNN:Epoch 3: Training Loss 0.02527245217705841 	 Validation Loss 0.12748333849012852
INFO:WNN:Epoch 4: Training Loss 0.03404167087165096 	 Validation Loss 0.05370353646576405
INFO:WNN:Epoch 5: Training Loss 0.018338966393354052 	 Validation Loss 0.104865662753582
INFO:WNN:Epoch 6: Training Loss 0.033060420505684814 	 Validation Loss 0.11857602819800377
INFO:WNN:Epoch 7: Training Loss 0.023959441978449025 	 Validation Loss 0.21294041424989701
INFO:WNN:Epoch 8: Training Loss 0.07356426973836025 	 Validation Loss 0.20169134624302387
INFO:WNN:Epoch 9: Training Loss 0.07904680052807991 	 Validation Loss 0.5413360238075257
INFO:WNN:Epoch 10: Training Loss 0.12456868168208277 	 Validation Loss 0.06764671020209789
INFO:WNN:Epoch 11: Training Loss 0.11285528874679032 	 Validation Loss 0.1580415979027748
threshold tensor(0.4195, grad_fn=<MulBackward0>)
