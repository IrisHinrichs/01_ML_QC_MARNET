INFO:WNN:Epoch 0: Training Loss 0.278004964529183 	 Validation Loss 0.16627755905501546
INFO:WNN:Epoch 1: Training Loss 0.18672808632549323 	 Validation Loss 0.2206361025571823
INFO:WNN:Epoch 2: Training Loss 0.0845982184268157 	 Validation Loss 0.31314031407237053
INFO:WNN:Epoch 3: Training Loss 0.16199677459648043 	 Validation Loss 0.5086492359638214
INFO:WNN:Epoch 4: Training Loss 0.3414442539627699 	 Validation Loss 3.1023257255554197
INFO:WNN:Epoch 5: Training Loss 0.7621673088744755 	 Validation Loss 0.25011670887470244
INFO:WNN:Epoch 6: Training Loss 0.2338839758326052 	 Validation Loss 0.507177920639515
INFO:WNN:Epoch 7: Training Loss 0.2717047148572776 	 Validation Loss 0.35571548491716387
INFO:WNN:Epoch 8: Training Loss 0.25318610960989013 	 Validation Loss 0.6472478240728379
INFO:WNN:Epoch 9: Training Loss 0.21330708500198264 	 Validation Loss 0.5629999951459468
INFO:WNN:Epoch 10: Training Loss 0.15802610961755714 	 Validation Loss 0.5861567616462707
INFO:WNN:Epoch 11: Training Loss 0.27506491963315427 	 Validation Loss 0.20206349417567254
threshold tensor(0.9529, grad_fn=<MulBackward0>)
