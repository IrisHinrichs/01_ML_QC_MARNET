INFO:WNN:Epoch 0: Training Loss 0.034745739377888565 	 Validation Loss 0.012205559740929553
INFO:WNN:Epoch 1: Training Loss 0.005737985308044015 	 Validation Loss 0.012609078510043522
INFO:WNN:Epoch 2: Training Loss 0.0038807242006727942 	 Validation Loss 0.014168995432555676
INFO:WNN:Epoch 3: Training Loss 0.0038211124153216527 	 Validation Loss 0.013406243679734567
INFO:WNN:Epoch 4: Training Loss 0.00378005205554851 	 Validation Loss 0.01054480109208574
INFO:WNN:Epoch 5: Training Loss 0.003502545538528435 	 Validation Loss 0.008022738698249062
INFO:WNN:Epoch 6: Training Loss 0.003222517689802485 	 Validation Loss 0.007596688480892529
INFO:WNN:Epoch 7: Training Loss 0.003118031556041796 	 Validation Loss 0.007741172177096208
INFO:WNN:Epoch 8: Training Loss 0.0028684015927497516 	 Validation Loss 0.00800484859306986
INFO:WNN:Epoch 9: Training Loss 0.002779843661740548 	 Validation Loss 0.008988435981639972
INFO:WNN:Epoch 10: Training Loss 0.0028951864407870008 	 Validation Loss 0.00848744879476726
INFO:WNN:Epoch 11: Training Loss 0.0028079580095416103 	 Validation Loss 0.008443448731365303
INFO:WNN:Epoch 12: Training Loss 0.002783060451916202 	 Validation Loss 0.008424915528545776
INFO:WNN:Epoch 13: Training Loss 0.002865270939488827 	 Validation Loss 0.008609915540243188
INFO:WNN:Epoch 14: Training Loss 0.0028941539234581164 	 Validation Loss 0.007170018313142161
INFO:WNN:Epoch 15: Training Loss 0.0025240508912247606 	 Validation Loss 0.008321626480513563
INFO:WNN:Epoch 16: Training Loss 0.0026521587855456623 	 Validation Loss 0.008011551573872566
INFO:WNN:Epoch 17: Training Loss 0.002659885572407557 	 Validation Loss 0.008235066508253416
INFO:WNN:Epoch 18: Training Loss 0.0026012520601592297 	 Validation Loss 0.005999963264912367
INFO:WNN:Epoch 19: Training Loss 0.002310941641982854 	 Validation Loss 0.008322780156352868
INFO:WNN:Epoch 20: Training Loss 0.002739596947863452 	 Validation Loss 0.006656011508312076
INFO:WNN:Epoch 21: Training Loss 0.00223084398499707 	 Validation Loss 0.006454365483174722
INFO:WNN:Epoch 22: Training Loss 0.00212276704291214 	 Validation Loss 0.005677448896070321
INFO:WNN:Epoch 23: Training Loss 0.0020995198547404544 	 Validation Loss 0.006189206343454619
INFO:WNN:Epoch 24: Training Loss 0.0020672452123148962 	 Validation Loss 0.004146135150222108
INFO:WNN:Epoch 25: Training Loss 0.0019056286152764198 	 Validation Loss 0.007024122673707704
INFO:WNN:Epoch 26: Training Loss 0.0025918784079120988 	 Validation Loss 0.0065663176064845175
INFO:WNN:Epoch 27: Training Loss 0.002725491988906909 	 Validation Loss 0.008228736396025246
INFO:WNN:Epoch 28: Training Loss 0.003071176437065895 	 Validation Loss 0.010561490567245832
INFO:WNN:Epoch 29: Training Loss 0.002592461662000082 	 Validation Loss 0.005890568815326939
INFO:WNN:Epoch 30: Training Loss 0.002219929969235156 	 Validation Loss 0.01006526016863063
INFO:WNN:Epoch 31: Training Loss 0.0023404754953507303 	 Validation Loss 0.010687209413542101
INFO:WNN:Epoch 32: Training Loss 0.0035162105640655465 	 Validation Loss 0.00937904823028172
INFO:WNN:Epoch 33: Training Loss 0.002500015392613707 	 Validation Loss 0.008521542612773677
INFO:WNN:Epoch 34: Training Loss 0.002978753803423449 	 Validation Loss 0.009607265994418412
INFO:WNN:Epoch 35: Training Loss 0.0028743305842959836 	 Validation Loss 0.008375311095733196
threshold tensor(0.0791, grad_fn=<MulBackward0>)
