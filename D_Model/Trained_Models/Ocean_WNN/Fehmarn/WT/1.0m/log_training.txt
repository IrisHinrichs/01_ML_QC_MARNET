INFO:WNN:Epoch 0: Training Loss 0.03474573758522342 	 Validation Loss 0.012205561681184918
INFO:WNN:Epoch 1: Training Loss 0.005737985403367235 	 Validation Loss 0.012609070593801638
INFO:WNN:Epoch 2: Training Loss 0.0038807245857262816 	 Validation Loss 0.014168994540038208
INFO:WNN:Epoch 3: Training Loss 0.0038211123049560034 	 Validation Loss 0.013406239605198303
INFO:WNN:Epoch 4: Training Loss 0.003780050707616048 	 Validation Loss 0.010544784444694718
INFO:WNN:Epoch 5: Training Loss 0.0035025441605111146 	 Validation Loss 0.008022739755688235
INFO:WNN:Epoch 6: Training Loss 0.003222517688821457 	 Validation Loss 0.007596689412215103
INFO:WNN:Epoch 7: Training Loss 0.0031180291943804076 	 Validation Loss 0.007741160923615098
INFO:WNN:Epoch 8: Training Loss 0.0028683975020265258 	 Validation Loss 0.008004851619868228
INFO:WNN:Epoch 9: Training Loss 0.002779844688795104 	 Validation Loss 0.008988451678305864
INFO:WNN:Epoch 10: Training Loss 0.0028951876457346333 	 Validation Loss 0.008487456109529981
INFO:WNN:Epoch 11: Training Loss 0.0028079604871278064 	 Validation Loss 0.008443446810512492
INFO:WNN:Epoch 12: Training Loss 0.0027830512747672137 	 Validation Loss 0.008424915780778974
INFO:WNN:Epoch 13: Training Loss 0.0028652897221690273 	 Validation Loss 0.00860986994424214
INFO:WNN:Epoch 14: Training Loss 0.002894206542202554 	 Validation Loss 0.007170378046187882
INFO:WNN:Epoch 15: Training Loss 0.0025240710688450145 	 Validation Loss 0.008321198401972651
INFO:WNN:Epoch 16: Training Loss 0.0026520176501987174 	 Validation Loss 0.00801209705726554
INFO:WNN:Epoch 17: Training Loss 0.002660058218537139 	 Validation Loss 0.00823570784026136
INFO:WNN:Epoch 18: Training Loss 0.002601704549510686 	 Validation Loss 0.006001472511949639
INFO:WNN:Epoch 19: Training Loss 0.0023109159802526154 	 Validation Loss 0.00831746655361106
INFO:WNN:Epoch 20: Training Loss 0.0027365797488548625 	 Validation Loss 0.006640845608975117
INFO:WNN:Epoch 21: Training Loss 0.0022323122227206707 	 Validation Loss 0.006504440961483245
INFO:WNN:Epoch 22: Training Loss 0.0021262178147634166 	 Validation Loss 0.005583864675524334
INFO:WNN:Epoch 23: Training Loss 0.002091126562569688 	 Validation Loss 0.00631080813279065
INFO:WNN:Epoch 24: Training Loss 0.0020892591528127525 	 Validation Loss 0.004011568909239334
INFO:WNN:Epoch 25: Training Loss 0.0018798230710345206 	 Validation Loss 0.006923945756473889
INFO:WNN:Epoch 26: Training Loss 0.0024898761243747776 	 Validation Loss 0.006031554968406756
INFO:WNN:Epoch 27: Training Loss 0.00251074321612976 	 Validation Loss 0.007719086706250285
INFO:WNN:Epoch 28: Training Loss 0.002988276179432555 	 Validation Loss 0.009729554954295358
INFO:WNN:Epoch 29: Training Loss 0.002636983853652341 	 Validation Loss 0.004204051646714409
INFO:WNN:Epoch 30: Training Loss 0.0020622415891573815 	 Validation Loss 0.009352943491345892
INFO:WNN:Epoch 31: Training Loss 0.0027716072576919708 	 Validation Loss 0.010000848647905514
INFO:WNN:Epoch 32: Training Loss 0.002357833672750132 	 Validation Loss 0.006048732146155089
INFO:WNN:Epoch 33: Training Loss 0.0025832122607088617 	 Validation Loss 0.008246206445619464
INFO:WNN:Epoch 34: Training Loss 0.002877669811629418 	 Validation Loss 0.008101482759229839
INFO:WNN:Epoch 35: Training Loss 0.003036178719432857 	 Validation Loss 0.01176538853906095
threshold tensor(0.1119, grad_fn=<MulBackward0>)
