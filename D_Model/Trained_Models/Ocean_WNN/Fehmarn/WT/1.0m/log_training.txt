INFO:WNN:Epoch 0: Training Loss 0.2780049741150269 	 Validation Loss 0.16627759668044745
INFO:WNN:Epoch 1: Training Loss 0.18672806287443713 	 Validation Loss 0.22063615918159485
INFO:WNN:Epoch 2: Training Loss 0.08459818608840762 	 Validation Loss 0.31314055249094963
INFO:WNN:Epoch 3: Training Loss 0.1619977332516043 	 Validation Loss 0.5086479842662811
INFO:WNN:Epoch 4: Training Loss 0.3414453427053846 	 Validation Loss 3.1022992610931395
INFO:WNN:Epoch 5: Training Loss 0.7621826330624237 	 Validation Loss 0.2502007633447647
INFO:WNN:Epoch 6: Training Loss 0.23379217999209237 	 Validation Loss 0.5118233934044838
INFO:WNN:Epoch 7: Training Loss 0.2734340960439884 	 Validation Loss 0.3707114666700363
INFO:WNN:Epoch 8: Training Loss 0.2549303621466307 	 Validation Loss 0.5388891652226449
INFO:WNN:Epoch 9: Training Loss 0.18234350799164392 	 Validation Loss 0.3561860606074333
INFO:WNN:Epoch 10: Training Loss 0.15859422793529362 	 Validation Loss 0.46788375414907935
INFO:WNN:Epoch 11: Training Loss 0.39167705061108676 	 Validation Loss 0.542396068572998
threshold tensor(1.7027, grad_fn=<MulBackward0>)
