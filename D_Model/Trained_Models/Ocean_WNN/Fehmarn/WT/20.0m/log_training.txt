INFO:WNN:Epoch 0: Training Loss 0.21557814069092274 	 Validation Loss 0.13173042237758636
INFO:WNN:Epoch 1: Training Loss 0.03228841837368567 	 Validation Loss 0.011089122854173183
INFO:WNN:Epoch 2: Training Loss 0.05894296716327186 	 Validation Loss 0.05042067915201187
INFO:WNN:Epoch 3: Training Loss 0.11409069901106483 	 Validation Loss 0.06651108898222446
INFO:WNN:Epoch 4: Training Loss 0.18390962591564114 	 Validation Loss 0.21229326725006104
INFO:WNN:Epoch 5: Training Loss 0.38013257279596996 	 Validation Loss 0.022019379772245884
INFO:WNN:Epoch 6: Training Loss 0.22821092828543801 	 Validation Loss 0.27922429144382477
INFO:WNN:Epoch 7: Training Loss 0.36425294089272164 	 Validation Loss 0.22672207653522491
INFO:WNN:Epoch 8: Training Loss 0.17055372754111886 	 Validation Loss 0.34951406717300415
INFO:WNN:Epoch 9: Training Loss 0.17697192781435495 	 Validation Loss 0.007098240777850151
INFO:WNN:Epoch 10: Training Loss 0.13642728145968055 	 Validation Loss 0.07669057697057724
INFO:WNN:Epoch 11: Training Loss 0.3699492080803876 	 Validation Loss 0.1324150487780571
INFO:WNN:Epoch 12: Training Loss 0.278580345552076 	 Validation Loss 0.6742354035377502
INFO:WNN:Epoch 13: Training Loss 0.44012745821171184 	 Validation Loss 0.4273095279932022
INFO:WNN:Epoch 14: Training Loss 0.5213328569661826 	 Validation Loss 0.06803711876273155
INFO:WNN:Epoch 15: Training Loss 0.5763997916082824 	 Validation Loss 0.659260630607605
INFO:WNN:Epoch 16: Training Loss 0.6399980705058569 	 Validation Loss 1.7590158581733704
INFO:WNN:Epoch 17: Training Loss 0.9284775022304419 	 Validation Loss 1.3511089086532593
INFO:WNN:Epoch 18: Training Loss 0.6974618673381029 	 Validation Loss 0.18805132806301117
INFO:WNN:Epoch 19: Training Loss 0.7022079929540103 	 Validation Loss 2.8952521085739136
INFO:WNN:Epoch 20: Training Loss 0.6753919270510474 	 Validation Loss 2.697195529937744
threshold tensor(2.6966, grad_fn=<MulBackward0>)
