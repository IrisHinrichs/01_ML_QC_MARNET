INFO:WNN:Epoch 0: Training Loss 0.022863100077825726 	 Validation Loss 0.0022426023561921385
INFO:WNN:Epoch 1: Training Loss 0.00872237829720358 	 Validation Loss 0.0021002301040829886
INFO:WNN:Epoch 2: Training Loss 0.005927930209757257 	 Validation Loss 0.00067124426843495
INFO:WNN:Epoch 3: Training Loss 0.004024363484604416 	 Validation Loss 0.0007988352283266269
INFO:WNN:Epoch 4: Training Loss 0.004023637918428655 	 Validation Loss 0.0018646885873749852
INFO:WNN:Epoch 5: Training Loss 0.0067334214844584385 	 Validation Loss 0.0023380034189257356
INFO:WNN:Epoch 6: Training Loss 0.005304416571424085 	 Validation Loss 0.0014118878170847893
INFO:WNN:Epoch 7: Training Loss 0.004283080753049779 	 Validation Loss 0.00533933953071634
INFO:WNN:Epoch 8: Training Loss 0.0037552832704381162 	 Validation Loss 0.0022407847249673474
INFO:WNN:Epoch 9: Training Loss 0.002365133305774538 	 Validation Loss 0.004924906986869044
INFO:WNN:Epoch 10: Training Loss 0.004998693263608154 	 Validation Loss 0.004639863683324721
INFO:WNN:Epoch 11: Training Loss 0.003295350317371644 	 Validation Loss 0.009045780843330754
INFO:WNN:Epoch 12: Training Loss 0.0039058917082002154 	 Validation Loss 0.009381477410594622
INFO:WNN:Epoch 13: Training Loss 0.004136219141814349 	 Validation Loss 0.005695400086955892
threshold tensor(0.0175, grad_fn=<MulBackward0>)
