INFO:WNN:Epoch 0: Training Loss 0.022863099850011084 	 Validation Loss 0.0022426030288139978
INFO:WNN:Epoch 1: Training Loss 0.00872237868503417 	 Validation Loss 0.002100230065277881
INFO:WNN:Epoch 2: Training Loss 0.005927929156645074 	 Validation Loss 0.0006712460017297417
INFO:WNN:Epoch 3: Training Loss 0.004024362322049704 	 Validation Loss 0.0007988362210906214
INFO:WNN:Epoch 4: Training Loss 0.004023637339521498 	 Validation Loss 0.0018647003970626327
INFO:WNN:Epoch 5: Training Loss 0.006733449195053254 	 Validation Loss 0.0023379898759432966
INFO:WNN:Epoch 6: Training Loss 0.005304418229901454 	 Validation Loss 0.001411934389681038
INFO:WNN:Epoch 7: Training Loss 0.004283215115540797 	 Validation Loss 0.005338791706081893
INFO:WNN:Epoch 8: Training Loss 0.003756433982151507 	 Validation Loss 0.0022415065775728887
INFO:WNN:Epoch 9: Training Loss 0.002369798027509453 	 Validation Loss 0.004876852139002747
INFO:WNN:Epoch 10: Training Loss 0.005015073764187753 	 Validation Loss 0.004723779572587874
INFO:WNN:Epoch 11: Training Loss 0.0032288684538026714 	 Validation Loss 0.008771212875015207
INFO:WNN:Epoch 12: Training Loss 0.003891487110222718 	 Validation Loss 0.008536054545806514
INFO:WNN:Epoch 13: Training Loss 0.0041053679234954125 	 Validation Loss 0.0040168836195435785
threshold tensor(0.0160, grad_fn=<MulBackward0>)
