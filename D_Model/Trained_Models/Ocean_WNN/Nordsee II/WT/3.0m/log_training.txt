INFO:WNN:Epoch 0: Training Loss 0.43090334391842283 	 Validation Loss 0.07394610345363617
INFO:WNN:Epoch 1: Training Loss 0.24472412604372948 	 Validation Loss 0.1181180328130722
INFO:WNN:Epoch 2: Training Loss 0.7411756402502457 	 Validation Loss 0.08397715538740158
INFO:WNN:Epoch 3: Training Loss 0.6296661330852658 	 Validation Loss 0.035654131323099136
INFO:WNN:Epoch 4: Training Loss 0.379221011698246 	 Validation Loss 0.09034692496061325
INFO:WNN:Epoch 5: Training Loss 0.14272508688736707 	 Validation Loss 0.09784610569477081
INFO:WNN:Epoch 6: Training Loss 0.3146850220859051 	 Validation Loss 0.07978381216526031
INFO:WNN:Epoch 7: Training Loss 0.257539360706384 	 Validation Loss 0.2755499482154846
INFO:WNN:Epoch 8: Training Loss 0.12768348559426765 	 Validation Loss 0.024478798732161522
INFO:WNN:Epoch 9: Training Loss 0.047107001983871064 	 Validation Loss 0.029269058257341385
INFO:WNN:Epoch 10: Training Loss 0.027349212913153072 	 Validation Loss 0.015558389015495777
INFO:WNN:Epoch 11: Training Loss 0.017216508959730467 	 Validation Loss 0.011718605645000935
INFO:WNN:Epoch 12: Training Loss 0.03022131749506419 	 Validation Loss 0.03109378181397915
INFO:WNN:Epoch 13: Training Loss 0.03784873012142877 	 Validation Loss 0.017985502257943153
INFO:WNN:Epoch 14: Training Loss 0.03777917063950251 	 Validation Loss 0.02206483669579029
INFO:WNN:Epoch 15: Training Loss 0.025143495698769888 	 Validation Loss 0.00745771499350667
INFO:WNN:Epoch 16: Training Loss 0.0201469160305957 	 Validation Loss 0.012495054863393307
INFO:WNN:Epoch 17: Training Loss 0.060470194534476225 	 Validation Loss 0.07227407395839691
INFO:WNN:Epoch 18: Training Loss 0.2176653135723124 	 Validation Loss 0.2985859811306
INFO:WNN:Epoch 19: Training Loss 0.24683496927221615 	 Validation Loss 0.01653507724404335
INFO:WNN:Epoch 20: Training Loss 0.18726953146979214 	 Validation Loss 0.0433693490922451
INFO:WNN:Epoch 21: Training Loss 0.1604924599950512 	 Validation Loss 0.010986174456775188
INFO:WNN:Epoch 22: Training Loss 0.12867404430483778 	 Validation Loss 0.05724139139056206
INFO:WNN:Epoch 23: Training Loss 0.3756014381845792 	 Validation Loss 0.28925764560699463
INFO:WNN:Epoch 24: Training Loss 0.5844456767042477 	 Validation Loss 0.04179313778877258
INFO:WNN:Epoch 25: Training Loss 0.20891833902957538 	 Validation Loss 0.04576550051569939
INFO:WNN:Epoch 26: Training Loss 0.23654121719106722 	 Validation Loss 0.024893270805478096
threshold tensor(0.1040, grad_fn=<MulBackward0>)
