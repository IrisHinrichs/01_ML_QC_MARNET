INFO:WNN:Epoch 0: Training Loss 0.05208672473026574 	 Validation Loss 0.0019085459061898291
INFO:WNN:Epoch 1: Training Loss 0.018822406239065705 	 Validation Loss 0.004021032073069364
INFO:WNN:Epoch 2: Training Loss 0.01133551069493879 	 Validation Loss 0.0006726669744239189
INFO:WNN:Epoch 3: Training Loss 0.006822460862044324 	 Validation Loss 0.0010701612336561084
INFO:WNN:Epoch 4: Training Loss 0.0064413548852672205 	 Validation Loss 0.0013039819023106247
INFO:WNN:Epoch 5: Training Loss 0.006663506064920142 	 Validation Loss 0.0012340053945081308
INFO:WNN:Epoch 6: Training Loss 0.006083717898853415 	 Validation Loss 0.001052647945471108
INFO:WNN:Epoch 7: Training Loss 0.006082161251994213 	 Validation Loss 0.001304898425587453
INFO:WNN:Epoch 8: Training Loss 0.006511770267240798 	 Validation Loss 0.0018806199077516794
INFO:WNN:Epoch 9: Training Loss 0.006303040908108923 	 Validation Loss 0.002553560014348477
INFO:WNN:Epoch 10: Training Loss 0.009515664437134608 	 Validation Loss 0.002244812319986522
INFO:WNN:Epoch 11: Training Loss 0.005607517717072693 	 Validation Loss 0.001164908600912895
INFO:WNN:Epoch 12: Training Loss 0.008986469107986846 	 Validation Loss 0.0016108304698718712
INFO:WNN:Epoch 13: Training Loss 0.008586510021922227 	 Validation Loss 0.0014279727620305493
threshold tensor(0.0119, grad_fn=<MulBackward0>)
