INFO:WNN:Epoch 0: Training Loss 0.024828212115655408 	 Validation Loss 0.001109895354602486
INFO:WNN:Epoch 1: Training Loss 0.0013394302525474207 	 Validation Loss 0.0012507376377470791
INFO:WNN:Epoch 2: Training Loss 0.0013195913749228794 	 Validation Loss 0.001281649456359446
INFO:WNN:Epoch 3: Training Loss 0.0013723658464689 	 Validation Loss 0.0013437547410527866
INFO:WNN:Epoch 4: Training Loss 0.0014466825947512991 	 Validation Loss 0.0015118129861851533
INFO:WNN:Epoch 5: Training Loss 0.0014711322984434598 	 Validation Loss 0.0015983393532224
INFO:WNN:Epoch 6: Training Loss 0.0014189452435905043 	 Validation Loss 0.0014752027248808492
INFO:WNN:Epoch 7: Training Loss 0.0013678938733908315 	 Validation Loss 0.0014690321550006047
INFO:WNN:Epoch 8: Training Loss 0.0014361918421220328 	 Validation Loss 0.0020790057023987174
INFO:WNN:Epoch 9: Training Loss 0.0016276000081987263 	 Validation Loss 0.002694685506867245
INFO:WNN:Epoch 10: Training Loss 0.0016440677606794907 	 Validation Loss 0.002843967309066405
INFO:WNN:Epoch 11: Training Loss 0.0017822135639183518 	 Validation Loss 0.0026119642813379564
threshold tensor(0.0227, grad_fn=<MulBackward0>)
