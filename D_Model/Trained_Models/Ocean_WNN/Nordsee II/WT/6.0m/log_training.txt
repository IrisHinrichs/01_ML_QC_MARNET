INFO:WNN:Epoch 0: Training Loss 0.03993166269522095 	 Validation Loss 0.00044614489161176607
INFO:WNN:Epoch 1: Training Loss 0.0014927171493917214 	 Validation Loss 0.0007871019915910438
INFO:WNN:Epoch 2: Training Loss 0.001965322789354168 	 Validation Loss 0.0007801933097653091
INFO:WNN:Epoch 3: Training Loss 0.0018319003130799455 	 Validation Loss 0.0006479118383140303
INFO:WNN:Epoch 4: Training Loss 0.001670534551841117 	 Validation Loss 0.0005372747255023569
INFO:WNN:Epoch 5: Training Loss 0.001522376933535908 	 Validation Loss 0.0004516283588600345
INFO:WNN:Epoch 6: Training Loss 0.001397835779674719 	 Validation Loss 0.0003833476803265512
INFO:WNN:Epoch 7: Training Loss 0.0012868028799155645 	 Validation Loss 0.00033406104194000363
INFO:WNN:Epoch 8: Training Loss 0.0011851785861756326 	 Validation Loss 0.0002962596045108512
INFO:WNN:Epoch 9: Training Loss 0.0010941566846061808 	 Validation Loss 0.00026361179698142223
INFO:WNN:Epoch 10: Training Loss 0.0010176095012483482 	 Validation Loss 0.0002412962421658449
INFO:WNN:Epoch 11: Training Loss 0.0009587205817010009 	 Validation Loss 0.00023611429787706584
INFO:WNN:Epoch 12: Training Loss 0.000915602538218975 	 Validation Loss 0.00023644260363653302
INFO:WNN:Epoch 13: Training Loss 0.0008914945108444316 	 Validation Loss 0.00022729607007931918
INFO:WNN:Epoch 14: Training Loss 0.000898260692529699 	 Validation Loss 0.00019405188140808605
INFO:WNN:Epoch 15: Training Loss 0.0009807966203528881 	 Validation Loss 9.799085091799498e-05
INFO:WNN:Epoch 16: Training Loss 0.0012139943164105429 	 Validation Loss 0.00028098938855691813
INFO:WNN:Epoch 17: Training Loss 0.0014726340576312954 	 Validation Loss 0.000758148918976076
INFO:WNN:Epoch 18: Training Loss 0.001283751394096231 	 Validation Loss 0.0004108340581296943
INFO:WNN:Epoch 19: Training Loss 0.00099720274757649 	 Validation Loss 0.0004924688983010128
INFO:WNN:Epoch 20: Training Loss 0.0009874269336777569 	 Validation Loss 0.0004927022819174454
INFO:WNN:Epoch 21: Training Loss 0.0009405306156399444 	 Validation Loss 0.00045626888459082693
INFO:WNN:Epoch 22: Training Loss 0.0009019194268355996 	 Validation Loss 0.00042901705455733463
INFO:WNN:Epoch 23: Training Loss 0.0008841506912830754 	 Validation Loss 0.00040364748565480113
INFO:WNN:Epoch 24: Training Loss 0.0009010588784899722 	 Validation Loss 0.00034834160760510713
INFO:WNN:Epoch 25: Training Loss 0.0009726686698023082 	 Validation Loss 0.00026470350348972715
INFO:WNN:Epoch 26: Training Loss 0.0010666642740129885 	 Validation Loss 0.0003771268675336614
threshold tensor(0.0012, grad_fn=<MulBackward0>)
