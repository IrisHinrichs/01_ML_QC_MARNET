INFO:WNN:Epoch 0: Training Loss 0.03416564810134279 	 Validation Loss 0.0010247966383758467
INFO:WNN:Epoch 1: Training Loss 0.008348056211616495 	 Validation Loss 0.000632085299002938
INFO:WNN:Epoch 2: Training Loss 0.0058003821366476 	 Validation Loss 0.0003796218018881821
INFO:WNN:Epoch 3: Training Loss 0.003987599699650994 	 Validation Loss 0.00034325200006909046
INFO:WNN:Epoch 4: Training Loss 0.0037675760437303005 	 Validation Loss 0.0003686904553129959
INFO:WNN:Epoch 5: Training Loss 0.003560419498150141 	 Validation Loss 0.0004461582308673921
INFO:WNN:Epoch 6: Training Loss 0.003536214481530752 	 Validation Loss 0.0008966385309273998
INFO:WNN:Epoch 7: Training Loss 0.005181084617267034 	 Validation Loss 0.0006624544112128206
INFO:WNN:Epoch 8: Training Loss 0.004590461598084349 	 Validation Loss 0.0008554235343278075
INFO:WNN:Epoch 9: Training Loss 0.004215873801235027 	 Validation Loss 0.0009021676111539515
INFO:WNN:Epoch 10: Training Loss 0.005543353620262625 	 Validation Loss 0.0008291842095786706
INFO:WNN:Epoch 11: Training Loss 0.005746241684199263 	 Validation Loss 0.0008551242111328369
INFO:WNN:Epoch 12: Training Loss 0.005352529079690986 	 Validation Loss 0.0009650797655922361
INFO:WNN:Epoch 13: Training Loss 0.00534616692637107 	 Validation Loss 0.0008092260589667907
INFO:WNN:Epoch 14: Training Loss 0.006545995609528344 	 Validation Loss 0.0005919385390977064
threshold tensor(0.0029, grad_fn=<MulBackward0>)
