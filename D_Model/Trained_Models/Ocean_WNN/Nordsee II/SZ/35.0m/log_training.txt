INFO:WNN:Epoch 0: Training Loss 0.024940460160839468 	 Validation Loss 8.135897360261879e-06
INFO:WNN:Epoch 1: Training Loss 1.0059697294728664e-05 	 Validation Loss 3.816662162610858e-06
INFO:WNN:Epoch 2: Training Loss 7.226665463377913e-06 	 Validation Loss 5.156374868420244e-06
INFO:WNN:Epoch 3: Training Loss 9.82826790455841e-06 	 Validation Loss 7.14212311928956e-06
INFO:WNN:Epoch 4: Training Loss 1.4643698281228504e-05 	 Validation Loss 2.5590334644221002e-05
INFO:WNN:Epoch 5: Training Loss 6.933504505646226e-06 	 Validation Loss 1.161055517210722e-05
INFO:WNN:Epoch 6: Training Loss 6.6200921155316434e-06 	 Validation Loss 8.056744055314388e-06
INFO:WNN:Epoch 7: Training Loss 1.0882006938217614e-05 	 Validation Loss 1.3722729515090274e-05
INFO:WNN:Epoch 8: Training Loss 9.435801641366481e-06 	 Validation Loss 4.834394455125827e-06
INFO:WNN:Epoch 9: Training Loss 1.0572573737377411e-05 	 Validation Loss 5.8694137502849726e-06
INFO:WNN:Epoch 10: Training Loss 8.043515975497684e-06 	 Validation Loss 1.0741488267740351e-05
INFO:WNN:Epoch 11: Training Loss 5.6678771643466535e-06 	 Validation Loss 9.856491942628054e-06
INFO:WNN:Epoch 12: Training Loss 6.124381071614948e-06 	 Validation Loss 9.246640066370068e-06
threshold tensor(6.6237e-05, grad_fn=<MulBackward0>)
