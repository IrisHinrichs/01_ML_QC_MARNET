INFO:WNN:Epoch 0: Training Loss 0.02675277742690696 	 Validation Loss 0.0020840201420166218
INFO:WNN:Epoch 1: Training Loss 0.0004889968663140584 	 Validation Loss 0.0035986787794778743
INFO:WNN:Epoch 2: Training Loss 0.0006167017952141881 	 Validation Loss 0.0045905435690656304
INFO:WNN:Epoch 3: Training Loss 0.0006443423859726257 	 Validation Loss 0.004339176598781099
INFO:WNN:Epoch 4: Training Loss 0.0005893455714461501 	 Validation Loss 0.0038323126112421355
INFO:WNN:Epoch 5: Training Loss 0.0005353062526107047 	 Validation Loss 0.00341320897374923
INFO:WNN:Epoch 6: Training Loss 0.0004925549795113208 	 Validation Loss 0.0028999123023822904
INFO:WNN:Epoch 7: Training Loss 0.0004630251855436048 	 Validation Loss 0.0024892012394654253
INFO:WNN:Epoch 8: Training Loss 0.0004448235788080031 	 Validation Loss 0.0022471935371868312
INFO:WNN:Epoch 9: Training Loss 0.00042818570945731455 	 Validation Loss 0.002118825805761541
INFO:WNN:Epoch 10: Training Loss 0.00041151235355603905 	 Validation Loss 0.0020412641509513683
INFO:WNN:Epoch 11: Training Loss 0.00039610393489889856 	 Validation Loss 0.0019735634268727154
INFO:WNN:Epoch 12: Training Loss 0.00038235529207971314 	 Validation Loss 0.001887035488228624
INFO:WNN:Epoch 13: Training Loss 0.00036959506331868397 	 Validation Loss 0.0017583440009426947
INFO:WNN:Epoch 14: Training Loss 0.0003568443411268163 	 Validation Loss 0.001595757064933423
INFO:WNN:Epoch 15: Training Loss 0.00034429645076746357 	 Validation Loss 0.001429021523411696
INFO:WNN:Epoch 16: Training Loss 0.0003319211809866829 	 Validation Loss 0.0012734607177359674
INFO:WNN:Epoch 17: Training Loss 0.00031888611236278547 	 Validation Loss 0.0011347777435730677
INFO:WNN:Epoch 18: Training Loss 0.00030606075758517665 	 Validation Loss 0.0010542627363368713
INFO:WNN:Epoch 19: Training Loss 0.00029559181112404076 	 Validation Loss 0.0010693545276202106
INFO:WNN:Epoch 20: Training Loss 0.000284126277842726 	 Validation Loss 0.0012358211509611767
INFO:WNN:Epoch 21: Training Loss 0.00027174565101972803 	 Validation Loss 0.0015698581701144576
INFO:WNN:Epoch 22: Training Loss 0.0002782340603933638 	 Validation Loss 0.0019808180416778973
INFO:WNN:Epoch 23: Training Loss 0.0003190167579418812 	 Validation Loss 0.002141453054112693
INFO:WNN:Epoch 24: Training Loss 0.00032743178305357407 	 Validation Loss 0.0017196744738612324
INFO:WNN:Epoch 25: Training Loss 0.0003011233977379864 	 Validation Loss 0.0015316259547641191
INFO:WNN:Epoch 26: Training Loss 0.0002881465453204631 	 Validation Loss 0.001430438974542388
INFO:WNN:Epoch 27: Training Loss 0.0002794528380339519 	 Validation Loss 0.001414772819164985
INFO:WNN:Epoch 28: Training Loss 0.00027722347436072897 	 Validation Loss 0.0015126584282067295
INFO:WNN:Epoch 29: Training Loss 0.000296524441883624 	 Validation Loss 0.0018793362348030012
threshold tensor(0.0154, grad_fn=<MulBackward0>)
